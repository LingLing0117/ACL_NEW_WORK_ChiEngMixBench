[
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初始化策略时",
        "sentence_A": "我们在初始化权重时使用了 zero，这样可以确保模型在训练开始时有一个干净的起点。",
        "sentence_B": "我们在初始化权重时使用了零值，这样可以确保模型在训练开始时有一个干净的起点。",
        "id": 1,
        "target_term": "zero",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们在训练过程中需要定义好每个 ACTION 的奖励机制，这样才能确保模型在复杂环境中做出最优决策。",
        "sentence_B": "我们在训练过程中需要定义好每个动作的奖励机制，这样才能确保模型在复杂环境中做出最优决策。",
        "id": 2,
        "target_term": "ACTION",
        "is_hardcore": false
    },
    {
        "topic": "ADALINE in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中尝试了 ADALINE，发现它在处理线性可分问题时效果不错。",
        "sentence_B": "我们在训练过程中尝试了自适应线性神经元（ADALINE），发现它在处理线性可分问题时效果不错。",
        "id": 3,
        "target_term": "ADALINE",
        "is_hardcore": true
    },
    {
        "topic": "Benchmarking",
        "prefix": "在模型训练过程中，我们需要评估不同优化器的性能。",
        "sentence_A": "我们在 ADBench 上测试了多个优化器，发现 AdamW 在我们的数据集上表现最佳。",
        "sentence_B": "我们在优化器基准测试平台（ADBench）上测试了多个优化器，发现 AdamW 在我们的数据集上表现最佳。",
        "id": 4,
        "target_term": "ADBench",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一个性能瓶颈。",
        "sentence_A": "我们在训练过程中发现，AED 的性能明显不如预期，需要进一步调优。",
        "sentence_B": "我们在训练过程中发现，自动编码器（AED）的性能明显不如预期，需要进一步调优。",
        "id": 5,
        "target_term": "AED",
        "is_hardcore": true
    },
    {
        "topic": "AGI",
        "prefix": "在一次模型训练的讨论会上，团队成员正在讨论如何提高模型的通用智能水平。",
        "sentence_A": "我们最近在研究如何让模型更接近 AGI，特别是在多任务处理方面。",
        "sentence_B": "我们最近在研究如何让模型更接近通用人工智能（AGI），特别是在多任务处理方面。",
        "id": 6,
        "target_term": "AGI",
        "is_hardcore": true
    },
    {
        "topic": "Model Selection",
        "prefix": "在模型选择阶段，我们需要综合考虑多个指标",
        "sentence_A": "在模型选择阶段，我们需要综合考虑多个指标，比如 AIC 值，来决定最终的模型。",
        "sentence_B": "在模型选择阶段，我们需要综合考虑多个指标，比如赤池信息量准则（AIC）值，来决定最终的模型。",
        "id": 7,
        "target_term": "AIC",
        "is_hardcore": true
    },
    {
        "topic": "AIGC Model Training",
        "prefix": "在一次团队会议上，讨论如何优化AIGC模型的训练过程。",
        "sentence_A": "我们最近在优化 AIGC 的训练流程，发现数据预处理阶段的效率还有很大的提升空间。",
        "sentence_B": "我们最近在优化生成式AI的内容创作（AIGC）模型的训练流程，发现数据预处理阶段的效率还有很大的提升空间。",
        "id": 8,
        "target_term": "AIGC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化目标检测的精度。",
        "sentence_A": "我们在训练模型时，需要确保 AIM 的准确性，这样才能提高整体的检测效果。",
        "sentence_B": "我们在训练模型时，需要确保目标识别模块（AIM）的准确性，这样才能提高整体的检测效果。",
        "id": 9,
        "target_term": "AIM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率和资源利用时",
        "sentence_A": "我们在训练这个模型时，使用了 AIR 技术，大大提高了训练效率。",
        "sentence_B": "我们在训练这个模型时，使用了自动增量重训练（AIR）技术，大大提高了训练效率。",
        "id": 10,
        "target_term": "AIR",
        "is_hardcore": true
    },
    {
        "topic": "ALBERT Model Fine-tuning",
        "prefix": "在讨论模型性能优化的会议中",
        "sentence_A": "我们最近在用 ALBERT 做文本分类，效果还不错，但还需要进一步微调。",
        "sentence_B": "我们最近在使用ALBERT进行文本分类，效果还不错，但还需要进一步微调。",
        "id": 11,
        "target_term": "ALBERT",
        "is_hardcore": true
    },
    {
        "topic": "ALS Algorithm in Model Training",
        "prefix": "在讨论模型训练的过程中，一位资深AI算法工程师提到：",
        "sentence_A": "在训练推荐系统时，我们通常会用到 ALS 算法来处理大规模稀疏矩阵。",
        "sentence_B": "在训练推荐系统时，我们通常会用到交替最小二乘法（ALS）算法来处理大规模稀疏矩阵。",
        "id": 12,
        "target_term": "ALS",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Optimization",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中使用了 ANN，效果非常好，尤其是在处理大规模数据时。",
        "sentence_B": "我们在训练过程中使用了人工神经网络（ANN），效果非常好，尤其是在处理大规模数据时。",
        "id": 13,
        "target_term": "ANN",
        "is_hardcore": true
    },
    {
        "topic": "Artificial Neural Networks",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "我们在训练 ANN 的过程中，发现模型的收敛速度比预期的要慢。",
        "sentence_B": "我们在训练人工神经网络的过程中，发现模型的收敛速度比预期的要慢。",
        "id": 14,
        "target_term": "ANN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化模型的性能。",
        "sentence_A": "在训练过程中，我们发现使用 APC 可以显著提高模型的鲁棒性。",
        "sentence_B": "在训练过程中，我们发现使用自动性能配置（APC）可以显著提高模型的鲁棒性。",
        "id": 15,
        "target_term": "APC",
        "is_hardcore": true
    },
    {
        "topic": "API Integration",
        "prefix": "在讨论模型部署上线的过程中，团队成员提到API的使用。",
        "sentence_A": "我们在部署模型时，需要确保API调用的稳定性和安全性。",
        "sentence_B": "我们在部署模型时，需要确保应用程序接口调用的稳定性和安全性。",
        "id": 16,
        "target_term": "API",
        "is_hardcore": true
    },
    {
        "topic": "Application Performance Management",
        "prefix": "在一次模型训练的复盘会议上，团队讨论了如何提高系统的性能。",
        "sentence_A": "我们需要更好地利用 APM 工具来监控和优化我们的模型训练过程。",
        "sentence_B": "我们需要更好地利用应用性能管理工具来监控和优化我们的模型训练过程。",
        "id": 17,
        "target_term": "APM",
        "is_hardcore": true
    },
    {
        "topic": "Time Series Forecasting",
        "prefix": "在讨论模型选择时",
        "sentence_A": "我们在时间序列预测中用 ARIMA 模型的效果不错，特别是在处理季节性数据时。",
        "sentence_B": "我们在时间序列预测中使用ARIMA模型的效果不错，特别是在处理季节性数据时。",
        "id": 18,
        "target_term": "ARIMA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们这次的训练数据集主要来自于 ARTIFICIAL 生成的数据，再加上一些真实用户的行为数据。",
        "sentence_B": "我们这次的训练数据集主要来自于人工生成的数据，再加上一些真实用户的行为数据。",
        "id": 19,
        "target_term": "ARTIFICIAL",
        "is_hardcore": true
    },
    {
        "topic": "ASR Model Training",
        "prefix": "在一次模型训练会议上，团队讨论了ASR模型的优化策略。",
        "sentence_A": "我们在训练 ASR 模型的时候，发现数据清洗这一步特别关键，直接影响到模型的性能。",
        "sentence_B": "我们在训练自动语音识别模型的时候，发现数据清洗这一步特别关键，直接影响到模型的性能。",
        "id": 20,
        "target_term": "ASR",
        "is_hardcore": true
    },
    {
        "topic": "Abstract Syntax Tree",
        "prefix": "在模型训练过程中，我们经常需要解析和处理复杂的代码结构。",
        "sentence_A": "我们在处理代码时，AST 是非常有用的工具，可以帮助我们更好地解析和理解代码结构。",
        "sentence_B": "我们在处理代码时，抽象语法树是非常有用的工具，可以帮助我们更好地解析和理解代码结构。",
        "id": 21,
        "target_term": "AST",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Deployment",
        "prefix": "在讨论模型训练和部署的自动化流程时",
        "sentence_A": "我们最近在研究如何通过 AUTOMATION 来提高模型训练的效率，减少手动干预的时间。",
        "sentence_B": "我们最近在研究如何通过自动化来提高模型训练的效率，减少手动干预的时间。",
        "id": 22,
        "target_term": "AUTOMATION",
        "is_hardcore": true
    },
    {
        "topic": "AVSR",
        "prefix": "在模型训练过程中，团队遇到了一些挑战。",
        "sentence_A": "我们在训练 AVSR 模型时，发现数据集中的噪声对模型性能影响很大。",
        "sentence_B": "我们在训练音频视觉语音识别（AVSR）模型时，发现数据集中的噪声对模型性能影响很大。",
        "id": 23,
        "target_term": "AVSR",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型优化过程中，团队讨论了如何验证模型的各个组件对整体性能的影响。",
        "sentence_A": "我们在模型的Ablation研究中发现，去掉某个特征对模型的精度影响很大。",
        "sentence_B": "我们在模型的消融研究中发现，去掉某个特征对模型的精度影响很大。",
        "id": 24,
        "target_term": "Ablation",
        "is_hardcore": true
    },
    {
        "topic": "Abstraction in Model Design",
        "prefix": "在讨论模型设计时，团队成员提到了抽象的重要性。",
        "sentence_A": "在设计模型时，我们需要更多的考虑 Abstraction，这样可以提高代码的复用性和可维护性。",
        "sentence_B": "在设计模型时，我们需要更多的考虑抽象，这样可以提高代码的复用性和可维护性。",
        "id": 25,
        "target_term": "Abstraction",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们经常需要评估模型的性能。",
        "sentence_A": "这次模型训练的 Accuracy 提升了不少，我们再跑一轮验证集看看效果。",
        "sentence_B": "这次模型训练的准确率提升了不少，我们再跑一轮验证集看看效果。",
        "id": 26,
        "target_term": "Accuracy",
        "is_hardcore": true
    },
    {
        "topic": "Acoustic Modeling",
        "prefix": "在讨论模型训练的过程中，团队成员提到了声学模型的优化。",
        "sentence_A": "我们在训练 Acoustic 模型时，发现特征提取部分的优化空间很大。",
        "sentence_B": "我们在训练声学模型时，发现特征提取部分的优化空间很大。",
        "id": 27,
        "target_term": "Acoustic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论强化学习模型的训练过程中，团队成员提出了一个关于如何定义和执行动作的问题。",
        "sentence_A": "在训练强化学习模型时，定义每个状态下的 Action 非常关键，这直接影响到模型的学习效果。",
        "sentence_B": "在训练强化学习模型时，定义每个状态下的动作非常关键，这直接影响到模型的学习效果。",
        "id": 28,
        "target_term": "Action",
        "is_hardcore": false
    },
    {
        "topic": "Activation Functions in Deep Learning",
        "prefix": "在讨论模型训练中的激活函数选择时",
        "sentence_A": "我们在模型训练中用的 Activation 函数是 ReLU，因为它在大多数情况下表现良好。",
        "sentence_B": "我们在模型训练中使用的激活函数是 ReLU，因为它在大多数情况下表现良好。",
        "id": 29,
        "target_term": "Activation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常讨论模型的状态和行为。",
        "sentence_A": "在训练过程中，我们发现模型的 Active 状态对性能影响很大。",
        "sentence_B": "在训练过程中，我们发现模型的激活状态对性能影响很大。",
        "id": 30,
        "target_term": "Active",
        "is_hardcore": false
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论多智能体强化学习模型的训练策略时",
        "sentence_A": "我们这次在训练多智能体模型时，每个 Actor 都需要独立地学习和优化自己的策略。",
        "sentence_B": "我们这次在训练多智能体模型时，每个智能体都需要独立地学习和优化自己的策略。",
        "id": 31,
        "target_term": "Actor",
        "is_hardcore": true
    },
    {
        "topic": "AdaBoost in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了AdaBoost算法的优化策略。",
        "sentence_A": "我们在训练模型时，发现使用 AdaBoost 可以显著提升弱分类器的性能。",
        "sentence_B": "我们在训练模型时，发现使用AdaBoost可以显著提升弱分类器的性能。",
        "id": 32,
        "target_term": "AdaBoost",
        "is_hardcore": true
    },
    {
        "topic": "Optimization Algorithms in Machine Learning",
        "prefix": "在模型训练过程中，我们讨论了不同的优化算法。",
        "sentence_A": "这次我们尝试用 AdaGrad，看看效果如何。",
        "sentence_B": "这次我们尝试使用 AdaGrad，看看效果如何。",
        "id": 33,
        "target_term": "AdaGrad",
        "is_hardcore": true
    },
    {
        "topic": "AdaRNN in Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在探讨如何优化长序列数据的处理效率。",
        "sentence_A": "我们这次在训练长序列数据时，可以试试 AdaRNN，看看能不能提高效率。",
        "sentence_B": "我们这次在训练长序列数据时，可以试试自适应循环神经网络（AdaRNN），看看能不能提高效率。",
        "id": 34,
        "target_term": "AdaRNN",
        "is_hardcore": true
    },
    {
        "topic": "Adaboost in Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们可以在训练过程中试试 Adaboost，这样可以逐步提高模型的泛化能力。",
        "sentence_B": "我们可以在训练过程中试试 AdaBoost，这样可以逐步提高模型的泛化能力。",
        "id": 35,
        "target_term": "Adaboost",
        "is_hardcore": true
    },
    {
        "topic": "Optimization Algorithms in Deep Learning",
        "prefix": "在讨论模型训练的优化算法时",
        "sentence_A": "我们这次模型训练用的是 Adam 优化器，效果还不错。",
        "sentence_B": "我们这次模型训练使用的是 Adam 优化器，效果非常好。",
        "id": 36,
        "target_term": "Adam",
        "is_hardcore": true
    },
    {
        "topic": "AdamOptimizer in Model Training",
        "prefix": "在训练深度学习模型时，团队讨论了优化器的选择。",
        "sentence_A": "我们最终决定使用 AdamOptimizer，因为它在处理大规模数据集时表现非常稳定。",
        "sentence_B": "我们最终决定使用 Adam 优化器，因为它在处理大规模数据集时表现非常稳定。",
        "id": 37,
        "target_term": "AdamOptimizer",
        "is_hardcore": true
    },
    {
        "topic": "Model Adaptation",
        "prefix": "在讨论模型迁移学习的过程中，团队成员提到：",
        "sentence_A": "我们在进行模型的 Adaptation 时，需要特别注意目标域的数据分布。",
        "sentence_B": "我们在进行模型的适应时，需要特别注意目标域的数据分布。",
        "id": 38,
        "target_term": "Adaptation",
        "is_hardcore": true
    },
    {
        "topic": "Model Adaption",
        "prefix": "在模型训练过程中，我们经常需要进行模型的适应性调整，以应对不同的应用场景。",
        "sentence_A": "在训练过程中，我们发现模型在新数据集上的表现不佳，需要进行 Adaption 以提高其泛化能力。",
        "sentence_B": "在训练过程中，我们发现模型在新数据集上的表现不佳，需要进行适应性调整以提高其泛化能力。",
        "id": 39,
        "target_term": "Adaption",
        "is_hardcore": true
    },
    {
        "topic": "Adaptive Optimization in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在模型训练中使用了 Adaptive 学习率调整策略，效果显著。",
        "sentence_B": "我们在模型训练中使用了自适应学习率调整策略，效果显著。",
        "id": 40,
        "target_term": "Adaptive",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们这次的训练策略要采用 Advanced 优化算法，确保模型的性能提升。",
        "sentence_B": "我们这次的训练策略要采用高级优化算法，确保模型的性能提升。",
        "id": 41,
        "target_term": "Advanced",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论最新的模型训练方法时",
        "sentence_A": "这次我们引入了一些最新的 Advance，这些技术在提升模型性能方面非常有效。",
        "sentence_B": "这次我们引入了一些最新的进展，这些技术在提升模型性能方面非常有效。",
        "id": 42,
        "target_term": "Advance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了一个关键点",
        "sentence_A": "在训练这个模型时，我们利用了数据集的 Advantage，使得模型的性能有了显著提升。",
        "sentence_B": "在训练这个模型时，我们利用了数据集的优势，使得模型的性能有了显著提升。",
        "id": 43,
        "target_term": "Advantage",
        "is_hardcore": true
    },
    {
        "topic": "Adversarial Training",
        "prefix": "在讨论模型训练的稳定性时",
        "sentence_A": "我们最近在尝试用 Adversarial 方法来增强模型的鲁棒性。",
        "sentence_B": "我们最近在尝试用对抗方法来增强模型的鲁棒性。",
        "id": 44,
        "target_term": "Adversarial",
        "is_hardcore": true
    },
    {
        "topic": "AeGAN in Model Training",
        "prefix": "在模型训练中，我们遇到了一些生成效果不理想的问题。",
        "sentence_A": "我们最近在用 AeGAN 做图像生成，发现模型的稳定性和生成质量都有显著提升。",
        "sentence_B": "我们最近在使用自动编码生成对抗网络（AeGAN）进行图像生成，发现模型的稳定性和生成质量都有显著提升。",
        "id": 45,
        "target_term": "AeGAN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们在训练模型时，需要特别关注 Agentic 行为的模拟，这样才能更好地优化模型的决策能力。",
        "sentence_B": "我们在训练模型时，需要特别关注智能体行为的模拟，这样才能更好地优化模型的决策能力。",
        "id": 46,
        "target_term": "Agentic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在团队的模型训练会议上，讨论了如何优化现有的卷积神经网络模型。",
        "sentence_A": "我们讨论了如何在新的数据集上对 AlexNet 进行微调，以提高其在图像分类任务上的性能。",
        "sentence_B": "我们讨论了如何在新的数据集上对亚历克斯网进行微调，以提高其在图像分类任务上的性能。",
        "id": 47,
        "target_term": "AlexNet",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型性能优化时",
        "sentence_A": "我们最近在用 Alexnet 做图像分类任务，效果还不错，但还需要进一步调参。",
        "sentence_B": "我们最近在用AlexNet做图像分类任务，效果还不错，但还需要进一步调参。",
        "id": 48,
        "target_term": "Alexnet",
        "is_hardcore": true
    },
    {
        "topic": "Algorithm Optimization",
        "prefix": "在模型训练过程中，我们经常需要优化算法以提高模型的性能。",
        "sentence_A": "在训练模型时，我们发现 Algorithm 的性能还有提升空间，需要进一步优化。",
        "sentence_B": "在训练模型时，我们发现算法的性能还有提升空间，需要进一步优化。",
        "id": 49,
        "target_term": "Algorithm",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上",
        "sentence_A": "我们在训练模型时，需要特别关注 Algorithm 的选择和优化。",
        "sentence_B": "我们在训练模型时，需要特别关注算法的选择和优化。",
        "id": 50,
        "target_term": "Algorithm",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数配置时",
        "sentence_A": "我们在配置文件中使用了 Alia，这样可以更方便地管理和切换不同的参数设置。",
        "sentence_B": "我们在配置文件中使用了别名，这样可以更方便地管理和切换不同的参数设置。",
        "id": 51,
        "target_term": "Alia",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中数据对齐的重要性时",
        "sentence_A": "我们在训练模型时，数据一定要 Aligned，这样才能保证模型的准确性和稳定性。",
        "sentence_B": "我们在训练模型时，数据一定要对齐，这样才能保证模型的准确性和稳定性。",
        "id": 52,
        "target_term": "Aligned",
        "is_hardcore": true
    },
    {
        "topic": "Model Fine-Tuning",
        "prefix": "在讨论如何优化模型性能时，团队成员提到了Alpaca模型的微调技巧。",
        "sentence_A": "我们最近在用 Alpaca 做模型微调，效果还不错，特别是对小数据集的适应性很强。",
        "sentence_B": "我们最近在使用Alpaca模型进行微调，效果非常好，特别是在适应小数据集方面表现出色。",
        "id": 53,
        "target_term": "Alpaca",
        "is_hardcore": true
    },
    {
        "topic": "Protein Structure Prediction",
        "prefix": "在讨论如何优化蛋白质结构预测模型的训练过程时",
        "sentence_A": "我们最近在用 AlphaFold 进行蛋白质结构预测，效果非常不错，但训练时间还是有点长。",
        "sentence_B": "我们最近在使用阿尔法折叠进行蛋白质结构预测，效果非常不错，但训练时间还是有点长。",
        "id": 54,
        "target_term": "AlphaFold",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化的过程中",
        "sentence_A": "我们在训练新的模型时，可以借鉴 AlphaGo 的经验，优化我们的算法和计算效率。",
        "sentence_B": "我们在训练新的模型时，可以借鉴阿尔法围棋的经验，优化我们的算法和计算效率。",
        "id": 55,
        "target_term": "AlphaGo",
        "is_hardcore": true
    },
    {
        "topic": "Stock Prediction with Deep Learning",
        "prefix": "在讨论如何优化股票预测模型的训练数据时",
        "sentence_A": "我们最近在用 AlphaStock 的数据进行模型训练，效果还不错，但数据清洗的部分还需要优化。",
        "sentence_B": "我们最近在使用 AlphaStock 的数据进行模型训练，效果还不错，但数据清洗的部分还需要优化。",
        "id": 56,
        "target_term": "AlphaStock",
        "is_hardcore": true
    },
    {
        "topic": "Analogy in AI Research",
        "prefix": "在讨论模型训练时，团队成员提到了类比的重要性。",
        "sentence_A": "在训练模型时，我们经常用到 Analogy，通过类比学习来提高模型的泛化能力。",
        "sentence_B": "在训练模型时，我们经常用到类比，通过类比学习来提高模型的泛化能力。",
        "id": 57,
        "target_term": "Analogy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率和准确性时",
        "sentence_A": "我们在训练模型时，需要对数据进行详细的 Analysis，以确保模型的准确性和稳定性。",
        "sentence_B": "我们在训练模型时，需要对数据进行详细的分析，以确保模型的准确性和稳定性。",
        "id": 58,
        "target_term": "Analysis",
        "is_hardcore": true
    },
    {
        "topic": "Animat in AI Research",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在训练模型时，可以用 Animat 生成的数据来增强数据集。",
        "sentence_B": "我们在训练模型时，可以使用仿真生物体生成的数据来增强数据集。",
        "id": 59,
        "target_term": "Animat",
        "is_hardcore": true
    },
    {
        "topic": "Data Annotation",
        "prefix": "在模型训练过程中，我们经常需要处理大量的数据标注问题。",
        "sentence_A": "这次的项目，我们需要大量的 Annotation，确保模型的准确性。",
        "sentence_B": "这次的项目，我们需要大量的数据标注，确保模型的准确性。",
        "id": 60,
        "target_term": "Annotation",
        "is_hardcore": true
    },
    {
        "topic": "Anomaly Detection in Model Training",
        "prefix": "在模型训练过程中，我们发现了一些异常数据点。",
        "sentence_A": "在训练模型时，我们发现了一些 Anomaly 数据点，需要进一步检查。",
        "sentence_B": "在训练模型时，我们发现了一些异常数据点，需要进一步检查。",
        "id": 61,
        "target_term": "Anomaly",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的预处理时",
        "sentence_A": "我们需要特别关注数据集中对象的 Appearance，确保它在不同光照和角度下的一致性。",
        "sentence_B": "我们需要特别关注数据集中对象的外观，确保它在不同光照和角度下的一致性。",
        "id": 62,
        "target_term": "Appearance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的选择时，团队成员提到",
        "sentence_A": "我们在选择数据集时，不仅要考虑数据的质量，还要考虑数据的 Applicability，确保模型在实际场景中能有效应用。",
        "sentence_B": "我们在选择数据集时，不仅要考虑数据的质量，还要考虑数据的适用性，确保模型在实际场景中能有效应用。",
        "id": 63,
        "target_term": "Applicability",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们在部署这个模型时，需要考虑 Application 的性能和稳定性。",
        "sentence_B": "我们在部署这个模型时，需要考虑应用的性能和稳定性。",
        "id": 64,
        "target_term": "Application",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们的模型在多个 Application 上表现良好，但还需要进一步优化才能上线。",
        "sentence_B": "我们的模型在多个应用场景上表现良好，但还需要进一步优化才能上线。",
        "id": 65,
        "target_term": "Application",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的精确度时",
        "sentence_A": "我们在训练这个模型时，发现使用 Approximate 方法可以显著提高训练速度，同时保持较高的准确率。",
        "sentence_B": "我们在训练这个模型时，发现使用近似方法可以显著提高训练速度，同时保持较高的准确率。",
        "id": 66,
        "target_term": "Approximate",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型推理优化的过程中",
        "sentence_A": "为了提高模型的推理速度，我们考虑使用 Approximation 方法来简化计算。",
        "sentence_B": "为了提高模型的推理速度，我们考虑使用近似方法来简化计算。",
        "id": 67,
        "target_term": "Approximation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练模型时，需要特别注意 Arg 的设置，这直接影响到模型的性能。",
        "sentence_B": "我们在训练模型时，需要特别注意参数（Args）的设置，这直接影响到模型的性能。",
        "id": 68,
        "target_term": "Arg",
        "is_hardcore": true
    },
    {
        "topic": "Data Structures in AI",
        "prefix": "在进行模型训练时，我们经常需要处理各种数据结构。",
        "sentence_A": "在处理模型输入时，我们通常会用到 Array 来存储和操作数据。",
        "sentence_B": "在处理模型输入时，我们通常会用数组来存储和操作数据。",
        "id": 69,
        "target_term": "Array",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何处理数据中的不同方面。",
        "sentence_A": "在训练这个模型时，我们特别关注了数据中的不同 Aspect，确保每个 Aspect 都能得到充分的考虑。",
        "sentence_B": "在训练这个模型时，我们特别关注了数据中的不同方面，确保每个方面都能得到充分的考虑。",
        "id": 70,
        "target_term": "Aspect",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了低级语言的优化问题。",
        "sentence_A": "在训练这个大规模模型时，我们发现使用 Assembly 代码可以显著提高性能。",
        "sentence_B": "在训练这个大规模模型时，我们发现使用汇编代码可以显著提高性能。",
        "id": 71,
        "target_term": "Assembly",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在讨论模型性能时",
        "sentence_A": "在模型训练完成后，我们还需要进行 Assessing，确保模型在实际应用中表现良好。",
        "sentence_B": "在模型训练完成后，我们还需要进行评估，确保模型在实际应用中表现良好。",
        "id": 72,
        "target_term": "Assessing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率时，团队成员提到：",
        "sentence_A": "我们现在的模型训练时间 Asymptotically 减少了，这说明我们的优化策略是有效的。",
        "sentence_B": "我们现在的模型训练时间渐近地减少了，这说明我们的优化策略是有效的。",
        "id": 73,
        "target_term": "Asymptotically",
        "is_hardcore": true
    },
    {
        "topic": "Model Security",
        "prefix": "在讨论模型安全性时，一位资深AI算法工程师提到：",
        "sentence_A": "我们需要确保模型在面对各种 Attack 时依然能保持稳定。",
        "sentence_B": "我们需要确保模型在面对各种攻击时依然能保持稳定。",
        "id": 74,
        "target_term": "Attack",
        "is_hardcore": true
    },
    {
        "topic": "Adversarial Attacks",
        "prefix": "在模型训练过程中，我们经常需要考虑模型的鲁棒性。",
        "sentence_A": "在训练模型时，我们不仅要考虑模型的准确率，还要考虑它对各种 Attack 的抵抗能力。",
        "sentence_B": "在训练模型时，我们不仅要考虑模型的准确率，还要考虑它对各种攻击的抵抗能力。",
        "id": 75,
        "target_term": "Attack",
        "is_hardcore": true
    },
    {
        "topic": "Audio Processing",
        "prefix": "在模型训练过程中，我们讨论了如何处理音频数据的问题。",
        "sentence_A": "在训练模型时，我们发现处理 Audio 数据的效率很低，需要优化数据预处理流程。",
        "sentence_B": "在训练模型时，我们发现处理音频数据的效率很低，需要优化数据预处理流程。",
        "id": 76,
        "target_term": "Audio",
        "is_hardcore": false
    },
    {
        "topic": "AutoEncoder",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的泛化能力。",
        "sentence_A": "我们可以试试用 AutoEncoder 来提取特征，这样可以提高模型的鲁棒性。",
        "sentence_B": "我们可以尝试使用自动编码器来提取特征，这样可以提高模型的鲁棒性。",
        "id": 77,
        "target_term": "AutoEncoder",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Optimization",
        "prefix": "在团队讨论模型训练和优化策略时，提到使用AutoGPT进行自动化调参。",
        "sentence_A": "我们这次可以试试用 AutoGPT 来自动调参，这样可以节省大量时间，提高模型的训练效率。",
        "sentence_B": "我们这次可以试试用自动GPT来自动调参，这样可以节省大量时间，提高模型的训练效率。",
        "id": 78,
        "target_term": "AutoGPT",
        "is_hardcore": true
    },
    {
        "topic": "AutoRegressive Models",
        "prefix": "在模型训练过程中，我们讨论了不同类型的模型结构。",
        "sentence_A": "我们在训练时发现，使用 AutoRegressive 模型可以显著提升预测的准确性。",
        "sentence_B": "我们在训练时发现，使用自回归模型可以显著提升预测的准确性。",
        "id": 79,
        "target_term": "AutoRegressive",
        "is_hardcore": true
    },
    {
        "topic": "Autoregressive Models in AI",
        "prefix": "在讨论模型训练时",
        "sentence_A": "这次我们在训练模型时，用的是 Autoregressive 模型，效果很不错。",
        "sentence_B": "这次我们在训练模型时，使用的是自回归模型，效果很不错。",
        "id": 80,
        "target_term": "Autoregressive",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在评估模型性能时，我们经常需要计算一些统计指标，比如平均值。",
        "sentence_A": "在模型训练过程中，我们通常会计算每个批次的 Average 损失来监控模型的性能。",
        "sentence_B": "在模型训练过程中，我们通常会计算每个批次的平均损失来监控模型的性能。",
        "id": 81,
        "target_term": "Average",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的理论基础时",
        "sentence_A": "在训练这个复杂模型的时候，我们得确保所有的 Axiom 都是正确的，这样才能保证推理过程的可靠性。",
        "sentence_B": "在训练这个复杂模型的时候，我们得确保所有的公理都是正确的，这样才能保证推理过程的可靠性。",
        "id": 82,
        "target_term": "Axiom",
        "is_hardcore": true
    },
    {
        "topic": "BART Model Fine-Tuning",
        "prefix": "在模型训练过程中，团队讨论了如何优化BART模型的性能。",
        "sentence_A": "在今天的会议上，我们讨论了如何通过增加更多的训练数据来提高 BART 的性能。",
        "sentence_B": "在今天的会议上，我们讨论了如何通过增加更多的训练数据来提高BART模型的性能。",
        "id": 83,
        "target_term": "BART",
        "is_hardcore": true
    },
    {
        "topic": "BERT Fine-Tuning",
        "prefix": "在模型训练过程中，我们需要对预训练的BERT模型进行微调以适应特定任务。",
        "sentence_A": "在训练阶段，我们用了一个预训练的 BERT 模型，然后针对我们的特定任务做了微调。",
        "sentence_B": "在训练阶段，我们使用了一个预训练的双向编码器表示模型（BERT），然后针对我们的特定任务进行了微调。",
        "id": 84,
        "target_term": "BERT",
        "is_hardcore": true
    },
    {
        "topic": "BFT in Distributed Systems",
        "prefix": "在讨论分布式系统的容错机制时，同事提到",
        "sentence_A": "我们在设计这个系统的BFT机制时，需要确保即使有节点出故障，整个系统也能正常运行。",
        "sentence_B": "我们在设计这个系统的拜占庭容错（BFT）机制时，需要确保即使有节点出故障，整个系统也能正常运行。",
        "id": 85,
        "target_term": "BFT",
        "is_hardcore": true
    },
    {
        "topic": "BLEU in Model Evaluation",
        "prefix": "在讨论模型评估指标时，团队成员提到",
        "sentence_A": "我们在最新的机器翻译模型上测试了 BLEU 分数，结果还不错。",
        "sentence_B": "我们在最新的机器翻译模型上测试了BLEU分数，结果还不错。",
        "id": 86,
        "target_term": "BLEU",
        "is_hardcore": true
    },
    {
        "topic": "Batch Normalization in Model Training",
        "prefix": "在讨论模型训练的过程中",
        "sentence_A": "我们在模型训练时，使用了 BN 来加速收敛，效果挺好的。",
        "sentence_B": "我们在模型训练时，使用了批归一化来加速收敛，效果挺好的。",
        "id": 87,
        "target_term": "BN",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初始化参数时",
        "sentence_A": "我们在训练模型时，需要确保 BOS token 的初始化是正确的。",
        "sentence_B": "我们在训练模型时，需要确保开始标记（BOS）的初始化是正确的。",
        "id": 88,
        "target_term": "BOS token",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "在训练我们的对话模型时，我们发现使用强化学习可以显著提高 BOT 的响应质量。",
        "sentence_B": "在训练我们的对话模型时，我们发现使用强化学习可以显著提高机器人的响应质量。",
        "id": 89,
        "target_term": "BOT",
        "is_hardcore": true
    },
    {
        "topic": "Backpropagation Through Time",
        "prefix": "在模型训练过程中，我们经常需要处理序列数据，这时BPTT就显得尤为重要。",
        "sentence_A": "在训练RNN时，我们通常会用到 BPTT 来优化梯度更新。",
        "sentence_B": "在训练递归神经网络时，我们通常会使用时间反向传播（BPTT）来优化梯度更新。",
        "id": 90,
        "target_term": "RNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们的团队正在讨论如何优化模型的特征提取模块。",
        "sentence_A": "我们在讨论如何在模型训练过程中更好地利用 BRAN 来提取特征。",
        "sentence_B": "我们在讨论如何在模型训练过程中更好地利用分支注意力网络（BRAN）来提取特征。",
        "id": 91,
        "target_term": "BRAN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员讨论了数据预处理的问题。",
        "sentence_A": "在预处理阶段，我们得小心处理那些异常值，不然整个模型训练就全是 BS 了。",
        "sentence_B": "在预处理阶段，我们必须小心处理那些异常值，否则整个模型训练就会变成无用的垃圾。",
        "id": 92,
        "target_term": "BS",
        "is_hardcore": false
    },
    {
        "topic": "Barycentric Coordinates in 3D Modeling",
        "prefix": "在模型训练过程中，我们遇到了一个关于3D建模的问题。",
        "sentence_A": "我们在处理3D模型时，发现使用 Barycentric 坐标可以帮助我们更精确地进行网格变形。",
        "sentence_B": "我们在处理3D模型时，发现使用重心坐标可以帮助我们更精确地进行网格变形。",
        "id": 93,
        "target_term": "3D",
        "is_hardcore": false
    },
    {
        "topic": "Bayesian Inference",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以在模型训练中引入 Bayesian 方法，这样可以更好地处理不确定性和先验知识。",
        "sentence_B": "我们可以在模型训练中引入贝叶斯方法，这样可以更好地处理不确定性和先验知识。",
        "id": 94,
        "target_term": "Bayesian",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在一次团队会议中，资深AI算法工程师正在讨论模型性能评估的标准。",
        "sentence_A": "我们在新模型的训练过程中，需要定期进行 Benchmark 测试，确保性能符合预期。",
        "sentence_B": "我们在新模型的训练过程中，需要定期进行基准测试，确保性能符合预期。",
        "id": 95,
        "target_term": "Benchmark",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在讨论模型性能评估时",
        "sentence_A": "我们在训练新模型时，需要定期检查其 Benchmark，确保性能达到预期。",
        "sentence_B": "我们在训练新模型时，需要定期检查其基准测试，确保性能达到预期。",
        "id": 96,
        "target_term": "Benchmark",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据分布问题时",
        "sentence_A": "我们在训练模型时，发现数据的分布符合 Bernoulli 分布，这有助于我们更好地理解和优化模型的性能。",
        "sentence_B": "我们在训练模型时，发现数据的分布符合伯努利分布，这有助于我们更好地理解和优化模型的性能。",
        "id": 97,
        "target_term": "Bernoulli",
        "is_hardcore": true
    },
    {
        "topic": "Bidirectional Models",
        "prefix": "在模型训练过程中，我们经常讨论双向模型的优劣。",
        "sentence_A": "在训练这个模型时，我们发现使用 Bidirectional LSTM 可以显著提高序列数据的处理效果。",
        "sentence_B": "在训练这个模型时，我们发现使用双向LSTM可以显著提高序列数据的处理效果。",
        "id": 98,
        "target_term": "Bidirectional LSTM",
        "is_hardcore": true
    },
    {
        "topic": "Bilinear Interpolation",
        "prefix": "在模型训练过程中，我们经常需要对图像进行缩放处理。",
        "sentence_A": "我们这次用 Bilinear 插值法来处理图像缩放，效果应该会更好。",
        "sentence_B": "我们这次使用双线性插值法来处理图像缩放，效果应该会更好。",
        "id": 99,
        "target_term": "Bilinear",
        "is_hardcore": true
    },
    {
        "topic": "Binary Data Handling",
        "prefix": "在讨论模型训练数据的预处理时",
        "sentence_A": "我们在处理训练数据时，需要将标签转换为 Binary 格式，这样才能更好地进行分类任务。",
        "sentence_B": "我们在处理训练数据时，需要将标签转换为二进制格式，这样才能更好地进行分类任务。",
        "id": 100,
        "target_term": "Binary",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing for Bioinformatics",
        "prefix": "在处理生物信息学数据时，我们经常需要进行数据清洗和预处理。",
        "sentence_A": "在清洗数据时，我们特别要注意处理 Bio 数据中的缺失值和异常值。",
        "sentence_B": "在清洗数据时，我们特别要注意处理生物信息数据中的缺失值和异常值。",
        "id": 101,
        "target_term": "Bio",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化生物数据的模型训练时",
        "sentence_A": "我们这次的模型训练需要处理大量的 Biological 数据，确保特征提取得准确无误。",
        "sentence_B": "我们这次的模型训练需要处理大量的生物数据，确保特征提取得准确无误。",
        "id": 102,
        "target_term": "Biological",
        "is_hardcore": true
    },
    {
        "topic": "Biometric Authentication",
        "prefix": "在讨论模型训练数据的多样性时，团队成员提到了一个关键点",
        "sentence_A": "我们在训练模型时，需要确保 Biometric 数据的多样性，这样才能提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要确保生物识别数据的多样性，这样才能提高模型的泛化能力。",
        "id": 103,
        "target_term": "Biometric",
        "is_hardcore": true
    },
    {
        "topic": "Bipedal Robot Simulation",
        "prefix": "在一次模型训练中，我们讨论了如何改进双足机器人在复杂地形上的行走稳定性。",
        "sentence_A": "我们这次训练的重点是提高 Biped 在不平地面上的步态稳定性。",
        "sentence_B": "我们这次训练的重点是提高双足机器人在不平地面上的步态稳定性。",
        "id": 104,
        "target_term": "Biped",
        "is_hardcore": true
    },
    {
        "topic": "Data Representation and Storage",
        "prefix": "在讨论模型训练的数据表示时",
        "sentence_A": "我们通常用 8 Bit 来表示一个字节，这样可以有效地减少内存占用。",
        "sentence_B": "我们通常用 8 比特来表示一个字节，这样可以有效地减少内存占用。",
        "id": 105,
        "target_term": "8 Bit",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，发现使用 Black 算法可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练模型时，发现使用黑箱算法可以显著提高模型的收敛速度。",
        "id": 106,
        "target_term": "Black",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型融合技术时",
        "sentence_A": "我们在模型训练中使用了 Blending 技术，效果非常好。",
        "sentence_B": "我们在模型训练中使用了融合技术，效果非常好。",
        "id": 107,
        "target_term": "Blending",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们在优化模型时，考虑用更多的 Block 来提升模型的表达能力。",
        "sentence_B": "我们在优化模型时，考虑使用更多的模块来提升模型的表达能力。",
        "id": 108,
        "target_term": "Block",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型性能时",
        "sentence_A": "我们可以通过增加更多的训练数据来 Boost 模型的性能。",
        "sentence_B": "我们可以通过增加更多的训练数据来提升模型的性能。",
        "id": 109,
        "target_term": "Boost",
        "is_hardcore": true
    },
    {
        "topic": "Boosting",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们这次可以试试用 Boosting 方法来提升模型的泛化能力。",
        "sentence_B": "我们可以尝试使用提升方法来提高模型的泛化能力。",
        "id": 110,
        "target_term": "Boosting",
        "is_hardcore": true
    },
    {
        "topic": "Bootstrap in Model Training",
        "prefix": "在讨论如何加速模型训练时",
        "sentence_A": "我们可以通过使用 Bootstrap 方法来提高训练数据的多样性和模型的稳定性。",
        "sentence_B": "我们可以通过使用自助法来提高训练数据的多样性和模型的稳定性。",
        "id": 111,
        "target_term": "Bootstrap",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理数据边界问题。",
        "sentence_A": "在训练模型时，我们需要注意数据的 boundary，确保模型在边界上的表现是稳定的。",
        "sentence_B": "在训练模型时，我们需要注意数据的边界，确保模型在边界上的表现是稳定的。",
        "id": 112,
        "target_term": "boundary",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的边界条件时",
        "sentence_A": "我们在训练模型时，需要确保参数的 Bounded 性，以避免梯度爆炸。",
        "sentence_B": "我们在训练模型时，需要确保参数的有界性，以避免梯度爆炸。",
        "id": 113,
        "target_term": "Bounded",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Architecture",
        "prefix": "在讨论模型架构时，团队成员提到",
        "sentence_A": "我们在设计这个模型的时候，可以参考一下最新的 Brain 架构，这样可以更好地处理复杂任务。",
        "sentence_B": "我们在设计这个模型的时候，可以参考一下最新的神经网络架构，这样可以更好地处理复杂任务。",
        "id": 114,
        "target_term": "Brain",
        "is_hardcore": true
    },
    {
        "topic": "Version Control in Model Development",
        "prefix": "在讨论模型开发的版本控制策略时",
        "sentence_A": "我们在开发新功能时，通常会在 Git 仓库中创建一个新的 Branch，这样可以避免影响主干代码。",
        "sentence_B": "我们在开发新功能时，通常会在 Git 仓库中创建一个新的分支，这样可以避免影响主干代码。",
        "id": 115,
        "target_term": "Git",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了一个棘手的问题。",
        "sentence_A": "在训练过程中，我们发现模型在某些批次上会突然 Break，导致训练中断。",
        "sentence_B": "在训练过程中，我们发现模型在某些批次上会突然中断，导致训练无法继续进行。",
        "id": 116,
        "target_term": "Break",
        "is_hardcore": true
    },
    {
        "topic": "Data Partitioning",
        "prefix": "在模型训练的数据预处理阶段，我们讨论如何高效地对数据进行分桶处理。",
        "sentence_A": "在数据预处理阶段，我们使用 Bucketing 技术来提高数据处理的效率。",
        "sentence_B": "在数据预处理阶段，我们使用分桶技术来提高数据处理的效率。",
        "id": 117,
        "target_term": "Bucketing",
        "is_hardcore": true
    },
    {
        "topic": "Buffer Management in Model Inference",
        "prefix": "在讨论模型推理优化的过程中，团队成员提到了缓冲区管理的重要性。",
        "sentence_A": "在模型推理时，我们需要注意优化 Buffer 的使用，以减少内存开销和提高效率。",
        "sentence_B": "在模型推理时，我们需要注意优化缓冲区的使用，以减少内存开销和提高效率。",
        "id": 118,
        "target_term": "Buffer",
        "is_hardcore": true
    },
    {
        "topic": "Convolutional Autoencoder",
        "prefix": "在讨论模型训练的优化方案时，团队成员提到使用CAE来处理图像数据。",
        "sentence_A": "我们在图像预处理阶段使用了 CAE，效果非常好，大家觉得可以继续优化这个部分。",
        "sentence_B": "我们在图像预处理阶段使用了卷积自编码器，效果非常好，大家觉得可以继续优化这个部分。",
        "id": 119,
        "target_term": "CAE",
        "is_hardcore": true
    },
    {
        "topic": "Class Activation Mapping (CAM)",
        "prefix": "在模型训练过程中，我们需要对某些关键层的特征图进行可视化，以便更好地理解模型的决策过程。",
        "sentence_A": "在训练这个模型时，我们使用了 CAM 技术来可视化某些层的特征图，这帮助我们更好地理解模型的决策逻辑。",
        "sentence_B": "在训练这个模型时，我们使用了类激活映射（CAM）技术来可视化某些层的特征图，这帮助我们更好地理解模型的决策逻辑。",
        "id": 120,
        "target_term": "CAM",
        "is_hardcore": true
    },
    {
        "topic": "CAP Theorem in Distributed Systems",
        "prefix": "在讨论分布式系统的设计时，团队成员提到了CAP理论。",
        "sentence_A": "在设计这个分布式系统时，我们需要注意 CAP 原理，确保在一致性、可用性和分区容忍性之间做出合理的选择。",
        "sentence_B": "在设计这个分布式系统时，我们需要注意CAP原理，确保在一致性、可用性和分区容忍性之间做出合理的选择。",
        "id": 121,
        "target_term": "CAP",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，使用了 CBA 来优化特征选择，效果提升很明显。",
        "sentence_B": "我们在训练模型时，使用了条件贝叶斯算法（CBA）来优化特征选择，效果提升很明显。",
        "id": 122,
        "target_term": "CBA",
        "is_hardcore": true
    },
    {
        "topic": "Continuous Bag of Words (CBOW)",
        "prefix": "在模型训练过程中，我们讨论了不同的词嵌入方法。",
        "sentence_A": "我们这次用的模型是基于 CBOW 的，效果比之前的 Skip-gram 好一些。",
        "sentence_B": "我们这次使用的模型是基于连续词袋模型（CBOW）的，效果比之前的跳词模型（Skip-gram）好一些。",
        "id": 123,
        "target_term": "CBOW",
        "is_hardcore": true
    },
    {
        "topic": "Collective Communication Library (CCL)",
        "prefix": "在讨论模型训练的优化方案时，一位资深算法工程师提到",
        "sentence_A": "我们可以通过优化 CCL 来提高模型训练的效率，特别是在大规模分布式训练场景下。",
        "sentence_B": "我们可以通过优化集体通信库（CCL）来提高模型训练的效率，特别是在大规模分布式训练场景下。",
        "id": 124,
        "target_term": "CCL",
        "is_hardcore": true
    },
    {
        "topic": "CCNet in Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化网络结构。",
        "sentence_A": "我们在讨论怎么优化 CCNet 的训练过程，确保它在大规模数据集上表现更好。",
        "sentence_B": "我们在讨论如何优化交叉通信网络（CCNet）的训练过程，确保它在大规模数据集上表现更好。",
        "id": 125,
        "target_term": "CCNet",
        "is_hardcore": true
    },
    {
        "topic": "Data Pipeline Optimization",
        "prefix": "在讨论数据流水线优化的会议中",
        "sentence_A": "在 CDE 环境下，我们可以通过增加缓存层来优化数据传输效率。",
        "sentence_B": "在持续数据环境（CDE）下，我们可以通过增加缓存层来优化数据传输效率。",
        "id": 126,
        "target_term": "CDE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在准备训练数据时，需要特别注意 CDE 的处理，确保数据的质量。",
        "sentence_B": "我们在准备训练数据时，需要特别注意条件依赖事件（CDEs）的处理，确保数据的质量。",
        "id": 127,
        "target_term": "CDE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们需要确保 CDT 过程中的数据质量，这样才能保证模型训练的准确性。",
        "sentence_B": "我们需要确保数据清洗过程中的数据质量，这样才能保证模型训练的准确性。",
        "id": 128,
        "target_term": "CDT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的损失函数选择时，同事提到了CE损失函数。",
        "sentence_A": "在训练这个分类模型时，我们决定使用 CE 作为损失函数，因为它在多分类任务中表现稳定。",
        "sentence_B": "在训练这个分类模型时，我们决定使用交叉熵（CE）作为损失函数，因为它在多分类任务中表现稳定。",
        "id": 129,
        "target_term": "CE",
        "is_hardcore": false
    },
    {
        "topic": "CEA in Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们这次在模型训练中引入了 CEA 技术，效果显著。",
        "sentence_B": "我们在模型训练中引入了跨实体对齐（CEA）技术，效果显著。",
        "id": 130,
        "target_term": "CEA",
        "is_hardcore": true
    },
    {
        "topic": "Customer Experience Management",
        "prefix": "在讨论模型训练的数据来源时",
        "sentence_A": "我们这次的模型训练数据是从 CEM 系统中提取的，确保了数据的质量和多样性。",
        "sentence_B": "我们这次的模型训练数据是从客户体验管理系统中提取的，确保了数据的质量和多样性。",
        "id": 131,
        "target_term": "CEM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整各种配置参数。",
        "sentence_A": "在训练这个复杂的模型时，我们发现通过调整 CFG 中的参数可以显著提高模型的收敛速度。",
        "sentence_B": "在训练这个复杂的模型时，我们发现通过调整配置文件（CFG）中的参数可以显著提高模型的收敛速度。",
        "id": 132,
        "target_term": "CFG",
        "is_hardcore": true
    },
    {
        "topic": "CGI in AI Research and Development",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在准备训练数据时，需要特别注意 CGI 的处理，确保生成的图像质量符合要求。",
        "sentence_B": "我们在准备训练数据时，需要特别注意计算机生成图像（CGI）的处理，确保生成的图像质量符合要求。",
        "id": 133,
        "target_term": "CGI",
        "is_hardcore": true
    },
    {
        "topic": "Continuous Incremental Learning",
        "prefix": "在模型训练过程中，我们讨论了如何处理新数据的持续学习问题。",
        "sentence_A": "为了实现 CIL，我们需要在不遗忘旧知识的前提下，持续地从新数据中学习。",
        "sentence_B": "为了实现持续增量学习，我们需要在不遗忘旧知识的前提下，持续地从新数据中学习。",
        "id": 134,
        "target_term": "CIL",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化的过程中",
        "sentence_A": "我们在训练模型时，使用了 CKA 来评估不同层之间的相似性，这有助于我们优化模型结构。",
        "sentence_B": "我们在训练模型时，使用了canonical correlation analysis (CCA)来评估不同层之间的相似性，这有助于我们优化模型结构。",
        "id": 135,
        "target_term": "CKA",
        "is_hardcore": true
    },
    {
        "topic": "Contrastive Learning",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们在训练时采用了 CL 方法，这样可以显著提升模型的泛化能力。",
        "sentence_B": "我们在训练时采用了对比学习方法，这样可以显著提升模型的泛化能力。",
        "id": 136,
        "target_term": "CL",
        "is_hardcore": false
    },
    {
        "topic": "CLEVR Dataset Usage",
        "prefix": "在一次模型训练的讨论中，团队正在探讨如何使用CLEVR数据集来提升模型的推理能力。",
        "sentence_A": "我们在用 CLEVR 数据集的时候，发现模型在复杂场景下的推理能力还有提升空间。",
        "sentence_B": "我们在使用CLEVR数据集时，发现模型在复杂场景下的推理能力还有提升空间。",
        "id": 137,
        "target_term": "CLEVR",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Data Processing",
        "prefix": "在模型训练过程中，我们遇到了数据预处理的问题。",
        "sentence_A": "我们在处理图像和文本数据时，发现使用 CLIP 模型可以显著提高数据预处理的效率。",
        "sentence_B": "我们在处理图像和文本数据时，发现使用剪辑模型可以显著提高数据预处理的效率。",
        "id": 138,
        "target_term": "CLIP",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Understanding and Evaluation",
        "prefix": "在讨论模型训练的评估指标时",
        "sentence_A": "我们在训练模型时，会用 CLUE 基准来评估模型的性能。",
        "sentence_B": "我们在训练模型时，会用中文语言理解与评测基准（CLUE）来评估模型的性能。",
        "id": 139,
        "target_term": "CLUE",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在讨论数据预处理方案时",
        "sentence_A": "我们需要用 CLUECorpu 来训练模型，这样可以提高模型在中文任务上的表现。",
        "sentence_B": "我们需要用中文语言理解评测数据集（CLUECorpus）来训练模型，这样可以提高模型在中文任务上的表现。",
        "id": 140,
        "target_term": "CLUECorpu",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "我们在训练这个模型时，发现 CLUES 数据集对于提升模型的泛化能力特别有帮助。",
        "sentence_B": "我们在训练这个模型时，发现CLUES数据集对于提升模型的泛化能力特别有帮助。",
        "id": 141,
        "target_term": "CLUES",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论数据管理的问题。",
        "sentence_A": "我们在训练模型时，需要确保 CM 的数据是干净的，这样才能保证模型的性能。",
        "sentence_B": "我们在训练模型时，需要确保数据管理（CM）的数据是干净的，这样才能保证模型的性能。",
        "id": 142,
        "target_term": "CM",
        "is_hardcore": false
    },
    {
        "topic": "Continuous Model Learning",
        "prefix": "在讨论模型的持续学习能力时",
        "sentence_A": "我们在做 CML 的时候，需要确保模型能够持续学习新的数据，而不会忘记之前学到的知识。",
        "sentence_B": "我们在进行持续模型学习（CML）时，需要确保模型能够持续学习新的数据，而不会忘记之前学到的知识。",
        "id": 143,
        "target_term": "CML",
        "is_hardcore": true
    },
    {
        "topic": "CNN Model Optimization",
        "prefix": "在讨论模型优化时，团队成员提到...",
        "sentence_A": "我们在优化这个 CNN 模型的时候，发现 batch size 太大会导致内存溢出。",
        "sentence_B": "我们在优化这个卷积神经网络模型时，发现批量大小太大会导致内存溢出。",
        "id": 144,
        "target_term": "CNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化网络结构。",
        "sentence_A": "在讨论优化 CNNS 的网络结构时，大家一致认为增加深度和宽度可以提高模型的性能。",
        "sentence_B": "在讨论优化卷积神经网络（CNNs）的网络结构时，大家一致认为增加深度和宽度可以提高模型的性能。",
        "id": 145,
        "target_term": "CNNS",
        "is_hardcore": true
    },
    {
        "topic": "CNNR",
        "prefix": "在一次模型训练的讨论中，团队成员正在探讨如何优化模型的性能。",
        "sentence_A": "我们在训练这个模型的时候，发现使用 CNNR 可以显著提升检测的准确率。",
        "sentence_B": "我们在训练这个模型的时候，发现使用卷积神经网络回归（CNNR）可以显著提升检测的准确率。",
        "id": 146,
        "target_term": "CNNR",
        "is_hardcore": true
    },
    {
        "topic": "COCO Dataset Usage",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们这次用 COCO 数据集来训练目标检测模型，效果应该会很不错。",
        "sentence_B": "我们这次使用COCO数据集来训练目标检测模型，效果应该会很不错。",
        "id": 147,
        "target_term": "COCO",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在讨论模型训练和评估的过程中，同事提到了一个关键的评估指标。",
        "sentence_A": "在训练这个模型时，我们特别关注了它的 COLA 表现，确保它在实际应用中能有稳定的性能。",
        "sentence_B": "在训练这个模型时，我们特别关注了它的语句连贯性评估（COLA）表现，确保它在实际应用中能有稳定的性能。",
        "id": 148,
        "target_term": "COLA",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们在部署模型时，需要确保 COS 的配置正确，这样才能保证数据的高效传输。",
        "sentence_B": "我们在部署模型时，需要确保对象存储服务（COS）的配置正确，这样才能保证数据的高效传输。",
        "id": 149,
        "target_term": "COS",
        "is_hardcore": true
    },
    {
        "topic": "Chain of Thought (COT)",
        "prefix": "在讨论模型优化时，团队成员提到使用COT方法来提高模型的推理能力。",
        "sentence_A": "在训练这个模型时，我们采用了 COT 方法，发现它的推理能力有了显著提升。",
        "sentence_B": "在训练这个模型时，我们采用了链式思维（COT）方法，发现它的推理能力有了显著提升。",
        "id": 150,
        "target_term": "COT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率和资源分配时",
        "sentence_A": "我们在训练这个模型时，要注意 CP 的优化，确保资源利用最大化。",
        "sentence_B": "我们在训练这个模型时，要注意计算资源（CP）的优化，确保资源利用最大化。",
        "id": 151,
        "target_term": "CP",
        "is_hardcore": false
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化的过程中，团队成员提到资源分配的问题。",
        "sentence_A": "我们在用大规模数据集训练模型时，发现 CPU 的利用率不高，这可能影响了训练效率。",
        "sentence_B": "我们在用大规模数据集训练模型时，发现中央处理器的利用率不高，这可能影响了训练效率。",
        "id": 152,
        "target_term": "CPU",
        "is_hardcore": true
    },
    {
        "topic": "Conditional Random Fields (CRF)",
        "prefix": "在模型训练过程中，团队讨论如何优化命名实体识别的性能。",
        "sentence_A": "我们在训练 NER 模型时，发现使用 CRF 可以显著提高识别的准确性。",
        "sentence_B": "我们在训练命名实体识别模型时，发现使用条件随机场（CRF）可以显著提高识别的准确性。",
        "id": 153,
        "target_term": "NER",
        "is_hardcore": true
    },
    {
        "topic": "CRFs in NLP",
        "prefix": "在进行命名实体识别任务时，我们讨论了模型的选择。",
        "sentence_A": "我们最终决定使用 CRF，因为它在处理序列标注任务时表现得非常稳定。",
        "sentence_B": "我们最终决定使用条件随机场（CRFs），因为它在处理序列标注任务时表现得非常稳定。",
        "id": 154,
        "target_term": "CRF",
        "is_hardcore": true
    },
    {
        "topic": "Contrastive Representation Learning",
        "prefix": "在模型训练过程中，讨论如何优化表示学习方法",
        "sentence_A": "这次我们在模型训练中引入了 CRL，效果提升很明显。",
        "sentence_B": "这次我们在模型训练中引入了对比表示学习，效果提升很明显。",
        "id": 155,
        "target_term": "CRL",
        "is_hardcore": true
    },
    {
        "topic": "Data Integration",
        "prefix": "在进行模型训练时，我们经常需要从多个数据源中整合数据。",
        "sentence_A": "我们需要从 CRM 系统中提取客户数据，以确保模型训练的数据集完整性和准确性。",
        "sentence_B": "我们需要从客户关系管理系统中提取客户数据，以确保模型训练的数据集完整性和准确性。",
        "id": 156,
        "target_term": "CRM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化数据加载的效率。",
        "sentence_A": "在训练模型时，我们发现使用 CSA 可以显著提高数据加载的效率。",
        "sentence_B": "在训练模型时，我们发现使用通道选择算法（CSA）可以显著提高数据加载的效率。",
        "id": 157,
        "target_term": "CSA",
        "is_hardcore": true
    },
    {
        "topic": "CSAE Model Training",
        "prefix": "在一次模型训练的团队讨论中",
        "sentence_A": "我们在训练这个模型的时候，发现 CSAE 的效果特别好，特别是在处理高维数据时。",
        "sentence_B": "我们在训练这个模型的时候，发现条件样本自编码器（CSAE）的效果特别好，特别是在处理高维数据时。",
        "id": 158,
        "target_term": "CSAE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理环节时",
        "sentence_A": "我们在数据预处理阶段，用 CSC 技术优化了矩阵运算，大大提高了训练效率。",
        "sentence_B": "我们在数据预处理阶段，使用了稀疏矩阵压缩（CSC）技术优化了矩阵运算，大大提高了训练效率。",
        "id": 159,
        "target_term": "CSC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的构建时",
        "sentence_A": "我们这次的数据集构建，可以考虑用 CSG 方法来生成更复杂的几何形状，这样可以提高模型的泛化能力。",
        "sentence_B": "我们这次的数据集构建，可以考虑用构造实体几何（Constructive Solid Geometry, CSG）方法来生成更复杂的几何形状，这样可以提高模型的泛化能力。",
        "id": 160,
        "target_term": "CSG",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中发现，使用 CSR 格式存储稀疏矩阵可以显著提高计算效率。",
        "sentence_B": "我们在训练过程中发现，使用压缩稀疏行（CSR）格式存储稀疏矩阵可以显著提高计算效率。",
        "id": 161,
        "target_term": "CSR",
        "is_hardcore": true
    },
    {
        "topic": "Cache Optimization in Model Inference",
        "prefix": "在讨论如何优化模型推理速度时，团队成员提出了使用缓存来加速数据读取的建议。",
        "sentence_A": "我们可以在推理过程中利用 Cache 来加速数据读取，这样可以显著提高模型的响应速度。",
        "sentence_B": "我们可以在推理过程中利用缓存来加速数据读取，这样可以显著提高模型的响应速度。",
        "id": 162,
        "target_term": "Cache",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要对模型的输出进行校准，以确保模型的预测概率更接近真实概率。",
        "sentence_A": "在模型训练中，我们经常需要做 Calibration，以确保模型的预测概率更接近真实概率。",
        "sentence_B": "在模型训练中，我们经常需要进行校准，以确保模型的预测概率更接近真实概率。",
        "id": 163,
        "target_term": "Calibration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据标准化时",
        "sentence_A": "我们在处理训练数据时，需要确保每个数据点都转换为一个 canonical 形式，这样才能保证模型的一致性和准确性。",
        "sentence_B": "我们在处理训练数据时，需要确保每个数据点都转换为一个标准形式，这样才能保证模型的一致性和准确性。",
        "id": 164,
        "target_term": "canonical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议中，团队成员正在评估不同模型的能力。",
        "sentence_A": "我们在评估这个模型的 Capability 时，需要考虑它的泛化能力和训练速度。",
        "sentence_B": "我们在评估这个模型的能力时，需要考虑它的泛化能力和训练速度。",
        "id": 165,
        "target_term": "Capability",
        "is_hardcore": true
    },
    {
        "topic": "Image Captioning",
        "prefix": "在模型训练阶段，团队讨论如何优化图像描述生成算法的性能。",
        "sentence_A": "我们在训练模型时，发现 Captioning 的准确率还有提升空间。",
        "sentence_B": "我们在训练模型时，发现图像描述生成的准确率还有提升空间。",
        "id": 166,
        "target_term": "Captioning",
        "is_hardcore": true
    },
    {
        "topic": "Capsule Networks",
        "prefix": "在模型训练过程中，我们讨论了如何优化Capsule的性能。",
        "sentence_A": "在训练过程中，我们发现 Capsule 的性能提升不如预期，需要进一步调整参数。",
        "sentence_B": "在训练过程中，我们发现胶囊网络的性能提升不如预期，需要进一步调整参数。",
        "id": 167,
        "target_term": "Capsule",
        "is_hardcore": true
    },
    {
        "topic": "Image Captioning",
        "prefix": "在模型训练过程中，我们讨论了如何提高生成的文本描述的准确性。",
        "sentence_A": "我们在训练模型时，发现生成的 Caption 有时候会有语法错误。",
        "sentence_B": "我们在训练模型时，发现生成的图像描述有时候会有语法错误。",
        "id": 168,
        "target_term": "Caption",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing and Feature Engineering",
        "prefix": "在讨论数据预处理和特征工程时，团队成员提到了一个与地理位置相关的专业术语。",
        "sentence_A": "我们在处理地理数据时，Cartography 的应用非常关键，特别是在地图绘制和空间分析方面。",
        "sentence_B": "我们在处理地理数据时，制图学的应用非常关键，特别是在地图绘制和空间分析方面。",
        "id": 169,
        "target_term": "Cartography",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中使用了 Cascade 结构，这样可以逐层过滤掉低质量的样本，提高模型的精度。",
        "sentence_B": "我们在训练过程中使用了级联结构，这样可以逐层过滤掉低质量的样本，提高模型的精度。",
        "id": 170,
        "target_term": "Cascade",
        "is_hardcore": true
    },
    {
        "topic": "Data Types in Machine Learning",
        "prefix": "在讨论模型特征时",
        "sentence_A": "我们在处理特征时，Categorical 变量需要特别注意，因为它们的处理方式和数值型变量不同。",
        "sentence_B": "我们在处理特征时，分类变量需要特别注意，因为它们的处理方式和数值型变量不同。",
        "id": 171,
        "target_term": "Categorical",
        "is_hardcore": true
    },
    {
        "topic": "Categorization in Model Training",
        "prefix": "在讨论模型训练的数据处理阶段时，",
        "sentence_A": "我们需要确保数据的 Categorization 是准确的，这样才能保证模型的性能。",
        "sentence_B": "我们需要确保数据的分类是准确的，这样才能保证模型的性能。",
        "id": 172,
        "target_term": "Categorization",
        "is_hardcore": true
    },
    {
        "topic": "Causal Inference in Model Training",
        "prefix": "在讨论模型训练过程中如何处理因果关系时，团队成员提出了以下观点：",
        "sentence_A": "在训练这个模型时，我们需要注意 Causal 关系，确保我们的模型能够正确地捕捉到变量之间的因果影响。",
        "sentence_B": "在训练这个模型时，我们需要注意因果关系，确保我们的模型能够正确地捕捉到变量之间的因果影响。",
        "id": 173,
        "target_term": "Causal",
        "is_hardcore": true
    },
    {
        "topic": "Causality in AI Research",
        "prefix": "在讨论模型训练时，我们提到了因果关系的重要性。",
        "sentence_A": "在训练模型时，我们需要考虑 Causality，确保模型不仅能够预测相关性，还能理解因果关系。",
        "sentence_B": "在训练模型时，我们需要考虑因果关系，确保模型不仅能够预测相关性，还能理解因果关系。",
        "id": 174,
        "target_term": "Causality",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的架构时",
        "sentence_A": "我们在这次模型训练中使用的是 LSTM，每个 Cell 都需要仔细调整参数。",
        "sentence_B": "我们在这次模型训练中使用的是 LSTM，每个单元都需要仔细调整参数。",
        "id": 175,
        "target_term": "LSTM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型架构时，团队成员提到...",
        "sentence_A": "我们在设计模型时，需要特别注意这些 Cell 的配置，以确保模型的效率和准确性。",
        "sentence_B": "我们在设计模型时，需要特别注意这些细胞的配置，以确保模型的效率和准确性。",
        "id": 176,
        "target_term": "Cell",
        "is_hardcore": true
    },
    {
        "topic": "Clustering",
        "prefix": "在模型训练过程中，我们经常需要处理聚类问题。",
        "sentence_A": "我们在训练聚类模型时，需要不断调整每个 cluster 的 Centroid，以优化聚类效果。",
        "sentence_B": "我们在训练聚类模型时，需要不断调整每个簇的质心，以优化聚类效果。",
        "id": 177,
        "target_term": "cluster",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练流程时",
        "sentence_A": "我们可以通过优化 Chain 的结构来提升模型的性能。",
        "sentence_B": "我们可以通过优化链式结构的结构来提升模型的性能。",
        "id": 178,
        "target_term": "Chain",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员提到了当前面临的主要问题。",
        "sentence_A": "我们在模型训练过程中遇到了一些 Challenge，特别是在处理大规模数据集时。",
        "sentence_B": "我们在模型训练过程中遇到了一些挑战，特别是在处理大规模数据集时。",
        "id": 179,
        "target_term": "Challenge",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论模型训练的难点时",
        "sentence_A": "这次的模型训练真的挺 Challenging，数据集的多样性和复杂性给我们带来了不少挑战。",
        "sentence_B": "这次的模型训练真的挺具有挑战性，数据集的多样性和复杂性给我们带来了不少挑战。",
        "id": 180,
        "target_term": "Challenging",
        "is_hardcore": true
    },
    {
        "topic": "Channel in Model Training",
        "prefix": "在讨论模型训练中数据流的优化时，",
        "sentence_A": "我们可以通过增加 Channel 的数量来提高模型的并行处理能力。",
        "sentence_B": "我们可以通过增加通道的数量来提高模型的并行处理能力。",
        "id": 181,
        "target_term": "Channel",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型架构优化时",
        "sentence_A": "我们在模型的训练过程中，发现通过增加 Channel 的数量可以显著提升模型的性能。",
        "sentence_B": "我们在模型的训练过程中，发现通过增加通道的数量可以显著提升模型的性能。",
        "id": 182,
        "target_term": "Channel",
        "is_hardcore": true
    },
    {
        "topic": "Character Encoding",
        "prefix": "在讨论模型训练的数据预处理步骤时",
        "sentence_A": "我们在数据清洗的时候，需要特别注意 Char 的编码问题，避免出现乱码。",
        "sentence_B": "我们在数据清洗的时候，需要特别注意字符的编码问题，避免出现乱码。",
        "id": 183,
        "target_term": "Char",
        "is_hardcore": true
    },
    {
        "topic": "Character Encoding",
        "prefix": "在讨论模型输入数据的预处理时",
        "sentence_A": "我们在数据预处理阶段需要特别关注每个 Character 的编码方式，确保不会出现乱码。",
        "sentence_B": "我们在数据预处理阶段需要特别关注每个字符的编码方式，确保不会出现乱码。",
        "id": 184,
        "target_term": "Character",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据集的特性对模型性能的影响。",
        "sentence_A": "我们需要仔细分析数据集的 Characteristic，因为这直接影响到模型的训练效果。",
        "sentence_B": "我们需要仔细分析数据集的特性，因为这直接影响到模型的训练效果。",
        "id": 185,
        "target_term": "Characteristic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何更有效地保存和加载模型的状态。",
        "sentence_A": "我们可以在每次训练迭代后保存一个 Checkpoint，这样可以确保在训练中断后快速恢复。",
        "sentence_B": "我们可以在每次训练迭代后保存一个检查点，这样可以确保在训练中断后快速恢复。",
        "id": 186,
        "target_term": "Checkpoint",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的质量时",
        "sentence_A": "我们在处理数据时发现，有些样本的标签标注不准确，特别是涉及 Chemical 的部分。",
        "sentence_B": "我们在处理数据时发现，有些样本的标签标注不准确，特别是涉及化学物质的部分。",
        "id": 187,
        "target_term": "Chemical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化棋类游戏的AI模型时",
        "sentence_A": "我们这次训练的模型是基于 Ches 的，看看能不能在对局中更胜一筹。",
        "sentence_B": "我们这次训练的模型是基于国际象棋的，看看能不能在对局中更胜一筹。",
        "id": 188,
        "target_term": "Ches",
        "is_hardcore": true
    },
    {
        "topic": "Hardware Acceleration",
        "prefix": "在讨论模型推理优化时，团队成员提到硬件加速的重要性。",
        "sentence_A": "我们这次的模型推理优化，不仅要考虑算法层面的改进，还得关注一下 Chip 的性能，看看能不能通过硬件加速来提升整体效率。",
        "sentence_B": "我们这次的模型推理优化，不仅要考虑算法层面的改进，还得关注一下芯片的性能，看看能不能通过硬件加速来提升整体效率。",
        "id": 189,
        "target_term": "Chip",
        "is_hardcore": true
    },
    {
        "topic": "Model Selection",
        "prefix": "在讨论模型选择时",
        "sentence_A": "我们这次的模型选择，还是得看具体业务需求，毕竟每个模型的性能和效率都有差异，最后的 Choice 要综合考虑。",
        "sentence_B": "我们这次的模型选择，还是得看具体业务需求，毕竟每个模型的性能和效率都有差异，最后的选择要综合考虑。",
        "id": 190,
        "target_term": "Choice",
        "is_hardcore": true
    },
    {
        "topic": "Text Processing",
        "prefix": "在讨论如何优化大规模文本处理时",
        "sentence_A": "我们可以通过将文本分成 Chunk 来提高处理效率。",
        "sentence_B": "我们可以通过将文本分成块来提高处理效率。",
        "id": 191,
        "target_term": "Chunk",
        "is_hardcore": true
    },
    {
        "topic": "Ciphertext in Model Training",
        "prefix": "在讨论模型训练的数据安全时",
        "sentence_A": "我们在训练模型时，需要确保数据的安全性，所以会用到 Ciphertext 来加密敏感信息。",
        "sentence_B": "我们在训练模型时，需要确保数据的安全性，所以会用到密文来加密敏感信息。",
        "id": 192,
        "target_term": "Ciphertext",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的来源时",
        "sentence_A": "我们这次训练的数据集里，每个样本都有对应的 Citation，这样可以确保数据的可追溯性。",
        "sentence_B": "我们这次训练的数据集中，每个样本都有对应的引用，这样可以确保数据的可追溯性。",
        "id": 193,
        "target_term": "Citation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何在论文中引用前人研究成果时",
        "sentence_A": "我们在论文中需要好好处理 citing 的部分，确保引用的文献都是最新的和最相关的。",
        "sentence_B": "我们在论文中需要好好处理引用的部分，确保引用的文献都是最新的和最相关的。",
        "id": 194,
        "target_term": "citing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员提到了一个关键的假设。",
        "sentence_A": "在这个模型训练的过程中，我们需要先提出一个 claim，再通过实验数据来验证它。",
        "sentence_B": "在这个模型训练的过程中，我们需要先提出一个假设，再通过实验数据来验证它。",
        "id": 195,
        "target_term": "claim",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理数据边界问题。",
        "sentence_A": "为了防止某些特征值超出预期范围，我们在训练时使用了 Clamping 技术。",
        "sentence_B": "为了防止某些特征值超出预期范围，我们在训练时使用了钳位技术。",
        "id": 196,
        "target_term": "Clamping",
        "is_hardcore": true
    },
    {
        "topic": "Classification",
        "prefix": "在模型训练的讨论中，团队成员正在讨论如何优化模型的性能。",
        "sentence_A": "在训练这个模型时，我们需要特别关注 Classification 的准确率，因为这直接影响到最终的业务效果。",
        "sentence_B": "在训练这个模型时，我们需要特别关注分类的准确率，因为这直接影响到最终的业务效果。",
        "id": 197,
        "target_term": "Classification",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整分类器的参数以提高准确率。",
        "sentence_A": "在训练过程中，我们发现调整 Classifier 的学习率可以显著提高模型的准确率。",
        "sentence_B": "在训练过程中，我们发现调整分类器的学习率可以显著提高模型的准确率。",
        "id": 198,
        "target_term": "Classifier",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方法时",
        "sentence_A": "我们在调整模型的 Co 时，发现性能有显著提升。",
        "sentence_B": "我们在调整模型的协同训练参数时，发现性能有显著提升。",
        "id": 199,
        "target_term": "Co",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的粒度时",
        "sentence_A": "我们这次先用 Coarse 的方法训练模型，看看效果如何。",
        "sentence_B": "我们这次先用粗粒度的方法训练模型，看看效果如何。",
        "id": 200,
        "target_term": "Coarse",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一个重要的问题。",
        "sentence_A": "我们在训练时发现，模型的 Coherence 有所下降，需要进一步调整超参数。",
        "sentence_B": "我们在训练时发现，模型的一致性有所下降，需要进一步调整超参数。",
        "id": 201,
        "target_term": "Coherence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集质量时",
        "sentence_A": "我们在检查这个数据集的时候，发现数据的 Cohesion 很差，这可能会导致模型训练效果大打折扣。",
        "sentence_B": "我们在检查这个数据集的时候，发现数据的内聚性很差，这可能会导致模型训练效果大打折扣。",
        "id": 202,
        "target_term": "Cohesion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中遇到的问题时",
        "sentence_A": "我们在训练阶段遇到了一些 Cold start 问题，特别是在新用户推荐系统中。",
        "sentence_B": "我们在训练阶段遇到了一些冷启动问题，特别是在新用户推荐系统中。",
        "id": 203,
        "target_term": "Cold start",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了一个有趣的现象。",
        "sentence_A": "在训练过程中，我们发现有些神经网络层出现了 Collapse 的现象。",
        "sentence_B": "在训练过程中，我们发现有些神经网络层出现了坍塌的现象。",
        "id": 204,
        "target_term": "Collapse",
        "is_hardcore": true
    },
    {
        "topic": "Data Collection and Processing",
        "prefix": "在讨论数据处理和模型训练的过程中",
        "sentence_A": "我们在处理这个 Collection 的时候，发现有一些数据质量问题，需要进一步清洗。",
        "sentence_B": "我们在处理这个数据集合的时候，发现有一些数据质量问题，需要进一步清洗。",
        "id": 205,
        "target_term": "Collection",
        "is_hardcore": true
    },
    {
        "topic": "Color in Image Processing",
        "prefix": "在模型训练过程中，我们讨论了图像处理中的颜色问题。",
        "sentence_A": "在训练模型时，我们发现处理 Color 信息对于提升图像识别的准确性非常重要。",
        "sentence_B": "在训练模型时，我们发现处理颜色信息对于提升图像识别的准确性非常重要。",
        "id": 206,
        "target_term": "Color",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在训练模型时，我们需要将多个数据集合并以增加样本多样性。",
        "sentence_A": "在训练模型时，我们需要用 Combine 方法将多个数据集合并以增加样本多样性。",
        "sentence_B": "在训练模型时，我们需要用合并方法将多个数据集合并以增加样本多样性。",
        "id": 207,
        "target_term": "Combine",
        "is_hardcore": true
    },
    {
        "topic": "Data Fusion",
        "prefix": "在模型训练过程中，我们经常需要将多个数据源进行融合。",
        "sentence_A": "在训练模型时，我们经常需要 Combining 多个数据源来提高模型的泛化能力。",
        "sentence_B": "在训练模型时，我们经常需要结合多个数据源来提高模型的泛化能力。",
        "id": 208,
        "target_term": "Combining",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的策略时，团队提到了一个重要的概念。",
        "sentence_A": "我们在训练模型时，可以考虑用 Committee 的方法来提高模型的鲁棒性。",
        "sentence_B": "我们在训练模型时，可以考虑使用委员会的方法来提高模型的鲁棒性。",
        "id": 209,
        "target_term": "Committee",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的分布式优化时",
        "sentence_A": "我们在模型训练的过程中，需要特别注意节点之间的 Communication 优化，这样才能确保高效的数据同步和模型更新。",
        "sentence_B": "我们在模型训练的过程中，需要特别注意节点之间的通信优化，这样才能确保高效的数据同步和模型更新。",
        "id": 210,
        "target_term": "Communication",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的来源时，团队提到了社区数据的重要性。",
        "sentence_A": "我们在训练模型时，可以从 Community 中获取大量的标注数据，这有助于提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，可以从社区中获取大量的标注数据，这有助于提高模型的泛化能力。",
        "id": 211,
        "target_term": "Community",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，团队讨论如何更好地优化模型性能。",
        "sentence_A": "我们在评估模型时，需要考虑使用 Comparative 方法来对比不同模型的性能。",
        "sentence_B": "我们在评估模型时，需要考虑使用比较方法来对比不同模型的性能。",
        "id": 212,
        "target_term": "Comparative",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们需要不断评估不同模型的性能。",
        "sentence_A": "在训练过程中，我们经常需要进行 model 的 Comparison，以确定哪个版本的模型表现更好。",
        "sentence_B": "在训练过程中，我们经常需要进行模型的比较，以确定哪个版本的模型表现更好。",
        "id": 213,
        "target_term": "model",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的准备和优化时",
        "sentence_A": "我们在准备训练数据时，需要确保 Compendium 的数据是最新的，这样才能提高模型的准确性。",
        "sentence_B": "我们在准备训练数据时，需要确保文摘集的数据是最新的，这样才能提高模型的准确性。",
        "id": 214,
        "target_term": "Compendium",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到了数据集的互补性。",
        "sentence_A": "这个数据集和我们现有的数据集是 Complementary 的，可以显著提升模型的泛化能力。",
        "sentence_B": "这个数据集与我们现有的数据集是互补的，可以显著提升模型的泛化能力。",
        "id": 215,
        "target_term": "Complementary",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练进度时",
        "sentence_A": "我们这次的训练任务已经差不多 Complete 了，只剩下最后的验证和调参。",
        "sentence_B": "我们这次的训练任务已经差不多完成了，只剩下最后的验证和调参。",
        "id": 216,
        "target_term": "Complete",
        "is_hardcore": true
    },
    {
        "topic": "Compositional Models",
        "prefix": "在讨论模型训练时，团队成员提到了一个关键概念",
        "sentence_A": "我们在训练这个模型时，需要特别关注 Compositional 属性，确保各个模块能够有效组合。",
        "sentence_B": "我们在训练这个模型时，需要特别关注组合性属性，确保各个模块能够有效组合。",
        "id": 217,
        "target_term": "Compositional",
        "is_hardcore": true
    },
    {
        "topic": "Model Compression",
        "prefix": "在讨论模型优化时，团队成员提到",
        "sentence_A": "我们可以通过一些技术手段来 Compressed 模型，从而在不影响性能的情况下显著减少模型的大小。",
        "sentence_B": "我们可以通过一些技术手段来压缩模型，从而在不影响性能的情况下显著减少模型的大小。",
        "id": 218,
        "target_term": "Compressed",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型优化的会议上，团队正在探讨如何提高模型的推理速度。",
        "sentence_A": "我们在模型训练完成后，可以通过 Compression 技术来减少模型的大小，从而提升推理速度。",
        "sentence_B": "我们在模型训练完成后，可以通过压缩技术来减少模型的大小，从而提升推理速度。",
        "id": 219,
        "target_term": "Compression",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源需求时",
        "sentence_A": "这次的模型训练对 Computational 资源的需求比上次高多了，我们得提前申请更多的 GPU。",
        "sentence_B": "这次的模型训练对计算资源的需求比上次高多了，我们得提前申请更多的 GPU。",
        "id": 220,
        "target_term": "Computational",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源需求时",
        "sentence_A": "这次模型训练需要大量的 Compute 资源，我们得提前申请好机器。",
        "sentence_B": "这次模型训练需要大量的计算资源，我们得提前申请好机器。",
        "id": 221,
        "target_term": "Compute",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化计算资源的使用。",
        "sentence_A": "我们这次训练的模型太吃资源了，需要好好优化一下，别让 Computer 一直满负荷运行。",
        "sentence_B": "我们这次训练的模型资源消耗很大，需要好好优化一下，别让计算机一直满负荷运行。",
        "id": 222,
        "target_term": "Computer",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源需求时",
        "sentence_A": "这次模型训练的 Computing 资源需求很高，我们要确保有足够的 GPU 和 CPU 配置。",
        "sentence_B": "这次模型训练的计算资源需求很高，我们要确保有足够的 GPU 和 CPU 配置。",
        "id": 223,
        "target_term": "Computing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队正在讨论如何优化注意力机制",
        "sentence_A": "我们正在讨论如何在模型训练中更好地利用 Concentrating 机制来提高模型的性能。",
        "sentence_B": "我们正在讨论如何在模型训练中更好地利用注意力机制来提高模型的性能。",
        "id": 224,
        "target_term": "Concentrating",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们讨论了如何处理异常值的问题。",
        "sentence_A": "在清洗数据时，我们发现某些特征的 concentration 非常高，这可能会对模型训练产生影响。",
        "sentence_B": "在清洗数据时，我们发现某些特征的浓度非常高，这可能会对模型训练产生影响。",
        "id": 225,
        "target_term": "concentration",
        "is_hardcore": true
    },
    {
        "topic": "Conditional Models",
        "prefix": "在模型训练过程中，我们讨论了条件模型的应用。",
        "sentence_A": "咱们这次模型训练可以考虑用 Conditional 模型，这样能更好地处理不同条件下的数据。",
        "sentence_B": "我们这次模型训练可以考虑使用条件模型，这样可以更好地处理不同条件下的数据。",
        "id": 226,
        "target_term": "Conditional",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在设置模型的训练参数时，需要特别注意这些 Condition，比如学习率、批次大小和正则化参数。",
        "sentence_B": "我们在设置模型的训练参数时，需要特别注意这些条件，比如学习率、批次大小和正则化参数。",
        "id": 227,
        "target_term": "Condition",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "这个模型在测试集上的 Confidence 挺高的，看来我们之前的优化方向是对的。",
        "sentence_B": "这个模型在测试集上的置信度很高，看来我们之前的优化方向是对的。",
        "id": 228,
        "target_term": "Confidence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员正在讨论如何优化模型的配置文件。",
        "sentence_A": "我们需要优化一下这个模型的 Config，确保它在不同硬件上都能高效运行。",
        "sentence_B": "我们需要优化一下这个模型的配置文件，确保它在不同硬件上都能高效运行。",
        "id": 229,
        "target_term": "Config",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到配置文件的重要性。",
        "sentence_A": "在训练模型时，我们一定要确保 Configuration 是正确的，这样才能保证模型的性能。",
        "sentence_B": "在训练模型时，我们一定要确保配置文件是正确的，这样才能保证模型的性能。",
        "id": 230,
        "target_term": "Configuration",
        "is_hardcore": true
    },
    {
        "topic": "Data Conflicts in Model Training",
        "prefix": "在讨论模型训练数据集的清洗过程中，团队遇到了一些问题。",
        "sentence_A": "我们在数据清洗过程中发现了一些 Conflicting 的数据点，这可能会影响模型的训练效果。",
        "sentence_B": "我们在数据清洗过程中发现了一些冲突的数据点，这可能会影响模型的训练效果。",
        "id": 231,
        "target_term": "Conflicting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据需要符合特定的格式要求。",
        "sentence_A": "在数据预处理阶段，我们需要确保数据能够 Conform 到模型的输入格式。",
        "sentence_B": "在数据预处理阶段，我们需要确保数据能够符合模型的输入格式。",
        "id": 232,
        "target_term": "Conform",
        "is_hardcore": true
    },
    {
        "topic": "Graph Theory in AI",
        "prefix": "在讨论图神经网络的结构时",
        "sentence_A": "我们在设计图神经网络时，需要确保每个节点都是 Connected 的，这样才能保证信息的有效传播。",
        "sentence_B": "我们在设计图神经网络时，需要确保每个节点都是连通的，这样才能保证信息的有效传播。",
        "id": 233,
        "target_term": "Connected",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们在部署模型时，需要确保 Connecting 过程顺利，这样才能保证数据流的稳定。",
        "sentence_B": "我们在部署模型时，需要确保连接过程顺利，这样才能保证数据流的稳定。",
        "id": 234,
        "target_term": "Connecting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到连接数对性能的影响。",
        "sentence_A": "在训练大规模模型时，我们需要特别关注 Connection 数量，因为它直接影响到模型的性能和效率。",
        "sentence_B": "在训练大规模模型时，我们需要特别关注连接数，因为它直接影响到模型的性能和效率。",
        "id": 235,
        "target_term": "Connection",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在模型训练过程中，团队讨论了如何更好地模拟人类的意识状态。",
        "sentence_A": "在训练这个模型时，我们讨论了如何更好地模拟人类的 Consciousnes 状态。",
        "sentence_B": "在训练这个模型时，我们讨论了如何更好地模拟人类的意识状态。",
        "id": 236,
        "target_term": "Consciousnes",
        "is_hardcore": true
    },
    {
        "topic": "Distributed Systems",
        "prefix": "在讨论分布式系统中的数据同步问题时",
        "sentence_A": "我们在设计分布式系统时，需要确保各个节点之间能够达成 Consensu，这样才能保证数据的一致性。",
        "sentence_B": "我们在设计分布式系统时，需要确保各个节点之间能够达成共识，这样才能保证数据的一致性。",
        "id": 237,
        "target_term": "Consensu",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时，",
        "sentence_A": "我们决定采取一个 more Conservative 的策略，逐步调整超参数，确保模型的稳定性和性能。",
        "sentence_B": "我们决定采取一个更为保守的策略，逐步调整超参数，确保模型的稳定性和性能。",
        "id": 238,
        "target_term": "more Conservative",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时，团队成员提到了一些重要的考量因素。",
        "sentence_A": "在优化模型训练的过程中，我们还需要考虑一些关键的 Consideration，比如计算资源的分配和数据集的平衡性。",
        "sentence_B": "在优化模型训练的过程中，我们还需要考虑一些关键的考量因素，比如计算资源的分配和数据集的平衡性。",
        "id": 239,
        "target_term": "Consideration",
        "is_hardcore": true
    },
    {
        "topic": "Data Consistency",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在准备训练数据时，要特别注意数据的 Consistency，确保每个批次的数据在特征和标签上保持一致。",
        "sentence_B": "我们在准备训练数据时，要特别注意数据的一致性，确保每个批次的数据在特征和标签上保持一致。",
        "id": 240,
        "target_term": "Consistency",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中数据一致性问题时",
        "sentence_A": "我们在模型训练时要确保数据的 Consistent，这样才能保证模型的稳定性和准确性。",
        "sentence_B": "我们在模型训练时要确保数据的一致性，这样才能保证模型的稳定性和准确性。",
        "id": 241,
        "target_term": "Consistent",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练模型时，需要设置一些参数为 Constant，这样可以确保某些值在整个训练过程中保持不变。",
        "sentence_B": "我们在训练模型时，需要设置一些参数为常量，这样可以确保某些值在整个训练过程中保持不变。",
        "id": 242,
        "target_term": "Constant",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "在训练这个模型时，我们需要注意一些 Constraint，比如内存限制和计算资源。",
        "sentence_B": "在训练这个模型时，我们需要注意一些约束条件，比如内存限制和计算资源。",
        "id": 243,
        "target_term": "Constraint",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练流程时",
        "sentence_A": "为了提高训练效率，我们决定用更高效的方法来 construct 数据集。",
        "sentence_B": "为了提高训练效率，我们决定用更高效的方法来构建数据集。",
        "id": 244,
        "target_term": "construct",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何构建一个高效的数据处理管道时，团队成员提到：",
        "sentence_A": "我们在 Constructing 这个数据处理管道时，需要确保每个步骤都尽可能高效。",
        "sentence_B": "我们在构建这个数据处理管道时，需要确保每个步骤都尽可能高效。",
        "id": 245,
        "target_term": "Constructing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，需要特别注意 Construction 阶段的优化，这直接影响到模型的性能。",
        "sentence_B": "我们在训练模型时，需要特别注意构建阶段的优化，这直接影响到模型的性能。",
        "id": 246,
        "target_term": "Construction",
        "is_hardcore": true
    },
    {
        "topic": "Data Preparation",
        "prefix": "在模型训练的数据准备阶段，我们讨论如何处理数据中的内容部分。",
        "sentence_A": "在处理数据集时，我们发现有些 Content 需要进行预处理，比如去除噪声和标准化文本。",
        "sentence_B": "在处理数据集时，我们发现有些内容需要进行预处理，比如去除噪声和标准化文本。",
        "id": 247,
        "target_term": "Content",
        "is_hardcore": true
    },
    {
        "topic": "Contour Detection in Image Processing",
        "prefix": "在进行图像处理时，我们经常需要检测图像中的轮廓。",
        "sentence_A": "我们在训练模型时，发现使用 Contour 检测算法能显著提高目标识别的准确性。",
        "sentence_B": "我们在训练模型时，发现使用轮廓检测算法能显著提高目标识别的准确性。",
        "id": 248,
        "target_term": "Contour",
        "is_hardcore": true
    },
    {
        "topic": "Contrast in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到对比学习的重要性。",
        "sentence_A": "在训练这个模型时，我们特别强调了 Contrast 的重要性，这对于提升模型的泛化能力非常关键。",
        "sentence_B": "在训练这个模型时，我们特别强调了对比学习的重要性，这对于提升模型的泛化能力非常关键。",
        "id": 249,
        "target_term": "Contrast",
        "is_hardcore": true
    },
    {
        "topic": "Contrastive Learning",
        "prefix": "在模型训练过程中，团队讨论了如何改进特征表示的方法。",
        "sentence_A": "我们可以尝试用 Contrastive 学习方法来提升模型的特征表示能力。",
        "sentence_B": "我们可以尝试使用对比学习方法来提升模型的特征表示能力。",
        "id": 250,
        "target_term": "Contrastive",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整超参数来优化模型性能。",
        "sentence_A": "在训练过程中，我们通过调整 learning rate 和 batch size 来对模型的 performance 进行 Control。",
        "sentence_B": "在训练过程中，我们通过调整学习率和批量大小来对模型的性能进行控制。",
        "id": 251,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的实验设计时",
        "sentence_A": "我们在实验中使用了 Controlled 环境来确保结果的可重复性。",
        "sentence_B": "我们在实验中使用了受控环境来确保结果的可重复性。",
        "id": 252,
        "target_term": "Controlled",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练框架的设计时",
        "sentence_A": "我们在设计模型训练框架时，需要考虑如何用 Controller 来管理各个训练任务的状态和调度。",
        "sentence_B": "我们在设计模型训练框架时，需要考虑如何用控制器来管理各个训练任务的状态和调度。",
        "id": 253,
        "target_term": "Controller",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常讨论如何提高转化率的问题。",
        "sentence_A": "在训练模型时，我们重点关注如何提高 Conversion 率，这直接影响到业务效果。",
        "sentence_B": "在训练模型时，我们重点关注如何提高转化率，这直接影响到业务效果。",
        "id": 254,
        "target_term": "Conversion",
        "is_hardcore": true
    },
    {
        "topic": "Model Conversion",
        "prefix": "在模型部署过程中，我们需要将训练好的模型转换为适合推理的格式。",
        "sentence_A": "我们使用了 TensorFlow 的 Converter 把训练好的模型转换成了 TensorRT 格式，这样在 GPU 上推理速度会快很多。",
        "sentence_B": "我们使用了 TensorFlow 的转换器将训练好的模型转换成了 TensorRT 格式，这样在 GPU 上推理速度会快很多。",
        "id": 255,
        "target_term": "TensorFlow",
        "is_hardcore": true
    },
    {
        "topic": "Convex Optimization in Model Training",
        "prefix": "在讨论模型训练优化时，团队成员提到了一个关键的数学概念。",
        "sentence_A": "在优化这个模型的时候，我们发现使用 Convex 函数能显著提升训练的稳定性。",
        "sentence_B": "在优化这个模型的时候，我们发现使用凸函数能显著提升训练的稳定性。",
        "id": 256,
        "target_term": "Convex",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们在训练模型时采用了 Cooperative 策略，这样可以更好地利用多个数据源的信息。",
        "sentence_B": "我们在训练模型时采用了合作策略，这样可以更好地利用多个数据源的信息。",
        "id": 257,
        "target_term": "Cooperative",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据对齐问题时",
        "sentence_A": "我们需要更好地 Coordinate 不同数据源，以确保模型训练的准确性和效率。",
        "sentence_B": "我们需要更好地协调不同数据源，以确保模型训练的准确性和效率。",
        "id": 258,
        "target_term": "Coordinate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练过程时",
        "sentence_A": "我们在使用 GitHub Copilot 时发现，它在代码生成和调试方面提供了很大的帮助，特别是在处理复杂的数据预处理任务时。",
        "sentence_B": "我们在使用 GitHub 代码助手时发现，它在代码生成和调试方面提供了很大的帮助，特别是在处理复杂的数据预处理任务时。",
        "id": 259,
        "target_term": "GitHub Copilot",
        "is_hardcore": true
    },
    {
        "topic": "Data Preparation",
        "prefix": "在模型训练前的数据准备阶段，团队讨论数据集的选择和处理。",
        "sentence_A": "在准备训练数据时，我们决定使用多个 Corpora 来增强模型的泛化能力。",
        "sentence_B": "在准备训练数据时，我们决定使用多个语料库来增强模型的泛化能力。",
        "id": 260,
        "target_term": "Corpora",
        "is_hardcore": true
    },
    {
        "topic": "Corpus Usage in Model Training",
        "prefix": "在讨论模型训练数据集时",
        "sentence_A": "我们在训练模型时，Corpus 的选择非常重要，它直接影响模型的性能。",
        "sentence_B": "我们在训练模型时，语料库的选择非常重要，它直接影响模型的性能。",
        "id": 261,
        "target_term": "Corpus",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要对数据进行校正。",
        "sentence_A": "在训练模型时，我们发现有些数据需要进行 Correction，以提高模型的准确性。",
        "sentence_B": "在训练模型时，我们发现有些数据需要进行校正，以提高模型的准确性。",
        "id": 262,
        "target_term": "Correction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常讨论模型的正确性问题。",
        "sentence_A": "在训练这个模型时，我们不仅要关注性能，还要确保它的 Correctnes，这样才能在实际应用中避免出错。",
        "sentence_B": "在训练这个模型时，我们不仅要关注性能，还要确保它的正确性，这样才能在实际应用中避免出错。",
        "id": 263,
        "target_term": "Correctnes",
        "is_hardcore": true
    },
    {
        "topic": "Data Analysis",
        "prefix": "在一次模型训练中，团队讨论数据集中的特征关系时",
        "sentence_A": "我们需要仔细检查这些特征之间的 Correlation，以确保模型不会因为冗余特征而过拟合。",
        "sentence_B": "我们需要仔细检查这些特征之间的相关性，以确保模型不会因为冗余特征而过拟合。",
        "id": 264,
        "target_term": "Correlation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源消耗时",
        "sentence_A": "这个模型的训练过程太 Costly 了，我们需要优化一下。",
        "sentence_B": "这个模型的训练过程太昂贵了，我们需要优化一下。",
        "id": 265,
        "target_term": "Costly",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在数据清洗阶段，团队讨论如何处理缺失值的问题。",
        "sentence_A": "我们在数据清洗阶段，发现有些字段的 missing Count 比较高，需要特别处理。",
        "sentence_B": "我们在数据清洗阶段，发现有些字段的缺失值数量比较高，需要特别处理。",
        "id": 266,
        "target_term": "missing Count",
        "is_hardcore": true
    },
    {
        "topic": "Counterfactual Reasoning in AI Models",
        "prefix": "在讨论模型训练的因果关系时",
        "sentence_A": "咱们这次的模型训练需要考虑 Counterfactual 的影响，这样才能更好地理解不同决策路径下的结果。",
        "sentence_B": "我们这次的模型训练需要考虑反事实的影响，这样才能更好地理解不同决策路径下的结果。",
        "id": 267,
        "target_term": "Counterfactual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的耦合问题时",
        "sentence_A": "我们在训练模型时，发现输入和输出的特征之间存在一些 Coupled 的关系，这导致了模型的性能下降。",
        "sentence_B": "我们在训练模型时，发现输入和输出的特征之间存在一些耦合的关系，这导致了模型的性能下降。",
        "id": 268,
        "target_term": "Coupled",
        "is_hardcore": true
    },
    {
        "topic": "Data Coverage in Model Training",
        "prefix": "在讨论模型训练数据集的选择时",
        "sentence_A": "我们在选择数据集的时候要确保 Coverage 足够广泛，这样才能让模型在实际应用中表现更好。",
        "sentence_B": "我们在选择数据集的时候要确保覆盖范围足够广泛，这样才能让模型在实际应用中表现更好。",
        "id": 269,
        "target_term": "Coverage",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了模型的创新性。",
        "sentence_A": "在训练这个模型时，我们特别强调了 Creativity，希望模型能够生成更多新颖的内容。",
        "sentence_B": "在训练这个模型时，我们特别强调了创新性，希望模型能够生成更多新颖的内容。",
        "id": 270,
        "target_term": "Creativity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到特征交叉的重要性。",
        "sentence_A": "在训练模型时，我们需要特别关注 feature Cros，这能显著提升模型的性能。",
        "sentence_B": "在训练模型时，我们需要特别关注特征交叉，这能显著提升模型的性能。",
        "id": 271,
        "target_term": "feature Cros",
        "is_hardcore": true
    },
    {
        "topic": "Genetic Algorithm in Model Optimization",
        "prefix": "在讨论如何优化遗传算法以提高模型训练效率时，",
        "sentence_A": "我们可以通过增加 Crossover 的频率来提高模型的多样性。",
        "sentence_B": "我们可以通过增加交叉的频率来提高模型的多样性。",
        "id": 272,
        "target_term": "Crossover",
        "is_hardcore": true
    },
    {
        "topic": "Crowdsourced Data for Model Training",
        "prefix": "在讨论如何优化模型训练数据时，团队提到使用众包数据来提高数据量和多样性。",
        "sentence_A": "我们这次可以考虑用 Crowdsourced 的数据来增加训练集的多样性和数量。",
        "sentence_B": "我们这次可以考虑使用众包的数据来增加训练集的多样性和数量。",
        "id": 273,
        "target_term": "Crowdsourced",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署的优化方案时",
        "sentence_A": "我们在部署模型时，使用了 Crystal 来优化推理速度，效果很不错。",
        "sentence_B": "我们在部署模型时，使用了晶体来优化推理速度，效果很不错。",
        "id": 274,
        "target_term": "Crystal",
        "is_hardcore": true
    },
    {
        "topic": "CUDA Integration in Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在训练这个大规模模型时，一定要确保充分利用 Cuda 的并行计算能力，这样可以大大加快训练速度。",
        "sentence_B": "我们在训练这个大规模模型时，一定要确保充分利用 CUDA 的并行计算能力，这样可以大大加快训练速度。",
        "id": 275,
        "target_term": "Cuda",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们这次的训练计划可以参考 Curriculum Learning 的方法，逐步增加任务难度。",
        "sentence_B": "我们这次的训练计划可以参考课程学习的方法，逐步增加任务难度。",
        "id": 276,
        "target_term": "Curriculum Learning",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练流程时",
        "sentence_A": "我们在每个 training cycle 里都需要确保数据的准确性和模型的稳定性。",
        "sentence_B": "我们在每个训练周期里都需要确保数据的准确性和模型的稳定性。",
        "id": 277,
        "target_term": "training cycle",
        "is_hardcore": true
    },
    {
        "topic": "Data Center Connectivity",
        "prefix": "在讨论模型训练的数据传输优化方案时",
        "sentence_A": "我们可以通过优化 DCC 来提高数据传输效率，减少训练时间。",
        "sentence_B": "我们可以通过优化数据中心连接（DCC）来提高数据传输效率，减少训练时间。",
        "id": 278,
        "target_term": "DCC",
        "is_hardcore": true
    },
    {
        "topic": "DCNN Model Optimization",
        "prefix": "在一次模型优化的讨论中，团队正在探讨如何提高模型的准确率和效率。",
        "sentence_A": "我们在优化这个 DCNN 模型的时候，发现有些层的参数可以进一步调整，以提高模型的准确率。",
        "sentence_B": "我们在优化这个深度卷积神经网络模型的时候，发现有些层的参数可以进一步调整，以提高模型的准确率。",
        "id": 279,
        "target_term": "DCNN",
        "is_hardcore": true
    },
    {
        "topic": "DCUNet Model Optimization",
        "prefix": "在讨论模型优化策略时",
        "sentence_A": "我们在训练 DCUNet 的时候发现，通过增加更多的卷积层可以显著提升模型的性能。",
        "sentence_B": "我们在训练深度卷积神经网络（DCUNet）时发现，通过增加更多的卷积层可以显著提升模型的性能。",
        "id": 280,
        "target_term": "DCUNet",
        "is_hardcore": true
    },
    {
        "topic": "DDPM Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化DDPM模型的性能。",
        "sentence_A": "我们在训练 DDPM 模型时，发现通过调整学习率可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练扩散概率模型（DDPM）时，发现通过调整学习率可以显著提高模型的收敛速度。",
        "id": 281,
        "target_term": "DDPM",
        "is_hardcore": true
    },
    {
        "topic": "DDPMS in Model Training",
        "prefix": "在讨论模型训练优化的过程中",
        "sentence_A": "我们在训练模型时，发现 DDPMS 能显著提高训练效率，尤其是在大规模数据集上。",
        "sentence_B": "我们在训练模型时，发现分布式数据并行模型优化器（DDPMS）能显著提高训练效率，尤其是在大规模数据集上。",
        "id": 282,
        "target_term": "DDPMS",
        "is_hardcore": true
    },
    {
        "topic": "Deep Deterministic Policy Gradient (DDPG)",
        "prefix": "在模型训练过程中，团队讨论如何优化算法性能。",
        "sentence_A": "我们这次用 DDPG 来优化控制策略，效果还不错，但还需要进一步调整超参数。",
        "sentence_B": "我们这次使用深度确定性策略梯度（DDPG）来优化控制策略，效果还不错，但还需要进一步调整超参数。",
        "id": 283,
        "target_term": "DDPG",
        "is_hardcore": true
    },
    {
        "topic": "Denoising",
        "prefix": "在一次模型训练的讨论会上，团队成员正在讨论数据预处理的方法。",
        "sentence_A": "我们这次的模型训练，Denoising 这一步特别重要，可以显著提升模型的性能。",
        "sentence_B": "我们这次的模型训练，去噪这一步特别重要，可以显著提升模型的性能。",
        "id": 284,
        "target_term": "Denoising",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到了一个关键步骤。",
        "sentence_A": "在训练这个复杂模型时，我们可以通过 Decomposition 将大问题拆分成小问题，这样更容易管理和优化。",
        "sentence_B": "在训练这个复杂模型时，我们可以通过分解将大问题拆分成小问题，这样更容易管理和优化。",
        "id": 285,
        "target_term": "Decomposition",
        "is_hardcore": true
    },
    {
        "topic": "Decoupled Architecture",
        "prefix": "在讨论模型推理优化时，团队成员提到需要解耦某些模块以提高系统的可维护性和扩展性。",
        "sentence_A": "我们需要将这些模块 Decoupled，以便更好地管理和优化每个部分。",
        "sentence_B": "我们需要将这些模块解耦，以便更好地管理和优化每个部分。",
        "id": 286,
        "target_term": "Decoupled",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一些问题。",
        "sentence_A": "在模型训练过程中，我们发现了一些 Defect，需要进一步优化。",
        "sentence_B": "在模型训练过程中，我们发现了一些缺陷，需要进一步优化。",
        "id": 287,
        "target_term": "Defect",
        "is_hardcore": true
    },
    {
        "topic": "Adversarial Machine Learning",
        "prefix": "在讨论模型对抗攻击的防御策略时，",
        "sentence_A": "我们需要考虑多种 Defense，以确保模型在面对不同类型的攻击时仍然保持鲁棒性。",
        "sentence_B": "我们需要考虑多种防御措施，以确保模型在面对不同类型的攻击时仍然保持鲁棒性。",
        "id": 288,
        "target_term": "Defense",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，同事提到一个关键概念",
        "sentence_A": "在训练这个模型时，我们首先需要明确每个标签的 Definition，这样才能确保模型的准确性和一致性。",
        "sentence_B": "在训练这个模型时，我们首先需要明确每个标签的定义，这样才能确保模型的准确性和一致性。",
        "id": 289,
        "target_term": "Definition",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中数据处理的问题时",
        "sentence_A": "我们在处理数据时遇到了 Deflation 问题，导致模型的性能下降。",
        "sentence_B": "我们在处理数据时遇到了数据缩减问题，导致模型的性能下降。",
        "id": 290,
        "target_term": "Deflation",
        "is_hardcore": true
    },
    {
        "topic": "Deformable Models in Computer Vision",
        "prefix": "在讨论模型的性能优化时",
        "sentence_A": "我们最近在研究如何通过 Deformable 卷积来提升模型的鲁棒性。",
        "sentence_B": "我们最近在研究如何通过可变形卷积来提升模型的鲁棒性。",
        "id": 291,
        "target_term": "Deformable",
        "is_hardcore": true
    },
    {
        "topic": "Model Degeneration",
        "prefix": "在模型训练过程中，我们发现模型性能出现了明显下降。",
        "sentence_A": "在进行多轮迭代后，我们发现模型出现了明显的 Degeneration，需要进一步优化。",
        "sentence_B": "在进行多轮迭代后，我们发现模型出现了明显的退化，需要进一步优化。",
        "id": 292,
        "target_term": "Degeneration",
        "is_hardcore": true
    },
    {
        "topic": "Graph Theory in AI Models",
        "prefix": "在讨论图神经网络的结构时",
        "sentence_A": "我们需要注意每个节点的 Degree，这直接影响到信息传递的效率。",
        "sentence_B": "我们需要注意每个节点的度，这直接影响到信息传递的效率。",
        "id": 293,
        "target_term": "Degree",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型上线的过程中",
        "sentence_A": "我们在 Delivering 模型的时候，需要确保性能和稳定性。",
        "sentence_B": "我们在部署模型的时候，需要确保性能和稳定性。",
        "id": 294,
        "target_term": "Delivering",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署计划时",
        "sentence_A": "我们这次的 delivery 要确保模型在生产环境中的稳定性和性能。",
        "sentence_B": "我们这次的交付要确保模型在生产环境中的稳定性和性能。",
        "id": 295,
        "target_term": "delivery",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的改进时，一位资深AI算法工程师提到：",
        "sentence_A": "我们可以通过调整 Delta 来优化模型的收敛速度。",
        "sentence_B": "我们可以通过调整增量来优化模型的收敛速度。",
        "id": 296,
        "target_term": "Delta",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在项目评审会议上，团队成员讨论了模型的初步展示版本。",
        "sentence_A": "我们已经准备好了这个模型的 Demo，明天可以给大家展示一下。",
        "sentence_B": "我们已经准备好了这个模型的演示版本，明天可以给大家展示一下。",
        "id": 297,
        "target_term": "Demo",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在团队会议中讨论模型的展示效果",
        "sentence_A": "我们在下次团队会议中需要准备一个 Demonstration，让每个人都对模型的最新进展有直观的了解。",
        "sentence_B": "我们在下次团队会议中需要准备一个演示，让每个人都对模型的最新进展有直观的了解。",
        "id": 298,
        "target_term": "Demonstration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的依赖关系时",
        "sentence_A": "我们在训练这个模型的时候，需要特别注意 Dependence 的管理，确保所有依赖项都正确安装。",
        "sentence_B": "我们在训练这个模型的时候，需要特别注意依赖关系的管理，确保所有依赖项都正确安装。",
        "id": 299,
        "target_term": "Dependence",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时，团队成员提到依赖管理的问题。",
        "sentence_A": "在部署模型时，我们需要注意各种 Dependency，确保所有的库和环境都一致。",
        "sentence_B": "在部署模型时，我们需要注意各种依赖，确保所有的库和环境都一致。",
        "id": 300,
        "target_term": "Dependency",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到某些参数的依赖关系。",
        "sentence_A": "在训练过程中，我们发现有些参数是 Dependent 的，需要特别注意调整。",
        "sentence_B": "在训练过程中，我们发现有些参数是依赖的，需要特别注意调整。",
        "id": 301,
        "target_term": "Dependent",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何从现有数据中提取有用信息时",
        "sentence_A": "我们可以通过不同的算法来 derive 有用的特征，这样可以提高模型的准确性。",
        "sentence_B": "我们可以通过不同的算法来推导出有用的特征，这样可以提高模型的准确性。",
        "id": 302,
        "target_term": "derive",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "在这次数据预处理中，我们从原始数据中提取了大量 Derived 特征，这些特征对模型的性能提升非常明显。",
        "sentence_B": "在这次数据预处理中，我们从原始数据中提取了大量衍生特征，这些特征对模型的性能提升非常明显。",
        "id": 303,
        "target_term": "Derived",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们经常需要对数据进行描述和预处理。",
        "sentence_A": "在数据清洗过程中，我们经常需要对数据进行 Describing 和预处理。",
        "sentence_B": "在数据清洗过程中，我们经常需要对数据进行描述和预处理。",
        "id": 304,
        "target_term": "Describing",
        "is_hardcore": true
    },
    {
        "topic": "Descriptive Statistics",
        "prefix": "在数据清洗阶段，团队讨论如何更有效地处理数据集中的异常值和缺失值。",
        "sentence_A": "在数据清洗阶段，我们需要用一些 Descriptive 统计方法来识别和处理异常值和缺失值。",
        "sentence_B": "在数据清洗阶段，我们需要用一些描述性统计方法来识别和处理异常值和缺失值。",
        "id": 305,
        "target_term": "Descriptive",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，讨论模型参数的详细设置",
        "sentence_A": "我们在训练模型时，需要特别注意参数的 Detail，这样才能确保模型的性能。",
        "sentence_B": "我们在训练模型时，需要特别注意参数的详细设置，这样才能确保模型的性能。",
        "id": 306,
        "target_term": "Detail",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在模型训练过程中，我们遇到了一个挑战",
        "sentence_A": "在训练过程中，我们发现 Detecting 小目标物体的效果不理想，需要进一步优化模型。",
        "sentence_B": "在训练过程中，我们发现检测小目标物体的效果不理想，需要进一步优化模型。",
        "id": 307,
        "target_term": "Detecting",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在模型训练过程中，我们遇到了一些问题。",
        "sentence_A": "在训练我们的模型时，我们发现 Detection 的精度在某些场景下不太理想。",
        "sentence_B": "在训练我们的模型时，我们发现目标检测的精度在某些场景下不太理想。",
        "id": 308,
        "target_term": "Detection",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在模型训练过程中，团队讨论了不同类型的检测器的性能。",
        "sentence_A": "在我们的模型训练过程中，我们发现使用 YOLOv5 作为 Detector 的效果比 Faster R-CNN 更好。",
        "sentence_B": "在我们的模型训练过程中，我们发现使用 YOLOv5 作为检测器的效果比 Faster R-CNN 更好。",
        "id": 309,
        "target_term": "YOLOv5",
        "is_hardcore": true
    },
    {
        "topic": "Matrix Operations in AI Models",
        "prefix": "在讨论模型训练中矩阵运算的重要性时",
        "sentence_A": "在模型训练中，正确处理 Determinant 对于矩阵运算的稳定性非常重要。",
        "sentence_B": "在模型训练中，正确处理行列式对于矩阵运算的稳定性非常重要。",
        "id": 310,
        "target_term": "Determinant",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时，团队成员提到了一个关键概念",
        "sentence_A": "我们在训练模型时，需要确保 Determinism，这样才能保证每次训练的结果一致。",
        "sentence_B": "我们在训练模型时，需要确保确定性，这样才能保证每次训练的结果一致。",
        "id": 311,
        "target_term": "Determinism",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时，同事们提到一个关键概念。",
        "sentence_A": "咱们在模型训练过程中要特别注意 Deterministic，确保每次训练的结果都是一致的。",
        "sentence_B": "我们在模型训练过程中要特别注意确定性，确保每次训练的结果都是一致的。",
        "id": 312,
        "target_term": "Deterministic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的进度时",
        "sentence_A": "我们在 Development 阶段遇到了一些挑战，特别是在数据预处理和模型调参方面。",
        "sentence_B": "我们在开发阶段遇到了一些挑战，特别是在数据预处理和模型调参方面。",
        "id": 313,
        "target_term": "Development",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行数据清洗时，我们发现了一些异常值。",
        "sentence_A": "在数据清洗阶段，我们发现了一些显著的 Deviation，需要进一步处理。",
        "sentence_B": "在数据清洗阶段，我们发现了一些显著的偏差，需要进一步处理。",
        "id": 314,
        "target_term": "Deviation",
        "is_hardcore": true
    },
    {
        "topic": "Matrix Operations in AI",
        "prefix": "在讨论模型训练中的矩阵操作时",
        "sentence_A": "这次模型训练中，我们发现使用 Diagonal 矩阵能显著提高计算效率。",
        "sentence_B": "在这次模型训练中，我们发现使用对角矩阵能显著提高计算效率。",
        "id": 315,
        "target_term": "Diagonal",
        "is_hardcore": true
    },
    {
        "topic": "Data Structures in AI Development",
        "prefix": "在讨论模型训练时的数据结构优化",
        "sentence_A": "我们在处理模型输入时，经常需要将数据转换成 Dict 格式，以便于模型更好地理解和处理。",
        "sentence_B": "我们在处理模型输入时，经常需要将数据转换成字典格式，以便于模型更好地理解和处理。",
        "id": 316,
        "target_term": "Dict",
        "is_hardcore": true
    },
    {
        "topic": "Data Structures in AI Development",
        "prefix": "在讨论模型训练的数据处理时",
        "sentence_A": "我们在数据预处理阶段使用了 Dict 来高效管理特征和标签。",
        "sentence_B": "我们在数据预处理阶段使用了字典来高效管理特征和标签。",
        "id": 317,
        "target_term": "Dict",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练中的超参数选择时",
        "sentence_A": "我们在调整学习率时要注意，不同的学习率对模型的收敛速度和最终性能的 difference 很大。",
        "sentence_B": "我们在调整学习率时要注意，不同的学习率对模型的收敛速度和最终性能的差异很大。",
        "id": 318,
        "target_term": "difference",
        "is_hardcore": true
    },
    {
        "topic": "Differential Privacy in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到如何处理数据隐私问题。",
        "sentence_A": "在训练模型时，我们使用了 Differential 隐私技术来保护用户的个人信息。",
        "sentence_B": "在训练模型时，我们使用了差分隐私技术来保护用户的个人信息。",
        "id": 319,
        "target_term": "Differential",
        "is_hardcore": true
    },
    {
        "topic": "Diffusion Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化扩散模型的性能。",
        "sentence_A": "在训练过程中，我们注意到 Diffusion 模型的性能在大规模数据集上有所提升。",
        "sentence_B": "在训练过程中，我们注意到扩散模型的性能在大规模数据集上有所提升。",
        "id": 320,
        "target_term": "Diffusion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练的数据集时",
        "sentence_A": "我们在准备训练集的时候，需要确保 Digital 数据的质量，这样才能提高模型的准确性。",
        "sentence_B": "我们在准备训练集的时候，需要确保数字数据的质量，这样才能提高模型的准确性。",
        "id": 321,
        "target_term": "Digital",
        "is_hardcore": true
    },
    {
        "topic": "Dilated Convolution",
        "prefix": "在讨论模型优化策略时，团队成员提到使用膨胀卷积来增加感受野。",
        "sentence_A": "我们在模型训练中使用了 Dilated 卷积，这样可以有效增加感受野，而不增加参数量。",
        "sentence_B": "我们在模型训练中使用了膨胀卷积，这样可以有效增加感受野，而不增加参数量。",
        "id": 322,
        "target_term": "Dilated",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在设置模型的输入时，需要确保每个输入的 dimension 是正确的，这样才能保证模型的训练效果。",
        "sentence_B": "我们在设置模型的输入时，需要确保每个输入的维度是正确的，这样才能保证模型的训练效果。",
        "id": 323,
        "target_term": "dimension",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论特征工程对模型性能的影响时",
        "sentence_A": "我们在处理高 Dimensional 数据时，需要特别注意特征选择和降维方法的选择，否则模型可能会过拟合。",
        "sentence_B": "我们在处理高维数据时，需要特别注意特征选择和降维方法的选择，否则模型可能会过拟合。",
        "id": 324,
        "target_term": "Dimensional",
        "is_hardcore": true
    },
    {
        "topic": "Dimensionality Reduction in Machine Learning",
        "prefix": "在讨论模型训练时，团队成员提到高维数据的问题。",
        "sentence_A": "在处理高维数据时，我们通常会采用一些方法来降低 dimensionality，这样可以提高模型的训练效率和泛化能力。",
        "sentence_B": "在处理高维数据时，我们通常会采用一些方法来降低维度，这样可以提高模型的训练效率和泛化能力。",
        "id": 325,
        "target_term": "dimensionality",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的方向时，团队需要明确目标和策略。",
        "sentence_A": "在确定模型训练的 Direction 时，我们需要考虑当前数据集的特点和业务需求。",
        "sentence_B": "在确定模型训练的方向时，我们需要考虑当前数据集的特点和业务需求。",
        "id": 326,
        "target_term": "Direction",
        "is_hardcore": true
    },
    {
        "topic": "NLP and Text Analysis",
        "prefix": "在模型训练过程中，我们讨论了如何处理和分析大量文本数据的问题。",
        "sentence_A": "在训练模型时，我们发现处理 Discourse 需要特别小心，因为不同的 Discourse 类型对模型的性能影响很大。",
        "sentence_B": "在训练模型时，我们发现处理话语需要特别小心，因为不同类型的话语对模型的性能影响很大。",
        "id": 327,
        "target_term": "Discourse",
        "is_hardcore": true
    },
    {
        "topic": "Discrete Variables in Machine Learning",
        "prefix": "在讨论模型训练时，团队成员提到离散变量的处理方法。",
        "sentence_A": "在处理特征时，我们通常需要考虑如何处理这些 discrete 变量，比如类别数据。",
        "sentence_B": "在处理特征时，我们通常需要考虑如何处理这些离散变量，比如类别数据。",
        "id": 328,
        "target_term": "discrete",
        "is_hardcore": true
    },
    {
        "topic": "Discriminant Analysis",
        "prefix": "在模型训练过程中讨论特征选择的问题",
        "sentence_A": "在训练这个分类模型时，我们发现使用 discriminant 分析来选择特征，可以显著提高模型的性能。",
        "sentence_B": "在训练这个分类模型时，我们发现使用判别分析来选择特征，可以显著提高模型的性能。",
        "id": 329,
        "target_term": "discriminant",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练这个模型时，发现使用 Discriminative 优化方法能够显著提升分类准确率。",
        "sentence_B": "我们在训练这个模型时，发现使用判别优化方法能够显著提升分类准确率。",
        "id": 330,
        "target_term": "Discriminative",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们发现了一些数据集的问题。",
        "sentence_A": "我们在数据清洗时发现，这几个数据集是完全 Disjoint 的，没有重叠的部分。",
        "sentence_B": "我们在数据清洗时发现，这几个数据集是完全不相交的，没有重叠的部分。",
        "id": 331,
        "target_term": "Disjoint",
        "is_hardcore": true
    },
    {
        "topic": "Data Storage and Management",
        "prefix": "在讨论模型训练数据存储时",
        "sentence_A": "我们在训练模型时，需要确保 Disk 的读写速度足够快，以避免成为瓶颈。",
        "sentence_B": "我们在训练模型时，需要确保磁盘的读写速度足够快，以避免成为瓶颈。",
        "id": 332,
        "target_term": "Disk",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化时，团队成员提到如何有效处理请求分发的问题。",
        "sentence_A": "我们在优化模型推理时，需要考虑如何更高效地处理请求的 dispatch，确保每个请求都能被快速响应。",
        "sentence_B": "我们在优化模型推理时，需要考虑如何更高效地处理请求的分发，确保每个请求都能被快速响应。",
        "id": 333,
        "target_term": "dispatch",
        "is_hardcore": true
    },
    {
        "topic": "Data Distribution and Management",
        "prefix": "在模型训练过程中，我们讨论了数据分布的问题。",
        "sentence_A": "在训练模型时，我们需要注意数据的 Dispersal，确保每个节点上的数据分布均匀，以提高训练效率。",
        "sentence_B": "在训练模型时，我们需要注意数据的分散，确保每个节点上的数据分布均匀，以提高训练效率。",
        "id": 334,
        "target_term": "Dispersal",
        "is_hardcore": true
    },
    {
        "topic": "Distance Calculation in AI Models",
        "prefix": "在讨论模型训练中的相似度计算时",
        "sentence_A": "在训练这个推荐模型时，我们使用了不同的 Distance 度量方法来评估用户之间的相似度。",
        "sentence_B": "在训练这个推荐模型时，我们使用了不同的距离度量方法来评估用户之间的相似度。",
        "id": 335,
        "target_term": "Distance",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们讨论如何处理重复数据的问题。",
        "sentence_A": "我们在数据清洗阶段发现了很多重复的记录，需要确保每个用户的数据都是 distinct 的。",
        "sentence_B": "我们在数据清洗阶段发现了很多重复的记录，需要确保每个用户的数据都是唯一的。",
        "id": 336,
        "target_term": "distinct",
        "is_hardcore": true
    },
    {
        "topic": "Data Distribution in Model Training",
        "prefix": "在讨论模型训练数据的分布问题时",
        "sentence_A": "我们需要关注数据的 Distribution，确保训练集和测试集的分布一致。",
        "sentence_B": "我们需要关注数据的分布，确保训练集和测试集的分布一致。",
        "id": 337,
        "target_term": "Distribution",
        "is_hardcore": true
    },
    {
        "topic": "Distributions in Model Training",
        "prefix": "在讨论模型训练数据的分布时",
        "sentence_A": "我们在训练模型时，需要特别关注 Distribution，确保数据的分布能够代表实际应用场景。",
        "sentence_B": "我们在训练模型时，需要特别关注数据分布，确保数据的分布能够代表实际应用场景。",
        "id": 338,
        "target_term": "Distribution",
        "is_hardcore": true
    },
    {
        "topic": "Diversity in Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们需要确保数据集的 Diversity，这样才能保证模型的泛化能力。",
        "sentence_B": "我们需要确保数据集的多样性，这样才能保证模型的泛化能力。",
        "id": 339,
        "target_term": "Diversity",
        "is_hardcore": true
    },
    {
        "topic": "Document Processing",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "在处理训练数据时，我们需要确保每个 Document 都被正确地标注了类别。",
        "sentence_B": "在处理训练数据时，我们需要确保每个文档都被正确地标注了类别。",
        "id": 340,
        "target_term": "Document",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在进行模型训练前的数据准备阶段，团队讨论如何处理大量的文本数据。",
        "sentence_A": "我们在处理这些 Document 时，需要确保数据的一致性和准确性。",
        "sentence_B": "我们在处理这些文档时，需要确保数据的一致性和准确性。",
        "id": 341,
        "target_term": "Document",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数调整时",
        "sentence_A": "我们这次可以尝试把 learning rate Double 一下，看看效果如何。",
        "sentence_B": "我们这次可以尝试把学习率翻倍，看看效果如何。",
        "id": 342,
        "target_term": "learning rate Double",
        "is_hardcore": true
    },
    {
        "topic": "Dropout",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以在训练过程中使用 Dropout 技术来防止过拟合。",
        "sentence_B": "我们可以在训练过程中使用丢弃技术来防止过拟合。",
        "id": 343,
        "target_term": "Dropout",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们需要考虑使用 Dual 任务来提高模型的泛化能力。",
        "sentence_B": "我们需要考虑使用双重任务来提高模型的泛化能力。",
        "id": 344,
        "target_term": "Dual",
        "is_hardcore": true
    },
    {
        "topic": "Dubins Path in Path Planning",
        "prefix": "在路径规划的模型训练过程中，我们遇到了一个有趣的问题。",
        "sentence_A": "我们在路径规划的模型训练中，发现使用 Dubin 路径可以显著减少计算复杂度。",
        "sentence_B": "我们在路径规划的模型训练中，发现使用杜宾斯路径可以显著减少计算复杂度。",
        "id": 345,
        "target_term": "Dubin",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时间时",
        "sentence_A": "这次训练的 Duration 比上次长多了，可能是因为数据量增加了。",
        "sentence_B": "这次训练的持续时间比上次长多了，可能是因为数据量增加了。",
        "id": 346,
        "target_term": "Duration",
        "is_hardcore": true
    },
    {
        "topic": "ECG Data Processing",
        "prefix": "在讨论如何优化心电图数据的预处理流程时",
        "sentence_A": "我们在处理 ECG 数据时，要特别注意噪声的过滤，这样才能保证模型的准确性。",
        "sentence_B": "我们在处理心电图数据时，要特别注意噪声的过滤，这样才能保证模型的准确性。",
        "id": 347,
        "target_term": "ECG",
        "is_hardcore": true
    },
    {
        "topic": "Error Correction Mechanism",
        "prefix": "在讨论模型训练中的错误修正机制时",
        "sentence_A": "我们在模型训练中引入了 ECM，这大大提高了模型的鲁棒性。",
        "sentence_B": "我们在模型训练中引入了错误修正机制（ECM），这大大提高了模型的鲁棒性。",
        "id": 348,
        "target_term": "ECM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到一个关键概念。",
        "sentence_A": "我们在进行模型训练时，需要特别注意 ECT 的优化，这样才能确保模型在不同数据集上的表现更加稳定。",
        "sentence_B": "我们在进行模型训练时，需要特别注意早期收敛时间（ECT）的优化，这样才能确保模型在不同数据集上的表现更加稳定。",
        "id": 349,
        "target_term": "ECT",
        "is_hardcore": true
    },
    {
        "topic": "EEG Data Processing",
        "prefix": "在讨论如何优化脑电图数据处理时",
        "sentence_A": "我们在处理 EEG 数据时，发现噪声过滤的效果还需要进一步优化。",
        "sentence_B": "我们在处理脑电图数据时，发现噪声过滤的效果还需要进一步优化。",
        "id": 350,
        "target_term": "EEG",
        "is_hardcore": true
    },
    {
        "topic": "Expectation Maximization",
        "prefix": "在模型训练过程中，我们经常使用EM算法来处理含有隐变量的数据。",
        "sentence_A": "在处理这个数据集时，我们决定用 EM 算法来优化模型的参数。",
        "sentence_B": "在处理这个数据集时，我们决定用期望最大化算法来优化模型的参数。",
        "id": 351,
        "target_term": "EM",
        "is_hardcore": false
    },
    {
        "topic": "EMA in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在模型训练中使用了 EMA，这样可以平滑模型的参数更新，提高模型的稳定性和收敛速度。",
        "sentence_B": "我们在模型训练中使用了指数移动平均（EMA），这样可以平滑模型的参数更新，提高模型的稳定性和收敛速度。",
        "id": 352,
        "target_term": "EMA",
        "is_hardcore": true
    },
    {
        "topic": "Explainable Neural Networks",
        "prefix": "在讨论模型的可解释性时",
        "sentence_A": "我们在模型训练中使用了 ENN，这样可以更好地理解模型的决策过程。",
        "sentence_B": "我们在模型训练中使用了可解释神经网络，这样可以更好地理解模型的决策过程。",
        "id": 353,
        "target_term": "ENN",
        "is_hardcore": true
    },
    {
        "topic": "Energy-based Neural Networks",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "在训练 ENN 的过程中，我们发现使用不同的激活函数可以显著影响模型的收敛速度。",
        "sentence_B": "在训练能量神经网络（ENNs）的过程中，我们发现使用不同的激活函数可以显著影响模型的收敛速度。",
        "id": 354,
        "target_term": "ENN",
        "is_hardcore": true
    },
    {
        "topic": "Entity Prediction and Recognition",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化模型的实体预测和识别能力。",
        "sentence_A": "我们在训练模型时，EPR 的准确率提升遇到了瓶颈，需要重新审视数据集和模型架构。",
        "sentence_B": "我们在训练模型时，实体预测和识别（EPR）的准确率提升遇到了瓶颈，需要重新审视数据集和模型架构。",
        "id": 355,
        "target_term": "EPR",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了一个关键算法的优化问题。",
        "sentence_A": "在训练这个模型时，我们发现使用 EULER 方法可以显著提高收敛速度。",
        "sentence_B": "在训练这个模型时，我们发现使用欧拉方法可以显著提高收敛速度。",
        "id": 356,
        "target_term": "EULER",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练完成后，团队开会讨论模型的表现。",
        "sentence_A": "在今天的会议上，我们重点讨论了模型的 EVALUATION 结果，看看它在不同数据集上的表现如何。",
        "sentence_B": "在今天的会议上，我们重点讨论了模型的评估结果，看看它在不同数据集上的表现如何。",
        "id": 357,
        "target_term": "EVALUATION",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到一个常见的问题。",
        "sentence_A": "我们在训练模型时遇到了一个 Echo 问题，导致模型的输出有明显的重复性。",
        "sentence_B": "我们在训练模型时遇到了一个回声问题，导致模型的输出有明显的重复性。",
        "id": 358,
        "target_term": "Echo",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源优化时",
        "sentence_A": "我们在训练模型时，需要考虑 Economie 规模效应，以降低计算成本。",
        "sentence_B": "我们在训练模型时，需要考虑规模经济效应，以降低计算成本。",
        "id": 359,
        "target_term": "Economie",
        "is_hardcore": true
    },
    {
        "topic": "Text Editing",
        "prefix": "在模型训练过程中，我们经常需要使用编辑器来调整代码和配置文件。",
        "sentence_A": "我们通常用 VSCode Editor 来调整模型的配置文件，因为它有很好的代码高亮和自动补全功能。",
        "sentence_B": "我们通常使用 VSCode 编辑器来调整模型的配置文件，因为它有很好的代码高亮和自动补全功能。",
        "id": 360,
        "target_term": "VSCode Editor",
        "is_hardcore": true
    },
    {
        "topic": "Data Encoding in Model Training",
        "prefix": "在讨论模型训练数据预处理时",
        "sentence_A": "我们在处理训练数据时，需要特别注意 Encoding 的方式，因为这直接影响到模型的输入质量和训练效果。",
        "sentence_B": "我们在处理训练数据时，需要特别注意编码的方式，因为这直接影响到模型的输入质量和训练效果。",
        "id": 361,
        "target_term": "Encoding",
        "is_hardcore": true
    },
    {
        "topic": "Data Encoding and Representation",
        "prefix": "在模型训练过程中，我们遇到了一个关于数据表示的问题。",
        "sentence_A": "我们发现，在处理文本数据时，不同的 Encoding 对模型的性能影响很大。",
        "sentence_B": "我们发现，在处理文本数据时，不同的编码方式对模型的性能影响很大。",
        "id": 362,
        "target_term": "Encoding",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型架构时，团队成员提出了一个关于Encoder的优化方案。",
        "sentence_A": "在我们的模型训练中，我们需要优化 Encoder 的性能，以提高整体的推理速度。",
        "sentence_B": "在我们的模型训练中，我们需要优化编码器的性能，以提高整体的推理速度。",
        "id": 363,
        "target_term": "Encoder",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集配置时",
        "sentence_A": "我们在数据集配置中增加了一个新的参数，叫做 Endowment，用来增强模型的初始能力。",
        "sentence_B": "我们在数据集配置中增加了一个新的参数，叫做初始能力，用来增强模型的初始能力。",
        "id": 364,
        "target_term": "Endowment",
        "is_hardcore": true
    },
    {
        "topic": "Ensemble Learning",
        "prefix": "在讨论模型融合技术时，团队成员提到：",
        "sentence_A": "我们在训练模型时，用到了 Ensemble 方法，效果提升很明显。",
        "sentence_B": "我们在训练模型时，使用了集成学习方法，效果提升非常明显。",
        "id": 365,
        "target_term": "Ensemble",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Inference",
        "prefix": "在模型训练过程中，我们需要处理大量的文本数据来优化模型的性能。",
        "sentence_A": "在训练模型时，我们发现某些句子之间存在明显的 Entailment 关系，这有助于提高模型的准确性。",
        "sentence_B": "在训练模型时，我们发现某些句子之间存在明显的蕴含关系，这有助于提高模型的准确性。",
        "id": 366,
        "target_term": "Entailment",
        "is_hardcore": true
    },
    {
        "topic": "Entity Recognition",
        "prefix": "在模型训练过程中，我们讨论如何提高实体识别的准确性。",
        "sentence_A": "在训练这个模型时，我们发现如果能更好地处理 Entity 的上下文信息，识别准确率会有显著提升。",
        "sentence_B": "在训练这个模型时，我们发现如果能更好地处理实体的上下文信息，识别准确率会有显著提升。",
        "id": 367,
        "target_term": "Entity",
        "is_hardcore": true
    },
    {
        "topic": "Entropy in Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到熵的使用",
        "sentence_A": "在训练这个分类模型时，我们发现使用 Entropy 作为损失函数的效果比其他方法要好。",
        "sentence_B": "在训练这个分类模型时，我们发现使用熵作为损失函数的效果比其他方法要好。",
        "id": 368,
        "target_term": "Entropy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们需要对数据集进行处理。",
        "sentence_A": "在训练模型时，我们需要对数据集进行 Enumerating，确保每个样本都能被正确处理。",
        "sentence_B": "在训练模型时，我们需要对数据集进行枚举，确保每个样本都能被正确处理。",
        "id": 369,
        "target_term": "Enumerating",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了环境配置的问题。",
        "sentence_A": "我们在讨论如何优化模型训练的 Environment，以确保训练过程的稳定性和效率。",
        "sentence_B": "我们在讨论如何优化模型训练的环境配置，以确保训练过程的稳定性和效率。",
        "id": 370,
        "target_term": "Environment",
        "is_hardcore": true
    },
    {
        "topic": "Equivariance in Neural Networks",
        "prefix": "在讨论模型的不变性和等变性时，同事提到：",
        "sentence_A": "我们在设计模型时，需要特别关注 Equivariance，确保输入的变换能导致输出的相应变换。",
        "sentence_B": "我们在设计模型时，需要特别关注等变性，确保输入的变换能导致输出的相应变换。",
        "id": 371,
        "target_term": "Equivariance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们需要对某些参数进行初步评估。",
        "sentence_A": "在训练模型时，我们需要 Estimating 一些关键参数的初始值，以确保训练过程的稳定性和收敛性。",
        "sentence_B": "在训练模型时，我们需要估计一些关键参数的初始值，以确保训练过程的稳定性和收敛性。",
        "id": 372,
        "target_term": "Estimating",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员在讨论如何优化模型的参数估计过程。",
        "sentence_A": "在模型训练过程中，我们需要对参数的 Estimation 进行优化，以提高模型的准确性和泛化能力。",
        "sentence_B": "在模型训练过程中，我们需要对参数的估计进行优化，以提高模型的准确性和泛化能力。",
        "id": 373,
        "target_term": "Estimation",
        "is_hardcore": true
    },
    {
        "topic": "Estimator in Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到使用Estimator来简化训练流程。",
        "sentence_A": "我们这次模型训练用了 TensorFlow 的 Estimator，感觉流程简化了不少。",
        "sentence_B": "我们这次模型训练使用了 TensorFlow 的估计器，感觉流程简化了不少。",
        "id": 374,
        "target_term": "TensorFlow",
        "is_hardcore": true
    },
    {
        "topic": "Euclidean Distance in Model Training",
        "prefix": "在讨论模型训练中的距离度量时",
        "sentence_A": "我们在计算特征向量之间的相似度时，通常会用到 Euclidean 距离。",
        "sentence_B": "我们在计算特征向量之间的相似度时，通常会用到欧氏距离。",
        "id": 375,
        "target_term": "Euclidean",
        "is_hardcore": true
    },
    {
        "topic": "Evasion in Model Training",
        "prefix": "在讨论模型训练中如何处理对抗性样本时",
        "sentence_A": "我们在模型训练中特别注意 Evasion 攻击，确保模型在面对对抗性样本时依然能保持较高的鲁棒性。",
        "sentence_B": "我们在模型训练中特别注意规避攻击，确保模型在面对对抗性样本时依然能保持较高的鲁棒性。",
        "id": 376,
        "target_term": "Evasion",
        "is_hardcore": true
    },
    {
        "topic": "Event Handling in Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理各种事件，例如模型的性能指标变化等。",
        "sentence_A": "在训练过程中，我们经常需要处理各种 Event，比如模型的性能指标变化。",
        "sentence_B": "在训练过程中，我们经常需要处理各种事件，比如模型的性能指标变化。",
        "id": 377,
        "target_term": "Event",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的质量时",
        "sentence_A": "我们需要注意，训练数据中的每个样本都要有足够的 Evidence 来支持模型的学习。",
        "sentence_B": "我们需要注意，训练数据中的每个样本都要有足够的证据来支持模型的学习。",
        "id": 378,
        "target_term": "Evidence",
        "is_hardcore": true
    },
    {
        "topic": "Model Evolution",
        "prefix": "在讨论模型迭代的过程中，团队成员提到模型的持续改进。",
        "sentence_A": "我们的模型正在不断 Evolving，每次迭代都能看到显著的性能提升。",
        "sentence_B": "我们的模型正在不断进化，每次迭代都能看到显著的性能提升。",
        "id": 379,
        "target_term": "Evolving",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的精度问题时",
        "sentence_A": "我们这次训练的模型在验证集上的表现还是不错的，特别是在一些关键指标上，几乎达到了 Exact 的水平。",
        "sentence_B": "我们这次训练的模型在验证集上的表现还是不错的，特别是在一些关键指标上，几乎达到了精确的水平。",
        "id": 380,
        "target_term": "Exact",
        "is_hardcore": true
    },
    {
        "topic": "Error Handling",
        "prefix": "在模型训练过程中，我们经常需要处理各种异常情况，确保模型的稳定性和可靠性。",
        "sentence_A": "在模型训练过程中，如果出现了 Exception，我们需要及时记录日志并进行处理，以避免训练中断。",
        "sentence_B": "在模型训练过程中，如果出现了异常，我们需要及时记录日志并进行处理，以避免训练中断。",
        "id": 381,
        "target_term": "Exception",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，团队讨论了一个重要的数据处理策略。",
        "sentence_A": "在数据清洗阶段，我们需要特别注意数据的 Exclusion，确保不包含任何敏感信息。",
        "sentence_B": "在数据清洗阶段，我们需要特别注意数据的排除，确保不包含任何敏感信息。",
        "id": 382,
        "target_term": "Exclusion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们需要优化 Execution 过程中的资源分配，以提高训练效率。",
        "sentence_B": "我们需要优化执行过程中的资源分配，以提高训练效率。",
        "id": 383,
        "target_term": "Execution",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时，团队成员提到了一个关键概念。",
        "sentence_A": "我们在做模型训练的时候，需要考虑用 Exhaustive 搜索来找到最优的超参数组合。",
        "sentence_B": "我们在进行模型训练时，需要考虑使用穷尽搜索来找到最优的超参数组合。",
        "id": 384,
        "target_term": "Exhaustive",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretability",
        "prefix": "在讨论模型可解释性时",
        "sentence_A": "我们这次模型训练的时候，一定要注意生成详细的 Explanation，这样可以帮助我们更好地理解模型的决策过程。",
        "sentence_B": "我们这次模型训练的时候，一定要注意生成详细的解释，这样可以帮助我们更好地理解模型的决策过程。",
        "id": 385,
        "target_term": "Explanation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时，团队成员提到了显式参数的重要性。",
        "sentence_A": "在训练模型时，我们需要设置一些 explicit 参数来确保模型的稳定性和性能。",
        "sentence_B": "在训练模型时，我们需要设置一些显式参数来确保模型的稳定性和性能。",
        "id": 386,
        "target_term": "explicit",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中如何优化性能时",
        "sentence_A": "在训练过程中，我们需要特别注意 Exploiting 模型的潜力，以确保它在各种场景下都能表现出色。",
        "sentence_B": "在训练过程中，我们需要特别注意挖掘模型的潜力，以确保它在各种场景下都能表现出色。",
        "id": 387,
        "target_term": "Exploiting",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论强化学习算法的优化策略时",
        "sentence_A": "在强化学习中，我们经常需要在训练过程中进行 Exploration，以确保模型能够探索到更多的状态空间。",
        "sentence_B": "在强化学习中，我们经常需要在训练过程中进行探索，以确保模型能够探索到更多的状态空间。",
        "id": 388,
        "target_term": "Exploration",
        "is_hardcore": true
    },
    {
        "topic": "Gradient Explosion",
        "prefix": "在讨论模型训练过程中遇到的问题时",
        "sentence_A": "我们在训练这个深度神经网络时遇到了 Gradient Explosion，需要调整学习率和使用梯度裁剪来解决。",
        "sentence_B": "我们在训练这个深度神经网络时遇到了梯度爆炸问题，需要调整学习率并使用梯度裁剪来解决。",
        "id": 389,
        "target_term": "Gradient Explosion",
        "is_hardcore": true
    },
    {
        "topic": "Exponential Functions in Model Training",
        "prefix": "在讨论模型训练的优化方法时",
        "sentence_A": "我们在优化损失函数时，发现使用 Exponential 可以显著提高模型的收敛速度。",
        "sentence_B": "我们在优化损失函数时，发现使用指数函数可以显著提高模型的收敛速度。",
        "id": 390,
        "target_term": "Exponential",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的分布时",
        "sentence_A": "这次的数据集 Exposure 比之前高了很多，我们需要重新评估模型的性能。",
        "sentence_B": "这次的数据集曝光率比之前高了很多，我们需要重新评估模型的性能。",
        "id": 391,
        "target_term": "Exposure",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理各种复杂的表达式。",
        "sentence_A": "在训练这个模型时，我们发现处理复杂的 Expression 非常耗时，需要优化。",
        "sentence_B": "在训练这个模型时，我们发现处理复杂的表达式非常耗时，需要优化。",
        "id": 392,
        "target_term": "Expression",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何处理复杂的表达式问题。",
        "sentence_A": "在训练模型时，我们发现处理复杂的 Expression 是个大问题，需要特别的优化。",
        "sentence_B": "在训练模型时，我们发现处理复杂的表达式是个大问题，需要特别的优化。",
        "id": 393,
        "target_term": "Expression",
        "is_hardcore": true
    },
    {
        "topic": "Data Extraction",
        "prefix": "在讨论模型训练的数据处理阶段时",
        "sentence_A": "我们在数据预处理阶段，需要进行数据的 Extraction，确保输入模型的数据质量。",
        "sentence_B": "我们在数据预处理阶段，需要进行数据的提取，确保输入模型的数据质量。",
        "id": 394,
        "target_term": "Extraction",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗的过程中，我们发现了一些异常值。",
        "sentence_A": "在数据清洗的过程中，我们发现了一些 Extreme，需要特别处理。",
        "sentence_B": "在数据清洗的过程中，我们发现了一些极端值，需要特别处理。",
        "id": 395,
        "target_term": "Extreme",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们需要不断评估模型的性能。",
        "sentence_A": "在训练过程中，我们发现模型的 F1 score 一直没有明显提升，可能需要调整超参数。",
        "sentence_B": "在训练过程中，我们发现模型的 F1 值一直没有明显提升，可能需要调整超参数。",
        "id": 396,
        "target_term": "F1 score",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们这次训练的时候，FAN 的设置对模型的收敛速度影响很大。",
        "sentence_B": "我们这次训练的时候，特征归一化（FAN）的设置对模型的收敛速度影响很大。",
        "id": 397,
        "target_term": "FAN",
        "is_hardcore": true
    },
    {
        "topic": "FFN in Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以在 Transformer 的每个 layer 里用更大的 FFN，这样可以提升模型的表达能力。",
        "sentence_B": "我们可以在 Transformer 的每个层中使用更大的前馈神经网络（FFN），这样可以提升模型的表达能力。",
        "id": 398,
        "target_term": "Transformer",
        "is_hardcore": true
    },
    {
        "topic": "FFNN Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们这次可以尝试用 FFNN 作为基础模型，看看效果如何。",
        "sentence_B": "我们这次可以尝试用前馈神经网络作为基础模型，看看效果如何。",
        "id": 399,
        "target_term": "FFNN",
        "is_hardcore": true
    },
    {
        "topic": "Adversarial Attacks and Defenses",
        "prefix": "在模型训练过程中，我们遇到了对抗样本的问题。",
        "sentence_A": "我们决定使用 FGSM 来生成对抗样本，这样可以更好地测试模型的鲁棒性。",
        "sentence_B": "我们决定使用快速梯度符号方法（FGSM）来生成对抗样本，这样可以更好地测试模型的鲁棒性。",
        "id": 400,
        "target_term": "FGSM",
        "is_hardcore": true
    },
    {
        "topic": "FIR Filter Design",
        "prefix": "在讨论模型信号处理的优化方案时，团队成员提到",
        "sentence_A": "我们在信号处理模块中使用了 FIR 滤波器，这样可以更好地去除噪声。",
        "sentence_B": "我们在信号处理模块中使用了有限脉冲响应滤波器，这样可以更好地去除噪声。",
        "id": 401,
        "target_term": "FIR",
        "is_hardcore": true
    },
    {
        "topic": "Factorization Machine",
        "prefix": "在模型训练过程中，我们讨论了如何优化FM模型的性能。",
        "sentence_A": "我们在训练 FM 模型时，发现加入高阶特征交叉可以显著提升模型的预测精度。",
        "sentence_B": "我们在训练因子分解机模型时，发现加入高阶特征交叉可以显著提升模型的预测精度。",
        "id": 402,
        "target_term": "FM",
        "is_hardcore": false
    },
    {
        "topic": "Feedforward Neural Network Optimization",
        "prefix": "在模型训练过程中，我们讨论了如何优化前馈神经网络的性能。",
        "sentence_A": "我们在训练过程中发现，调整 FNN 的超参数可以显著提升模型的准确率。",
        "sentence_B": "我们在训练过程中发现，调整前馈神经网络的超参数可以显著提升模型的准确率。",
        "id": 403,
        "target_term": "FNN",
        "is_hardcore": true
    },
    {
        "topic": "Faster R-CNN Model Fine-Tuning",
        "prefix": "在模型训练过程中，我们遇到了一些问题。",
        "sentence_A": "我们在训练 FRCNN 模型时发现，数据集中的标注不一致导致了模型的精度下降。",
        "sentence_B": "我们在训练 Faster R-CNN 模型时发现，数据集中的标注不一致导致了模型的精度下降。",
        "id": 404,
        "target_term": "FRCNN",
        "is_hardcore": true
    },
    {
        "topic": "Finite State Machine in Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到了状态机的使用。",
        "sentence_A": "我们可以在模型训练中引入 FSM 来优化状态管理。",
        "sentence_B": "我们可以在模型训练中引入有限状态机来优化状态管理。",
        "id": 405,
        "target_term": "FSM",
        "is_hardcore": true
    },
    {
        "topic": "Fine-Tuning",
        "prefix": "在模型训练过程中，我们经常需要对预训练模型进行微调，以适应特定任务。",
        "sentence_A": "这次我们对预训练模型进行 FT，以提高在特定任务上的性能。",
        "sentence_B": "这次我们对预训练模型进行微调，以提高在特定任务上的性能。",
        "id": 406,
        "target_term": "FT",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到了一个关键算法",
        "sentence_A": "我们在训练模型时，发现使用 Fa 算法可以显著提高训练效率。",
        "sentence_B": "我们在训练模型时，发现使用快速傅里叶变换（Fast Fourier Transform, FFT）算法可以显著提高训练效率。",
        "id": 407,
        "target_term": "Fa",
        "is_hardcore": false
    },
    {
        "topic": "Facial Recognition in Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们需要确保数据集中有足够多的 Facial 图片，以提高模型的识别准确率。",
        "sentence_B": "我们需要确保数据集中有足够多的面部图片，以提高模型的识别准确率。",
        "id": 408,
        "target_term": "Facial",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现了一个重要的问题。",
        "sentence_A": "在数据清洗过程中，我们发现了一个重要的问题，这个数据点其实是一个 Fact，而不是模型预测的结果。",
        "sentence_B": "在数据清洗过程中，我们发现了一个重要的问题，这个数据点实际上是一个事实，而不是模型预测的结果。",
        "id": 409,
        "target_term": "Fact",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数选择时",
        "sentence_A": "我们在选择模型的 hyperparameter 时，Factor 是一个非常重要的参数，它直接影响模型的性能。",
        "sentence_B": "我们在选择模型的超参数时，因子是一个非常重要的参数，它直接影响模型的性能。",
        "id": 410,
        "target_term": "hyperparameter",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "我们在分析模型性能的时候，需要考虑多个 Factor，比如数据质量、特征选择和超参数设置。",
        "sentence_B": "在分析模型性能时，需要考虑多个因素，比如数据质量、特征选择和超参数设置。",
        "id": 411,
        "target_term": "Factor",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议中，团队成员提到一个关键问题。",
        "sentence_A": "我们在训练模型时，需要特别关注 Fairnes，确保算法对不同群体的处理是公平的。",
        "sentence_B": "我们在训练模型时，需要特别关注公平性，确保算法对不同群体的处理是公平的。",
        "id": 412,
        "target_term": "Fairnes",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了数据验证的重要性。",
        "sentence_A": "我们需要确保数据集中没有 Falsification 的情况，这样才能保证模型的准确性和可靠性。",
        "sentence_B": "我们需要确保数据集中没有伪造的情况，这样才能保证模型的准确性和可靠性。",
        "id": 413,
        "target_term": "Falsification",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数选择时",
        "sentence_A": "我们在选择模型参数时，需要考虑这个参数的 Family，比如是正态分布还是泊松分布。",
        "sentence_B": "我们在选择模型参数时，需要考虑这个参数的分布族，比如是正态分布还是泊松分布。",
        "id": 414,
        "target_term": "Family",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在推理阶段使用了 Faster R-CNN，结果真是快多了。",
        "sentence_B": "我们在推理阶段使用了快速区域卷积神经网络（Faster R-CNN），结果确实快了很多。",
        "id": 415,
        "target_term": "Faster R-CNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练过程中，我们遇到了一些问题。",
        "sentence_A": "我们在训练模型时遇到了一个 Fault，导致训练中断。",
        "sentence_B": "我们在训练模型时遇到了一个故障，导致训练中断。",
        "id": 416,
        "target_term": "Fault",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论新的模型训练方案时",
        "sentence_A": "我们在讨论新的模型训练方案时，需要先评估一下这个方案的 Feasibility，看看它在实际环境中的表现如何。",
        "sentence_B": "我们在讨论新的模型训练方案时，需要先评估一下这个方案的可行性，看看它在实际环境中的表现如何。",
        "id": 417,
        "target_term": "Feasibility",
        "is_hardcore": true
    },
    {
        "topic": "Federated Learning",
        "prefix": "在一次团队会议中，讨论如何在保证用户隐私的前提下进行模型训练。",
        "sentence_A": "我们可以通过 Federated 学习来在多个设备上训练模型，而不需要将用户数据集中到一个中心服务器。",
        "sentence_B": "我们可以通过联邦学习来在多个设备上训练模型，而不需要将用户数据集中到一个中心服务器。",
        "id": 418,
        "target_term": "Federated",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练模型时，需要确保 Fidelity，这样才能保证模型在不同数据集上的表现一致。",
        "sentence_B": "我们在训练模型时，需要确保保真度，这样才能保证模型在不同数据集上的表现一致。",
        "id": 419,
        "target_term": "Fidelity",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗的过程中，我们需要处理大量的噪声数据。",
        "sentence_A": "在数据预处理阶段，我们使用了多种 Filtering 技术来去除噪声，以确保模型的训练效果。",
        "sentence_B": "在数据预处理阶段，我们使用了多种滤波技术来去除噪声，以确保模型的训练效果。",
        "id": 420,
        "target_term": "Filtering",
        "is_hardcore": true
    },
    {
        "topic": "Convolutional Neural Networks",
        "prefix": "在讨论卷积神经网络的优化时",
        "sentence_A": "我们可以通过调整 Filter 的数量和大小来优化模型的性能。",
        "sentence_B": "我们可以通过调整滤波器的数量和大小来优化模型的性能。",
        "id": 421,
        "target_term": "Filter",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行模型训练前的数据清洗过程中，我们遇到了一些问题。",
        "sentence_A": "我们在清洗数据时发现，Financial 数据的格式非常不统一，需要进行大量的预处理。",
        "sentence_B": "我们在清洗数据时发现，金融数据的格式非常不统一，需要进行大量的预处理。",
        "id": 422,
        "target_term": "Financial",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中",
        "sentence_A": "我们在做这个模型的 Finetuning 时，发现有些数据集的效果特别好。",
        "sentence_B": "我们在对这个模型进行微调时，发现某些数据集的效果特别好。",
        "id": 423,
        "target_term": "Finetuning",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在一次模型训练会议上，团队讨论了如何优化模型的推理速度。",
        "sentence_A": "我们可以通过引入 Fission 技术来优化模型的推理速度。",
        "sentence_B": "我们可以通过引入裂变技术来优化模型的推理速度。",
        "id": 424,
        "target_term": "Fission",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一个关键问题并解决了它。",
        "sentence_A": "在最新的训练轮次中，我们终于把那个 bug Fixed 了，模型的性能提升了不少。",
        "sentence_B": "在最新的训练轮次中，我们终于解决了那个 bug，模型的性能提升了不少。",
        "id": 425,
        "target_term": "bug Fixed",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练框架的选择时，团队成员提到了灵活性的重要性。",
        "sentence_A": "我们在选择模型训练框架时，一定要考虑到 Flexibility，这样才能更好地适应不同的业务需求。",
        "sentence_B": "我们在选择模型训练框架时，一定要考虑到灵活性，这样才能更好地适应不同的业务需求。",
        "id": 426,
        "target_term": "Flexibility",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的灵活性时，团队成员提到",
        "sentence_A": "我们的模型需要更 Flexible 的架构，以便在不同数据集上快速调整和优化。",
        "sentence_B": "我们的模型需要更灵活的架构，以便在不同数据集上快速调整和优化。",
        "id": 427,
        "target_term": "Flexible",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型性能优化时，团队成员提到计算量的问题。",
        "sentence_A": "这个模型的 Flop 太高了，我们需要优化一下，否则推理速度会很慢。",
        "sentence_B": "这个模型的浮点运算量太高了，我们需要优化一下，否则推理速度会很慢。",
        "id": 428,
        "target_term": "Flop",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing and Model Training",
        "prefix": "在讨论数据处理和模型训练的过程中",
        "sentence_A": "我们在处理数据的时候，要注意整个 data Flow 的设计，确保数据在各个环节都能顺畅地流动。",
        "sentence_B": "我们在处理数据的时候，要注意整个数据流的设计，确保数据在各个环节都能顺畅地流动。",
        "id": 429,
        "target_term": "data Flow",
        "is_hardcore": true
    },
    {
        "topic": "Focal Loss",
        "prefix": "在模型训练中讨论损失函数的选择",
        "sentence_A": "我们在训练这个模型时，发现使用 Focal los 能够显著提升小目标检测的准确性。",
        "sentence_B": "我们在训练这个模型时，发现使用焦损能够显著提升小目标检测的准确性。",
        "id": 430,
        "target_term": "Focal los",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在训练模型时，需要特别注意 Foil 的处理，确保它们不会对模型的性能产生负面影响。",
        "sentence_B": "我们在训练模型时，需要特别注意对比样本的处理，确保它们不会对模型的性能产生负面影响。",
        "id": 431,
        "target_term": "Foil",
        "is_hardcore": true
    },
    {
        "topic": "Cross-Validation",
        "prefix": "在模型训练过程中，我们经常需要评估模型的泛化能力。",
        "sentence_A": "这次我们用 5 Fold 的交叉验证来评估模型的性能，确保结果的稳定性。",
        "sentence_B": "这次我们用 5 折的交叉验证来评估模型的性能，确保结果的稳定性。",
        "id": 432,
        "target_term": "5 Fold",
        "is_hardcore": true
    },
    {
        "topic": "Forecasting in Time Series Analysis",
        "prefix": "在讨论时间序列模型的准确性时，团队成员提到",
        "sentence_A": "我们在做时间序列的 Forecasting 时，模型的预测精度很重要，特别是在电商销售预测中。",
        "sentence_B": "我们在进行时间序列预测时，模型的预测精度非常重要，特别是在电商销售预测中。",
        "id": 433,
        "target_term": "Forecasting",
        "is_hardcore": true
    },
    {
        "topic": "Random Forest Algorithm",
        "prefix": "在讨论模型优化时",
        "sentence_A": "我们这次可以尝试用一下 Random Forest，看看能不能提升模型的泛化能力。",
        "sentence_B": "我们这次可以尝试使用随机森林，看看能否提升模型的泛化能力。",
        "id": 434,
        "target_term": "Random Forest",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们在数据清洗阶段需要特别注意 Formal 数据的处理，确保模型训练的质量。",
        "sentence_B": "我们在数据清洗阶段需要特别注意正式数据的处理，确保模型训练的质量。",
        "id": 435,
        "target_term": "Formal",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在数据清洗过程中，团队讨论数据格式的标准化问题。",
        "sentence_A": "我们在数据清洗过程中，需要确保所有数据的 Format 一致，这样模型训练时才不会出问题。",
        "sentence_B": "我们在数据清洗过程中，需要确保所有数据的格式一致，这样模型训练时才不会出问题。",
        "id": 436,
        "target_term": "Format",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过调整学习率的 Formula 来提高模型的收敛速度。",
        "sentence_B": "我们可以通过调整学习率的公式来提高模型的收敛速度。",
        "id": 437,
        "target_term": "Formula",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练流程时",
        "sentence_A": "在训练过程中，我们首先进行 Forward 计算，然后再进行 Backward 优化。",
        "sentence_B": "在训练过程中，我们首先进行前向计算，然后再进行反向优化。",
        "id": 438,
        "target_term": "Forward",
        "is_hardcore": true
    },
    {
        "topic": "Foundation Model Training",
        "prefix": "在讨论大模型的训练流程时，技术团队提到",
        "sentence_A": "我们在训练这个模型时，发现 Foundation 的预训练效果非常好，可以显著提升下游任务的性能。",
        "sentence_B": "我们在训练这个模型时，发现基础模型的预训练效果非常好，可以显著提升下游任务的性能。",
        "id": 439,
        "target_term": "Foundation",
        "is_hardcore": true
    },
    {
        "topic": "Signal Processing in AI Models",
        "prefix": "在讨论模型训练中的信号处理技术时",
        "sentence_A": "我们可以在模型训练中使用 Fourier 变换来优化信号处理的效率。",
        "sentence_B": "我们可以在模型训练中使用傅里叶变换来优化信号处理的效率。",
        "id": 440,
        "target_term": "Fourier",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们这次可以尝试用 Fractional 采样来优化数据集，看看效果如何。",
        "sentence_B": "我们这次可以尝试用分数采样来优化数据集，看看效果如何。",
        "id": 441,
        "target_term": "Fractional",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理步骤时",
        "sentence_A": "我们这次在数据预处理阶段，需要特别注意每个 Frame 的时间戳对齐，确保模型训练的准确性和效率。",
        "sentence_B": "我们这次在数据预处理阶段，需要特别注意每个帧的时间戳对齐，确保模型训练的准确性和效率。",
        "id": 442,
        "target_term": "Frame",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们这次用的 TensorFlow Framework 真的是太强大了，不仅支持多GPU训练，还能自动优化计算图。",
        "sentence_B": "我们这次使用的 TensorFlow 框架真的是太强大了，不仅支持多GPU训练，还能自动优化计算图。",
        "id": 443,
        "target_term": "TensorFlow Framework",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在模型训练过程中，我们经常需要对模型进行优化，以提高其性能和效率。",
        "sentence_A": "在训练完基础模型后，我们通常会对模型进行 Freezing，以减少推理时的计算开销。",
        "sentence_B": "在训练完基础模型后，我们通常会对模型进行冻结，以减少推理时的计算开销。",
        "id": 444,
        "target_term": "Freezing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在设置参数的时候，需要特别关注 Frequency 这个参数，它直接影响模型的训练效果。",
        "sentence_B": "我们在设置参数的时候，需要特别关注频率这个参数，它直接影响模型的训练效果。",
        "id": 445,
        "target_term": "Frequency",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型推理优化时，团队成员提到一个重要的优化策略。",
        "sentence_A": "我们在推理优化中采用了 Frugal 的策略，通过减少不必要的计算来提高效率。",
        "sentence_B": "我们在推理优化中采用了节俭的策略，通过减少不必要的计算来提高效率。",
        "id": 446,
        "target_term": "Frugal",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在一次团队会议中，讨论如何优化模型的推理速度。",
        "sentence_A": "我们在推理优化过程中，可以考虑使用 Fusion 技术来合并一些层，这样可以显著提升模型的推理速度。",
        "sentence_B": "我们在推理优化过程中，可以考虑使用融合技术来合并一些层，这样可以显著提升模型的推理速度。",
        "id": 447,
        "target_term": "Fusion",
        "is_hardcore": true
    },
    {
        "topic": "G2P",
        "prefix": "在模型训练过程中，我们遇到了一些关于G2P的问题。",
        "sentence_A": "我们在训练模型时发现，G2P 的准确率在某些数据集上有所下降，需要进一步优化。",
        "sentence_B": "我们在训练模型时发现，图到路径（G2P）的准确率在某些数据集上有所下降，需要进一步优化。",
        "id": 448,
        "target_term": "G2P",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的最后阶段时",
        "sentence_A": "我们这个模型的性能已经可以达到 GA 了，接下来就是准备上线了。",
        "sentence_B": "我们这个模型的性能已经可以达到正式发布（General Availability）了，接下来就是准备上线了。",
        "id": 449,
        "target_term": "GA",
        "is_hardcore": false
    },
    {
        "topic": "GAN",
        "prefix": "在讨论模型优化的会议上",
        "sentence_A": "我们在考虑使用 GAN 来提升图像生成的质量，这样可以更好地满足客户需求。",
        "sentence_B": "我们在考虑使用生成对抗网络来提升图像生成的质量，这样可以更好地满足客户需求。",
        "id": 450,
        "target_term": "GAN",
        "is_hardcore": true
    },
    {
        "topic": "GANs in Model Training",
        "prefix": "在讨论模型训练的优化时",
        "sentence_A": "我们在训练 GANS 模型时，发现数据集的分布对生成效果影响很大。",
        "sentence_B": "我们在训练生成对抗网络模型时，发现数据集的分布对生成效果影响很大。",
        "id": 451,
        "target_term": "GANS",
        "is_hardcore": true
    },
    {
        "topic": "Graph Convolutional Network",
        "prefix": "在模型训练过程中，我们遇到了性能瓶颈。",
        "sentence_A": "我们在用 GCN 进行图数据处理时，发现模型的收敛速度比预期的要慢。",
        "sentence_B": "我们在使用图卷积网络进行图数据处理时，发现模型的收敛速度比预期的要慢。",
        "id": 452,
        "target_term": "GCN",
        "is_hardcore": true
    },
    {
        "topic": "Graph Convolutional Networks",
        "prefix": "在模型训练过程中，我们讨论了如何优化GCNs的性能。",
        "sentence_A": "在训练模型时，我们发现 GCN 的性能在大规模图数据上还有提升空间。",
        "sentence_B": "在训练模型时，我们发现图卷积网络的性能在大规模图数据上还有提升空间。",
        "id": 453,
        "target_term": "GCN",
        "is_hardcore": true
    },
    {
        "topic": "Gradient Descent",
        "prefix": "在模型训练过程中，团队讨论优化算法的选择。",
        "sentence_A": "我们这次模型训练还是用 GD 吧，效果比较稳定。",
        "sentence_B": "我们这次模型训练还是用梯度下降吧，效果比较稳定。",
        "id": 454,
        "target_term": "GD",
        "is_hardcore": false
    },
    {
        "topic": "Gradient Descent Method",
        "prefix": "在讨论模型训练的优化算法时",
        "sentence_A": "我们在训练这个模型时，用的是 GDM，效果还不错。",
        "sentence_B": "我们在训练这个模型时，使用的是梯度下降法，效果还不错。",
        "id": 455,
        "target_term": "GDM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过引入 GEM 来提升模型的泛化能力。",
        "sentence_B": "我们可以通过引入梯度估计方法（GEM）来提升模型的泛化能力。",
        "id": 456,
        "target_term": "GEM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时，",
        "sentence_A": "我们这次的数据集里包含了很多 GENE 的信息，这对于我们的模型训练非常关键。",
        "sentence_B": "我们这次的数据集中包含了很多基因的信息，这对于我们的模型训练非常关键。",
        "id": 457,
        "target_term": "GENE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中讨论生成模型的性能优化",
        "sentence_A": "我们最近在优化这些 GEN 的生成质量，特别是在大规模数据集上。",
        "sentence_B": "我们最近在优化这些生成模型的生成质量，特别是在大规模数据集上。",
        "id": 458,
        "target_term": "GEN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到GEP的使用。",
        "sentence_A": "我们在最新的模型训练中引入了 GEP，发现它在处理大规模图数据时效果显著。",
        "sentence_B": "我们在最新的模型训练中引入了图嵌入路径（GEP），发现它在处理大规模图数据时效果显著。",
        "id": 459,
        "target_term": "GEP",
        "is_hardcore": true
    },
    {
        "topic": "Generalized Focal Loss",
        "prefix": "在模型训练过程中，我们发现使用GFL可以显著提升模型的性能。",
        "sentence_A": "在训练过程中，我们发现使用 GFL 可以显著提升模型的性能。",
        "sentence_B": "在训练过程中，我们发现使用广义焦点损失可以显著提升模型的性能。",
        "id": 460,
        "target_term": "GFL",
        "is_hardcore": true
    },
    {
        "topic": "GGNN in Model Training",
        "prefix": "在讨论模型训练的优化方案时，",
        "sentence_A": "我们考虑使用 GGNN 来增强图结构数据的表征能力，这样可以更好地捕捉节点间的复杂关系。",
        "sentence_B": "我们考虑使用图门控神经网络（GGNN）来增强图结构数据的表征能力，这样可以更好地捕捉节点间的复杂关系。",
        "id": 461,
        "target_term": "GGNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了一些数据集的问题。",
        "sentence_A": "我们在处理数据集时发现了一些 GHOST 数据，这些数据在训练过程中可能会导致模型过拟合。",
        "sentence_B": "我们在处理数据集时发现了一些幽灵数据，这些数据在训练过程中可能会导致模型过拟合。",
        "id": 462,
        "target_term": "GHOST",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在选择训练数据集时，考虑了 GIST 特征的提取效果，这对模型的性能提升有很大的帮助。",
        "sentence_B": "我们在选择训练数据集时，考虑了gist特征的提取效果，这对模型的性能提升有很大的帮助。",
        "id": 463,
        "target_term": "GIST",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，我们需要确保模型在多个任务上的表现都达到预期。",
        "sentence_A": "我们在模型评估阶段使用了 GLUE 基准，确保模型在多个任务上的表现都达到预期。",
        "sentence_B": "我们在模型评估阶段使用了GLUE基准，确保模型在多个任务上的表现都达到预期。",
        "id": 464,
        "target_term": "GLUE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化模型的性能。",
        "sentence_A": "在训练过程中，我们发现使用 GMA 可以显著提高模型的鲁棒性。",
        "sentence_B": "在训练过程中，我们发现使用全局注意力机制（GMA）可以显著提高模型的鲁棒性。",
        "id": 465,
        "target_term": "GMA",
        "is_hardcore": true
    },
    {
        "topic": "Generalized Matrix Factorization",
        "prefix": "在模型训练过程中，我们讨论了如何优化推荐系统的性能。",
        "sentence_A": "我们在训练推荐系统时，发现使用 GMF 可以显著提升模型的准确率。",
        "sentence_B": "我们在训练推荐系统时，发现使用广义矩阵分解可以显著提升模型的准确率。",
        "id": 466,
        "target_term": "GMF",
        "is_hardcore": true
    },
    {
        "topic": "GNN in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到GNN的应用。",
        "sentence_A": "我们在训练这个模型时，GNN 的表现特别好，尤其是在处理图结构数据的时候。",
        "sentence_B": "我们在训练这个模型时，图神经网络（GNN）的表现特别好，尤其是在处理图结构数据的时候。",
        "id": 467,
        "target_term": "GNN",
        "is_hardcore": true
    },
    {
        "topic": "Graph Neural Network Systems",
        "prefix": "在讨论模型训练的会议上",
        "sentence_A": "我们在训练 GNNS 时，需要特别注意图的结构和节点特征的处理。",
        "sentence_B": "我们在训练图神经网络系统时，需要特别注意图的结构和节点特征的处理。",
        "id": 468,
        "target_term": "GNNS",
        "is_hardcore": true
    },
    {
        "topic": "Gaussian Process",
        "prefix": "在模型训练过程中，讨论如何使用GP进行回归任务的优化。",
        "sentence_A": "我们这次用 GP 来优化回归任务，效果还不错。",
        "sentence_B": "我们这次使用高斯过程来优化回归任务，效果还不错。",
        "id": 469,
        "target_term": "GP",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化GPT模型的性能。",
        "sentence_A": "我们这次用的 GPT 模型在大规模数据集上的表现还不错，但还需要进一步调参优化。",
        "sentence_B": "我们这次使用的生成式预训练模型在大规模数据集上的表现还不错，但还需要进一步调参优化。",
        "id": 470,
        "target_term": "GPT",
        "is_hardcore": true
    },
    {
        "topic": "Model Fine-tuning",
        "prefix": "在讨论模型微调的过程中",
        "sentence_A": "我们最近在用 GPT2 做一些特定领域的文本生成任务，效果还不错。",
        "sentence_B": "我们最近在使用 GPT2 做一些特定领域的文本生成任务，效果还不错。",
        "id": 471,
        "target_term": "GPT2",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上",
        "sentence_A": "我们这次用 GPT4 做 fine-tuning，效果应该会比之前的好很多。",
        "sentence_B": "我们这次用GPT-4做微调，效果应该会比之前的好很多。",
        "id": 472,
        "target_term": "GPT4",
        "is_hardcore": true
    },
    {
        "topic": "GPU Usage in Model Training",
        "prefix": "在讨论如何优化模型训练的计算资源时",
        "sentence_A": "我们这次用的模型很复杂，训练时需要大量的 GPU 资源。",
        "sentence_B": "我们这次使用的模型非常复杂，训练时需要大量的图形处理器资源。",
        "id": 473,
        "target_term": "GPU",
        "is_hardcore": true
    },
    {
        "topic": "GPUs in Model Training",
        "prefix": "在讨论如何优化模型训练效率时",
        "sentence_A": "我们可以通过增加 GPUS 的数量来加速模型训练，但也要注意资源的合理分配。",
        "sentence_B": "我们可以通过增加GPU的数量来加速模型训练，但也要注意资源的合理分配。",
        "id": 474,
        "target_term": "GPUS",
        "is_hardcore": true
    },
    {
        "topic": "GRN in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到GRN的重要性。",
        "sentence_A": "在训练这个模型时，我们发现使用 GRN 可以显著提升模型的收敛速度。",
        "sentence_B": "在训练这个模型时，我们发现使用生成关系网络（GRN）可以显著提升模型的收敛速度。",
        "id": 475,
        "target_term": "GRN",
        "is_hardcore": true
    },
    {
        "topic": "GRU in Model Training",
        "prefix": "在讨论模型训练优化的会议中，团队成员正在探讨如何提高序列模型的性能。",
        "sentence_A": "我们可以在下一个版本的模型中尝试用 GRU 替换 LSTM，看看效果如何。",
        "sentence_B": "我们可以在下一个版本的模型中尝试用门控循环单元替换长短期记忆网络，看看效果如何。",
        "id": 476,
        "target_term": "GRU",
        "is_hardcore": true
    },
    {
        "topic": "GRU-based Sequence Modeling",
        "prefix": "在一次模型训练的团队会议上，讨论如何优化模型的性能。",
        "sentence_A": "我们可以在 GRUS 模型的训练过程中引入更多的历史数据，这样可能会提高模型的预测准确率。",
        "sentence_B": "我们可以在门控循环单元（GRU）模型的训练过程中引入更多的历史数据，这样可能会提高模型的预测准确率。",
        "id": 477,
        "target_term": "GRUS",
        "is_hardcore": true
    },
    {
        "topic": "Ground Truth in Model Training",
        "prefix": "在讨论模型训练的数据标注问题时",
        "sentence_A": "我们在训练模型时，需要确保标注的 GT 数据足够准确，这样才能保证模型的性能。",
        "sentence_B": "我们在训练模型时，需要确保标注的地面真值数据足够准确，这样才能保证模型的性能。",
        "id": 478,
        "target_term": "GT",
        "is_hardcore": false
    },
    {
        "topic": "Gabor Filter Application in Image Processing",
        "prefix": "在讨论图像处理算法优化时，团队成员提到了Gabor滤波器的应用。",
        "sentence_A": "我们在训练模型时发现，使用 Gabor 滤波器可以显著提升边缘检测的效果。",
        "sentence_B": "我们在训练模型时发现，使用Gabor滤波器可以显著提升边缘检测的效果。",
        "id": 479,
        "target_term": "Gabor",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "我们在这次的实验中，通过调整超参数，模型的 Gain 提升了10%。",
        "sentence_B": "我们在这次的实验中，通过调整超参数，模型的增益提升了10%。",
        "id": 480,
        "target_term": "Gain",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning in Game AI",
        "prefix": "在讨论如何优化游戏AI的强化学习模型时",
        "sentence_A": "我们在训练这个模型时，发现强化学习在 Game 中的策略优化非常关键。",
        "sentence_B": "我们在训练这个模型时，发现强化学习在游戏中的策略优化非常关键。",
        "id": 481,
        "target_term": "Game",
        "is_hardcore": false
    },
    {
        "topic": "Gaming in AI Model Training",
        "prefix": "在讨论模型训练数据集时",
        "sentence_A": "咱们这次的模型训练数据集中，Gaming 部分的数据质量特别高，对提升模型的泛化能力有很大帮助。",
        "sentence_B": "我们这次的模型训练数据集中，游戏部分的数据质量特别高，对提升模型的泛化能力有很大帮助。",
        "id": 482,
        "target_term": "Gaming",
        "is_hardcore": true
    },
    {
        "topic": "Gating Mechanism in Neural Networks",
        "prefix": "在讨论如何优化模型的推理速度时",
        "sentence_A": "我们可以通过引入 Gating 机制来控制模型的复杂度，从而提高推理效率。",
        "sentence_B": "我们可以通过引入门控机制来控制模型的复杂度，从而提高推理效率。",
        "id": 483,
        "target_term": "Gating",
        "is_hardcore": true
    },
    {
        "topic": "Gaze Estimation",
        "prefix": "在模型训练过程中，我们遇到了一个关于注视点估计的问题。",
        "sentence_A": "我们在训练模型时发现，Gaze 的估计误差比较大，需要进一步优化数据预处理步骤。",
        "sentence_B": "我们在训练模型时发现，注视点的估计误差比较大，需要进一步优化数据预处理步骤。",
        "id": 484,
        "target_term": "Gaze",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "这次的模型在测试集上的表现不错，Generalization 能力很强，看来我们的数据增强策略很有效。",
        "sentence_B": "这次的模型在测试集上的表现不错，泛化能力很强，看来我们的数据增强策略很有效。",
        "id": 485,
        "target_term": "Generalization",
        "is_hardcore": true
    },
    {
        "topic": "Model Generalization",
        "prefix": "在讨论模型训练的泛化能力时",
        "sentence_A": "我们在训练模型时，要确保它能很好地处理各种未知数据，这就是所谓的 Generalized 能力。",
        "sentence_B": "我们在训练模型时，要确保它能很好地处理各种未知数据，这就是所谓的泛化能力。",
        "id": 486,
        "target_term": "Generalized",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练过程时",
        "sentence_A": "在进行模型训练时，我们发现 Generating 阶段的效率可以进一步提升。",
        "sentence_B": "在进行模型训练时，我们发现生成阶段的效率可以进一步提升。",
        "id": 487,
        "target_term": "Generating",
        "is_hardcore": true
    },
    {
        "topic": "Generative Models",
        "prefix": "在讨论模型训练的过程中",
        "sentence_A": "我们在训练这个模型时，重点是利用 Generative 模型来生成高质量的文本。",
        "sentence_B": "我们在训练这个模型时，重点是利用生成模型来生成高质量的文本。",
        "id": 488,
        "target_term": "Generative",
        "is_hardcore": true
    },
    {
        "topic": "Genetic Algorithms in Model Training",
        "prefix": "在讨论模型训练方法时，团队成员提出了使用遗传算法来优化模型参数。",
        "sentence_A": "我们可以试试用 Genetic 算法来优化模型参数，这样可能会找到更好的解。",
        "sentence_B": "我们可以尝试使用遗传算法来优化模型参数，这样可能会找到更优的解。",
        "id": 489,
        "target_term": "Genetic",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们讨论如何处理地理信息数据的缺失值问题。",
        "sentence_A": "在数据清洗阶段，我们讨论如何处理 Geography 信息数据的缺失值问题。",
        "sentence_B": "在数据清洗阶段，我们讨论如何处理地理信息数据的缺失值问题。",
        "id": 490,
        "target_term": "Geography",
        "is_hardcore": true
    },
    {
        "topic": "Geometry in AI Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们在数据预处理阶段，发现 Geometry 的处理对模型的训练效果影响很大。",
        "sentence_B": "我们在数据预处理阶段，发现几何处理对模型的训练效果影响很大。",
        "id": 491,
        "target_term": "Geometry",
        "is_hardcore": true
    },
    {
        "topic": "Stochastic Simulation Algorithm",
        "prefix": "在讨论模型训练的随机过程时",
        "sentence_A": "我们今天在讨论模型训练的随机过程时，提到了 Gillespie 算法，这个算法在模拟生化反应过程中非常有用。",
        "sentence_B": "我们在讨论模型训练的随机过程时，提到了吉尔皮算法，这个算法在模拟生化反应过程中非常有用。",
        "id": 492,
        "target_term": "Gillespie",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的目标时",
        "sentence_A": "我们在设定模型训练的 Goal 时，需要考虑多个因素，比如准确率、收敛速度和泛化能力。",
        "sentence_B": "我们在设定模型训练的目标时，需要考虑多个因素，比如准确率、收敛速度和泛化能力。",
        "id": 493,
        "target_term": "Goal",
        "is_hardcore": false
    },
    {
        "topic": "Gradient Descent",
        "prefix": "在模型训练过程中，我们经常需要调整参数以优化模型性能。",
        "sentence_A": "在训练这个模型的时候，我们发现 Gradient 的计算非常关键，需要确保每一步都准确无误。",
        "sentence_B": "在训练这个模型的时候，我们发现梯度的计算非常关键，需要确保每一步都准确无误。",
        "id": 494,
        "target_term": "Gradient",
        "is_hardcore": true
    },
    {
        "topic": "Gradient Calculation in Model Training",
        "prefix": "在模型训练过程中，我们经常需要计算梯度来优化模型参数。",
        "sentence_A": "在训练模型时，我们使用反向传播算法计算 Gradient，以便优化模型的参数。",
        "sentence_B": "在训练模型时，我们使用反向传播算法计算梯度，以便优化模型的参数。",
        "id": 495,
        "target_term": "Gradient",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在模型训练过程中，我们讨论了如何处理输入文本的语法结构。",
        "sentence_A": "在处理输入文本的时候，我们需要注意输入的 Grammar，这样才能确保模型的准确性。",
        "sentence_B": "在处理输入文本的时候，我们需要注意输入的语法结构，这样才能确保模型的准确性。",
        "id": 496,
        "target_term": "Grammar",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在进行模型训练时，我们需要确保数据的质量。",
        "sentence_A": "在数据清洗阶段，我们特别关注数据的 grammatical 正确性，这直接影响模型的性能。",
        "sentence_B": "在数据清洗阶段，我们特别关注数据的语法正确性，这直接影响模型的性能。",
        "id": 497,
        "target_term": "grammatical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论如何确保模型的输出与实际数据保持一致。",
        "sentence_A": "我们在训练模型时，特别注意让输出结果保持 Grounded，确保模型的预测结果与实际数据相符。",
        "sentence_B": "我们在训练模型时，特别注意让输出结果保持接地，确保模型的预测结果与实际数据相符。",
        "id": 498,
        "target_term": "Grounded",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到使用HAL来优化模型性能。",
        "sentence_A": "我们这次训练模型的时候，可以考虑用 HAL 来优化一下，这样可能会提高模型的稳定性和效率。",
        "sentence_B": "我们这次训练模型的时候，可以考虑使用半监督学习（HAL）来优化，这样可能会提高模型的稳定性和效率。",
        "id": 499,
        "target_term": "HAL",
        "is_hardcore": true
    },
    {
        "topic": "Hierarchical Attention Network (HAN)",
        "prefix": "在模型训练过程中，我们讨论如何优化模型的注意力机制。",
        "sentence_A": "我们在训练这个模型时，发现 HAN 的效果非常好，特别是在处理长文本时。",
        "sentence_B": "我们在训练这个模型时，发现层次注意力网络（HAN）的效果非常好，特别是在处理长文本时。",
        "id": 500,
        "target_term": "HAN",
        "is_hardcore": true
    },
    {
        "topic": "Human Activity Recognition",
        "prefix": "在模型训练过程中，我们讨论了如何优化HAR模型的性能。",
        "sentence_A": "在训练过程中，我们发现通过增加数据的多样性可以显著提升 HAR 模型的准确性。",
        "sentence_B": "在训练过程中，我们发现通过增加数据的多样性可以显著提升人体活动识别模型的准确性。",
        "id": 501,
        "target_term": "HAR",
        "is_hardcore": true
    },
    {
        "topic": "Homomorphic Encryption",
        "prefix": "在一次模型训练的讨论中，团队成员讨论如何保护数据隐私。",
        "sentence_A": "我们可以在数据加密阶段使用 HE，这样在训练过程中数据始终是加密的。",
        "sentence_B": "我们可以在数据加密阶段使用同态加密，这样在训练过程中数据始终是加密的。",
        "id": 502,
        "target_term": "HE",
        "is_hardcore": false
    },
    {
        "topic": "Optimization Techniques in Machine Learning",
        "prefix": "在讨论模型优化技术时，团队成员提到了一个关键的数学概念。",
        "sentence_A": "我们在优化模型的时候，使用 HESSIAN 矩阵来分析二阶导数，这有助于我们更好地理解模型的收敛性。",
        "sentence_B": "我们在优化模型的时候，使用海森矩阵来分析二阶导数，这有助于我们更好地理解模型的收敛性。",
        "id": 503,
        "target_term": "HESSIAN",
        "is_hardcore": true
    },
    {
        "topic": "HMM in Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到使用HMM进行序列标注。",
        "sentence_A": "我们这次的序列标注任务，可以考虑用 HMM 来优化模型的性能。",
        "sentence_B": "我们这次的序列标注任务，可以考虑使用隐马尔可夫模型来优化模型的性能。",
        "id": 504,
        "target_term": "HMM",
        "is_hardcore": true
    },
    {
        "topic": "Hierarchical Neural Network",
        "prefix": "在讨论模型架构时",
        "sentence_A": "我们这次的模型采用了 HNN 结构，可以有效地处理多层级的特征。",
        "sentence_B": "我们这次的模型采用了层次神经网络结构，可以有效地处理多层级的特征。",
        "id": 505,
        "target_term": "HNN",
        "is_hardcore": true
    },
    {
        "topic": "HRRN in Model Training",
        "prefix": "在讨论模型训练的调度策略时",
        "sentence_A": "我们在模型训练的调度策略中使用了 HRRN，这样可以更高效地利用资源。",
        "sentence_B": "我们在模型训练的调度策略中使用了最高响应比优先（HRRN），这样可以更高效地利用资源。",
        "id": 506,
        "target_term": "HRRN",
        "is_hardcore": true
    },
    {
        "topic": "HTN Planning in AI",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练模型时，使用了 HTN 规划来提高任务的复杂度和灵活性。",
        "sentence_B": "我们在训练模型时，使用了分层任务网络（HTN）规划来提高任务的复杂度和灵活性。",
        "id": 507,
        "target_term": "HTN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练 HUBERT 模型时，发现数据清洗非常重要，不干净的数据会影响模型的性能。",
        "sentence_B": "我们在训练基于HuBERT的模型时，发现数据清洗非常重要，不干净的数据会影响模型的性能。",
        "id": 508,
        "target_term": "HUBERT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，发现使用 Hao 方法可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练模型时，发现使用郝方法可以显著提高模型的收敛速度。",
        "id": 509,
        "target_term": "Hao",
        "is_hardcore": true
    },
    {
        "topic": "Data Annotation",
        "prefix": "在进行数据标注时，我们需要注意识别有害内容。",
        "sentence_A": "在标注过程中，我们要特别注意标记出那些 Harmful 的内容，确保模型不会学到这些东西。",
        "sentence_B": "在标注过程中，我们要特别注意标记出那些有害的内容，确保模型不会学到这些东西。",
        "id": 510,
        "target_term": "Harmful",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现某些数据样本对结果的负面影响较大。",
        "sentence_A": "在模型训练过程中，我们发现某些数据样本的 Harmfulnes 比较大，需要进一步处理。",
        "sentence_B": "在模型训练过程中，我们发现某些数据样本的有害性比较大，需要进一步处理。",
        "id": 511,
        "target_term": "Harmfulnes",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员提到",
        "sentence_A": "我们在训练这个情感分析模型时，发现处理 'Hate' 语句特别棘手。",
        "sentence_B": "我们在训练这个情感分析模型时，发现处理“仇恨”语句特别棘手。",
        "id": 512,
        "target_term": "",
        "is_hardcore": false
    },
    {
        "topic": "Hebbian Learning",
        "prefix": "在模型训练过程中，我们讨论了不同的学习算法。",
        "sentence_A": "我们在模型训练中使用了 Hebbian 学习算法，效果相当不错。",
        "sentence_B": "我们在模型训练中使用了赫布学习算法，效果相当不错。",
        "id": 513,
        "target_term": "Hebbian",
        "is_hardcore": true
    },
    {
        "topic": "Hierarchical Models",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们这次可以尝试用 Hierarchical 的方法来优化模型的层级结构，这样可以更好地处理多尺度的问题。",
        "sentence_B": "我们这次可以尝试用层次化的方法来优化模型的层级结构，这样可以更好地处理多尺度的问题。",
        "id": 514,
        "target_term": "Hierarchical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型结构时",
        "sentence_A": "我们需要考虑模型的 Hierarchy，确保每一层都能有效提取特征。",
        "sentence_B": "我们需要考虑模型的层次结构，确保每一层都能有效提取特征。",
        "id": 515,
        "target_term": "Hierarchy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集划分时",
        "sentence_A": "我们这次用的 Holdout 方法，把数据集分成了训练集和测试集，确保模型在未见过的数据上表现良好。",
        "sentence_B": "我们这次使用了留出法，将数据集分成了训练集和测试集，确保模型在未见过的数据上表现良好。",
        "id": 516,
        "target_term": "Holdout",
        "is_hardcore": true
    },
    {
        "topic": "Holographic Technology in AI Models",
        "prefix": "在讨论如何优化全息投影技术的模型时",
        "sentence_A": "我们今天主要讨论一下如何在模型训练中优化 Holographic 投影的效果，特别是在大数据集上。",
        "sentence_B": "我们今天主要讨论一下如何在模型训练中优化全息投影的效果，特别是在大数据集上。",
        "id": 517,
        "target_term": "Holographic",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，讨论数据集的特征一致性问题。",
        "sentence_A": "我们在数据清洗的时候发现，这些特征并不是完全 Homogeneou，这可能会对模型训练造成影响。",
        "sentence_B": "我们在数据清洗的时候发现，这些特征并不是完全同质的，这可能会对模型训练造成影响。",
        "id": 518,
        "target_term": "Homogeneou",
        "is_hardcore": true
    },
    {
        "topic": "Hyperparameter Tuning",
        "prefix": "在模型训练过程中，团队正在讨论如何优化模型的性能。",
        "sentence_A": "我们这次的模型训练，Hparam 的设置对最终效果影响很大，大家一定要认真调参。",
        "sentence_B": "我们这次的模型训练，超参数的设置对最终效果影响很大，大家一定要认真调参。",
        "id": 519,
        "target_term": "Hparam",
        "is_hardcore": true
    },
    {
        "topic": "Hyperparameter Tuning",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化模型性能。",
        "sentence_A": "这次我们得好好调调 Hyperparameter，看看能不能提升模型的精度。",
        "sentence_B": "这次我们得好好调整超参数，看看能不能提升模型的精度。",
        "id": 520,
        "target_term": "Hyperparameter",
        "is_hardcore": true
    },
    {
        "topic": "Hyperparameters Tuning",
        "prefix": "在模型训练过程中，团队遇到了性能瓶颈。",
        "sentence_A": "为了提升模型的性能，我们决定调整 Hyperparameter，看看能不能找到更好的配置。",
        "sentence_B": "为了提升模型的性能，我们决定调整超参数，看看能不能找到更好的配置。",
        "id": 521,
        "target_term": "Hyperparameter",
        "is_hardcore": true
    },
    {
        "topic": "IAM Integration in Model Deployment",
        "prefix": "在讨论模型部署的安全性时，团队成员提到IAM的集成问题。",
        "sentence_A": "我们在模型部署时，需要确保 IAM 集成得当，以保证权限管理的安全性和灵活性。",
        "sentence_B": "我们在模型部署时，需要确保身份和访问管理（IAM）集成得当，以保证权限管理的安全性和灵活性。",
        "id": 522,
        "target_term": "IAM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到需要优化IC的通信效率。",
        "sentence_A": "我们需要优化 IC 的通信效率，这样才能在大规模训练中减少延迟。",
        "sentence_B": "我们需要优化集成电路的通信效率，这样才能在大规模训练中减少延迟。",
        "id": 523,
        "target_term": "IC",
        "is_hardcore": false
    },
    {
        "topic": "ICT in Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们在部署模型时需要确保服务器的 ICT 基础设施是稳定的，这样才能保证模型的高性能运行。",
        "sentence_B": "我们在部署模型时需要确保服务器的信息通信技术（ICT）基础设施是稳定的，这样才能保证模型的高性能运行。",
        "id": 524,
        "target_term": "ICT",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing and Model Training",
        "prefix": "在一次数据清洗和模型训练的过程中，团队讨论如何处理用户ID的问题。",
        "sentence_A": "我们这次数据清洗时，需要特别注意用户的 ID，确保在模型训练中不会出现数据泄露的问题。",
        "sentence_B": "我们这次数据清洗时，需要特别注意用户的用户标识，确保在模型训练中不会出现数据泄露的问题。",
        "id": 525,
        "target_term": "ID",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论会上，团队成员正在讨论如何优化模型的训练过程。",
        "sentence_A": "我们这次的模型训练需要遵循 IDEAL 原则，确保每一个环节都尽可能地高效和准确。",
        "sentence_B": "我们这次的模型训练需要遵循理想原则，确保每一个环节都尽可能地高效和准确。",
        "id": 526,
        "target_term": "IDEAL",
        "is_hardcore": true
    },
    {
        "topic": "Intrusion Detection System (IDS)",
        "prefix": "在进行模型训练时，我们讨论了如何提高入侵检测系统的性能。",
        "sentence_A": "在训练模型时，我们发现使用更先进的特征提取方法可以显著提升 IDS 的检测精度。",
        "sentence_B": "在训练模型时，我们发现使用更先进的特征提取方法可以显著提升入侵检测系统（IDS）的检测精度。",
        "id": 527,
        "target_term": "IDS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的独立性和同分布性时，",
        "sentence_A": "我们需要确保训练数据是 IID 的，这样才能保证模型的泛化能力。",
        "sentence_B": "我们需要确保训练数据是独立同分布（IID）的，这样才能保证模型的泛化能力。",
        "id": 528,
        "target_term": "IID",
        "is_hardcore": true
    },
    {
        "topic": "Incremental Learning",
        "prefix": "在讨论模型持续学习能力时",
        "sentence_A": "我们在最新的模型训练中引入了 IL 技术，以实现更好的持续学习能力。",
        "sentence_B": "我们在最新的模型训练中引入了增量学习技术，以实现更好的持续学习能力。",
        "id": 529,
        "target_term": "IL",
        "is_hardcore": false
    },
    {
        "topic": "Integer Linear Programming",
        "prefix": "在模型训练中讨论优化问题时",
        "sentence_A": "我们可以通过使用 ILP 来解决这个问题，优化模型的训练效率。",
        "sentence_B": "我们可以通过使用整数线性规划来解决这个问题，优化模型的训练效率。",
        "id": 530,
        "target_term": "ILP",
        "is_hardcore": true
    },
    {
        "topic": "IMU Integration in Sensor Fusion",
        "prefix": "在讨论传感器融合算法的优化时",
        "sentence_A": "我们在进行传感器融合算法的优化时，发现 IMU 的数据对姿态估计的精度影响很大。",
        "sentence_B": "我们在进行传感器融合算法的优化时，发现惯性测量单元（IMU）的数据对姿态估计的精度影响很大。",
        "id": 531,
        "target_term": "IMU",
        "is_hardcore": true
    },
    {
        "topic": "ImageNet in Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们这次的模型训练可以考虑用 ImageNet 数据集，这样可以提高模型的泛化能力。",
        "sentence_B": "我们这次的模型训练可以考虑使用 ImageNet 数据集，这样可以提高模型的泛化能力。",
        "id": 532,
        "target_term": "ImageNet",
        "is_hardcore": true
    },
    {
        "topic": "Image Processing in Model Training",
        "prefix": "在讨论模型训练的数据准备时，",
        "sentence_A": "我们需要确保 Image 的预处理步骤是高效的，这样才能保证模型训练的性能。",
        "sentence_B": "我们需要确保图像的预处理步骤是高效的，这样才能保证模型训练的性能。",
        "id": 533,
        "target_term": "Image",
        "is_hardcore": false
    },
    {
        "topic": "Imaging in AI Models",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "在数据预处理阶段，我们特别关注 Imaging 数据的质量，因为这对模型的性能影响很大。",
        "sentence_B": "在数据预处理阶段，我们特别关注成像数据的质量，因为这对模型的性能影响很大。",
        "id": 534,
        "target_term": "Imaging",
        "is_hardcore": true
    },
    {
        "topic": "Imbalanced Data Handling",
        "prefix": "在模型训练过程中，我们遇到了一个典型的问题",
        "sentence_A": "在训练这个分类模型时，我们发现数据集是 Imbalanced 的，这导致模型在少数类上的表现非常差。",
        "sentence_B": "在训练这个分类模型时，我们发现数据集是不平衡的，这导致模型在少数类上的表现非常差。",
        "id": 535,
        "target_term": "Imbalanced",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型对特定噪声的鲁棒性时",
        "sentence_A": "我们的模型需要对这些噪声具有一定的 Immune，这样才能在实际应用中表现稳定。",
        "sentence_B": "我们的模型需要对这些噪声具有一定的免疫性，这样才能在实际应用中表现稳定。",
        "id": 536,
        "target_term": "Immune",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中遇到的问题时",
        "sentence_A": "我们在训练时发现有些样本的 Impairment 比较严重，导致模型的性能下降。",
        "sentence_B": "我们在训练时发现有些样本的损伤比较严重，导致模型的性能下降。",
        "id": 537,
        "target_term": "Impairment",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "在训练模型时，我们需要注意 Implicit 偏置的影响，这可能会导致模型在某些场景下表现不佳。",
        "sentence_B": "在训练模型时，我们需要注意隐式偏置的影响，这可能会导致模型在某些场景下表现不佳。",
        "id": 538,
        "target_term": "Implicit",
        "is_hardcore": true
    },
    {
        "topic": "Feature Selection",
        "prefix": "在模型训练过程中，我们讨论了特征选择的重要性。",
        "sentence_A": "在训练模型时，我们需要注意每个特征的 Importance，这样才能确保模型的性能。",
        "sentence_B": "在训练模型时，我们需要注意每个特征的重要性，这样才能确保模型的性能。",
        "id": 539,
        "target_term": "Importance",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们遇到了许多缺失值问题。",
        "sentence_A": "我们正在用一些高级方法来做 Imputing，确保模型训练时数据的完整性和准确性。",
        "sentence_B": "我们正在使用一些高级方法进行数据填补，确保模型训练时数据的完整性和准确性。",
        "id": 540,
        "target_term": "Imputing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在调整模型的参数时，可以考虑引入一个 Incentive 机制，来提高模型的训练效率。",
        "sentence_B": "我们在调整模型的参数时，可以考虑引入一个激励机制，来提高模型的训练效率。",
        "id": 541,
        "target_term": "Incentive",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现了一些问题。",
        "sentence_A": "这些数据集有些是 Incomplete 的，我们需要填补缺失值才能继续训练模型。",
        "sentence_B": "这些数据集有些是不完整的，我们需要填补缺失值才能继续训练模型。",
        "id": 542,
        "target_term": "Incomplete",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何整合新的特征",
        "sentence_A": "我们在训练模型时，需要考虑如何 Incorporating 新的特征来提高模型的性能。",
        "sentence_B": "我们在训练模型时，需要考虑如何整合新的特征来提高模型的性能。",
        "id": 543,
        "target_term": "Incorporating",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现某些特征之间存在相关性。",
        "sentence_A": "我们需要确保这些特征之间的 Independence，这样才能保证模型的稳定性和准确性。",
        "sentence_B": "我们需要确保这些特征之间的独立性，这样才能保证模型的稳定性和准确性。",
        "id": 544,
        "target_term": "Independence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集时，团队成员提到数据点之间的独立性问题。",
        "sentence_A": "我们在训练模型时，需要确保每个数据点是 Independent 的，这样才能保证模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要确保每个数据点是独立的，这样才能保证模型的泛化能力。",
        "id": 545,
        "target_term": "Independent",
        "is_hardcore": true
    },
    {
        "topic": "Data Indexing",
        "prefix": "在讨论模型训练数据的优化时",
        "sentence_A": "我们可以通过优化数据的 Indice 来提高模型的训练效率。",
        "sentence_B": "我们可以通过优化数据的索引来提高模型的训练效率。",
        "id": 546,
        "target_term": "Indice",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现了一个有趣的现象：",
        "sentence_A": "在处理用户数据时，我们发现每个 Individual 的行为模式非常不同，这对我们模型的泛化能力提出了新的挑战。",
        "sentence_B": "在处理用户数据时，我们发现每个个体的行为模式非常不同，这对我们模型的泛化能力提出了新的挑战。",
        "id": 547,
        "target_term": "Individual",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗的过程中，我们经常需要处理各种类型的信息。",
        "sentence_A": "在数据清洗的时候，我们经常需要处理各种类型的 Information，比如文本、图像和音频。",
        "sentence_B": "在数据清洗的时候，我们经常需要处理各种类型的信息，比如文本、图像和音频。",
        "id": 548,
        "target_term": "Information",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在模型部署前的优化讨论中，团队正在讨论如何提高推理速度。",
        "sentence_A": "我们在做模型优化时，Inference 速度是关键，需要找到一个平衡点来提升性能。",
        "sentence_B": "我们在进行模型优化时，推理速度是关键，需要找到一个平衡点来提升性能。",
        "id": 549,
        "target_term": "Inference",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了一个新工具",
        "sentence_A": "我们最近在用的 Infini 工具，对大规模数据集的处理效率提升明显。",
        "sentence_B": "我们最近在使用的无限工具，对大规模数据集的处理效率提升明显。",
        "id": 550,
        "target_term": "Infini",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数的影响时",
        "sentence_A": "我们需要仔细评估每个参数的 Influence，以确保模型的稳定性和准确性。",
        "sentence_B": "我们需要仔细评估每个参数的影响，以确保模型的稳定性和准确性。",
        "id": 551,
        "target_term": "Influence",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，我们讨论了一个特征的重要性。",
        "sentence_A": "这个特征的 Informativenes 很高，对模型的预测效果有很大帮助。",
        "sentence_B": "这个特征的信息量很高，对模型的预测效果有很大帮助。",
        "id": 552,
        "target_term": "Informativenes",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练的初期阶段，团队正在讨论如何优化模型的初始化过程。",
        "sentence_A": "在模型训练的初期阶段，我们需要注意 Initialization 的方式，以确保模型能够快速收敛。",
        "sentence_B": "在模型训练的初期阶段，我们需要注意初始化的方式，以确保模型能够快速收敛。",
        "id": 553,
        "target_term": "Initialization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练开始前，我们需要确保所有参数都已经正确初始化。",
        "sentence_A": "在模型训练开始前，我们需要确保所有参数都已经正确 initialized。",
        "sentence_B": "在模型训练开始前，我们需要确保所有参数都已经正确初始化。",
        "id": 554,
        "target_term": "initialized",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的内部机制时",
        "sentence_A": "我们在训练过程中，需要特别关注模型的 Inner 层的权重初始化。",
        "sentence_B": "我们在训练过程中，需要特别关注模型的内部层的权重初始化。",
        "id": 555,
        "target_term": "Inner",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Optimization",
        "prefix": "在讨论模型训练和优化的会议上，团队成员正在讨论如何引入新的技术来提升模型性能。",
        "sentence_A": "我们在模型训练中需要更多的 Innovation，这样才能在竞争中保持领先。",
        "sentence_B": "我们在模型训练中需要更多的创新，这样才能在竞争中保持领先。",
        "id": 556,
        "target_term": "Innovation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们这次的模型训练需要特别注意 Instruction 的设计，这直接影响到生成的质量。",
        "sentence_B": "我们这次的模型训练需要特别注意指令的设计，这直接影响到生成的质量。",
        "id": 557,
        "target_term": "Instruction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据预处理的重要性。",
        "sentence_A": "在数据预处理阶段，我们得好好处理这些 Instruction，确保模型训练时不会出问题。",
        "sentence_B": "在数据预处理阶段，我们得好好处理这些指令，确保模型训练时不会出问题。",
        "id": 558,
        "target_term": "Instruction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以在训练过程中引入更多的 Instrument 来监控模型的性能。",
        "sentence_B": "我们可以在训练过程中引入更多的工具来监控模型的性能。",
        "id": 559,
        "target_term": "Instrument",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在数据清洗过程中，我们遇到了一些与保险相关的数据问题。",
        "sentence_A": "我们在数据清洗的时候遇到了一些关于 Insurance 的数据问题，需要进一步处理。",
        "sentence_B": "我们在数据清洗的时候遇到了一些关于保险的数据问题，需要进一步处理。",
        "id": 560,
        "target_term": "Insurance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练中的数学优化问题时",
        "sentence_A": "我们在训练这个模型的时候，需要处理很多关于 Integral 的计算，这直接影响到模型的性能。",
        "sentence_B": "我们在训练这个模型的时候，需要处理很多关于积分的计算，这直接影响到模型的性能。",
        "id": 561,
        "target_term": "Integral",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时，团队成员提到需要确保各个模块之间的平滑衔接。",
        "sentence_A": "在模型部署阶段，我们需要确保各个模块的 Integration 是平滑的，这样才能保证整个系统的稳定运行。",
        "sentence_B": "在模型部署阶段，我们需要确保各个模块的集成是平滑的，这样才能保证整个系统的稳定运行。",
        "id": 562,
        "target_term": "Integration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在日常的模型训练中，我们经常讨论如何提升模型的智能水平。",
        "sentence_A": "我们在训练模型时，特别关注如何提高模型的 Intelligence，特别是在处理复杂任务时。",
        "sentence_B": "我们在训练模型时，特别关注如何提高模型的智能水平，特别是在处理复杂任务时。",
        "id": 563,
        "target_term": "Intelligence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到智能算法的重要性。",
        "sentence_A": "我们在训练模型时，Intelligent 算法的优化非常关键，能够显著提升模型的性能。",
        "sentence_B": "我们在训练模型时，智能算法的优化非常关键，能够显著提升模型的性能。",
        "id": 564,
        "target_term": "Intelligent",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到用户与系统的互动对模型性能的影响。",
        "sentence_A": "在训练推荐系统时，我们发现用户和系统的 Interaction 对模型的性能提升非常关键。",
        "sentence_B": "在训练推荐系统时，我们发现用户与系统的交互对模型的性能提升非常关键。",
        "id": 565,
        "target_term": "Interaction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化用户与系统的交互数据。",
        "sentence_A": "在训练模型时，我们发现优化用户与系统的 Interaction 数据对提升模型性能非常重要。",
        "sentence_B": "在训练模型时，我们发现优化用户与系统的交互数据对提升模型性能非常重要。",
        "id": 566,
        "target_term": "Interaction",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretability",
        "prefix": "在模型训练过程中，团队讨论如何提高模型的可解释性。",
        "sentence_A": "我们在模型训练时，不仅要关注性能，还得提升模型的 Interpretability，这样才能更好地理解模型的决策过程。",
        "sentence_B": "我们在模型训练时，不仅要关注性能，还得提升模型的可解释性，这样才能更好地理解模型的决策过程。",
        "id": 567,
        "target_term": "Interpretability",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretation",
        "prefix": "在一次模型训练会议上，团队讨论如何提高模型的可解释性。",
        "sentence_A": "我们这次要重点讨论一下模型的 Interpretation，确保我们的业务方能理解模型的决策过程。",
        "sentence_B": "我们这次要重点讨论一下模型的可解释性，确保我们的业务方能理解模型的决策过程。",
        "id": 568,
        "target_term": "Interpretation",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference",
        "prefix": "在讨论模型推理优化的时候",
        "sentence_A": "我们在优化模型的推理速度时，发现 Interpreter 的性能瓶颈很明显。",
        "sentence_B": "我们在优化模型的推理速度时，发现解释器的性能瓶颈很明显。",
        "id": 569,
        "target_term": "Interpreter",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretability",
        "prefix": "在模型训练过程中，我们需要确保模型的可解释性，以便更好地理解模型的行为。",
        "sentence_A": "在训练过程中，我们不仅要关注模型的性能，还要确保 Interpreting 是透明的，这样才能更好地理解模型的行为。",
        "sentence_B": "在训练过程中，我们不仅要关注模型的性能，还要确保模型的可解释性是透明的，这样才能更好地理解模型的行为。",
        "id": 570,
        "target_term": "Interpreting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中如何处理数据异常时",
        "sentence_A": "为了处理这些异常数据，我们可以在训练过程中引入一些 Intervention 措施。",
        "sentence_B": "为了处理这些异常数据，我们可以在训练过程中引入一些干预措施。",
        "id": 571,
        "target_term": "Intervention",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练超参数设置时",
        "sentence_A": "我们通常在设置 learning rate 的 decay 时，会考虑每个 interval 的表现，确保模型在不同的训练阶段都能稳定收敛。",
        "sentence_B": "我们通常在设置学习率的衰减时，会考虑每个间隔的表现，确保模型在不同的训练阶段都能稳定收敛。",
        "id": 572,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到逆运算的重要性。",
        "sentence_A": "在训练过程中，我们需要用到 Inverse 操作来调整参数。",
        "sentence_B": "在训练过程中，我们需要用到逆运算来调整参数。",
        "id": 573,
        "target_term": "Inverse",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一些异常情况，需要进一步排查。",
        "sentence_A": "我们正在 Investigating 这些异常情况，确保模型训练的稳定性。",
        "sentence_B": "我们正在调查这些异常情况，确保模型训练的稳定性。",
        "id": 574,
        "target_term": "Investigating",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "这次的模型训练，我们选的数据集要尽量多一些，因为涉及到的数据量越大，模型的泛化能力通常会更好。",
        "sentence_B": "这次的模型训练，我们选的数据集要尽量多一些，因为涉及的数据量越大，模型的泛化能力通常会更好。",
        "id": 575,
        "term_cleaned": "N/A",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的复杂性时，团队成员提到了涉及多个数据集的训练过程。",
        "sentence_A": "这次训练 Involving 多个数据集，我们需要确保每个数据集的特性和分布都被充分考虑。",
        "sentence_B": "这次训练涉及多个数据集，我们需要确保每个数据集的特性和分布都被充分考虑。",
        "id": 576,
        "target_term": "Involving",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在进行数据清洗时，我们发现了一些问题",
        "sentence_A": "在进行数据清洗时，我们发现了一些 Irrelevant 的数据，需要过滤掉。",
        "sentence_B": "在进行数据清洗时，我们发现了一些无关的数据，需要过滤掉。",
        "id": 577,
        "target_term": "Irrelevant",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现有些数据项需要特别处理。",
        "sentence_A": "在数据清洗过程中，我们发现有些 Item 需要特别处理。",
        "sentence_B": "在数据清洗过程中，我们发现有些数据项需要特别处理。",
        "id": 578,
        "target_term": "Item",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在团队讨论模型训练策略时，",
        "sentence_A": "我们在训练模型时采用了 Iterative 的方法，每次迭代后都会根据反馈调整超参数。",
        "sentence_B": "我们在训练模型时采用了迭代的方法，每次迭代后都会根据反馈调整超参数。",
        "id": 579,
        "target_term": "Iterative",
        "is_hardcore": true
    },
    {
        "topic": "JACCARD Similarity in Data Cleaning",
        "prefix": "在数据清洗过程中，我们经常需要评估两组数据的相似度。",
        "sentence_A": "我们在数据清洗的时候，用 JACCARD 系数来评估两组数据的相似度，这样可以更准确地过滤掉重复的数据。",
        "sentence_B": "我们在数据清洗的时候，用 JACCARD 系数来评估两组数据的相似度，这样可以更准确地过滤掉重复的数据。",
        "id": 580,
        "target_term": "JACCARD",
        "is_hardcore": true
    },
    {
        "topic": "Jaccard Index",
        "prefix": "在模型训练过程中，我们经常需要评估两个集合的相似度。",
        "sentence_A": "在数据预处理阶段，我们通常用 Jaccard 指数来计算两个集合的相似度。",
        "sentence_B": "在数据预处理阶段，我们通常用 Jaccard 指数来计算两个集合的相似度。",
        "id": 581,
        "target_term": "Jaccard",
        "is_hardcore": true
    },
    {
        "topic": "Joint Distribution in Model Training",
        "prefix": "在讨论多变量分布的模型训练时，团队成员提到了联合分布的重要性。",
        "sentence_A": "在训练多变量模型时，我们需要注意 Joint 分布的特性，这样才能更好地捕捉变量之间的关系。",
        "sentence_B": "在训练多变量模型时，我们需要注意联合分布的特性，这样才能更好地捕捉变量之间的关系。",
        "id": 582,
        "target_term": "Joint",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何评估模型的性能。",
        "sentence_A": "我们用了一个新的方法来 Judge 模型的准确性，感觉效果不错。",
        "sentence_B": "我们使用了一种新的方法来评估模型的准确性，感觉效果不错。",
        "id": 583,
        "target_term": "Judge",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练阶段，团队正在讨论如何评估模型的准确性。",
        "sentence_A": "在训练过程中，我们还需要关注 Judging 模型的性能，确保它在各种场景下都能表现良好。",
        "sentence_B": "在训练过程中，我们还需要关注评估模型的性能，确保它在各种场景下都能表现良好。",
        "id": 584,
        "target_term": "Judging",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何处理不确定的数据点。",
        "sentence_A": "在训练模型时，我们需要对不确定的数据点做出 Judgment，以确保模型的鲁棒性。",
        "sentence_B": "在训练模型时，我们需要对不确定的数据点做出判断，以确保模型的鲁棒性。",
        "id": 585,
        "target_term": "Judgment",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中遇到的问题时",
        "sentence_A": "我们在训练过程中遇到了一些 Jumping 现象，导致模型的损失函数波动很大。",
        "sentence_B": "我们在训练过程中遇到了一些跳跃现象，导致模型的损失函数波动很大。",
        "id": 586,
        "target_term": "Jumping",
        "is_hardcore": true
    },
    {
        "topic": "Knowledge Graph",
        "prefix": "在模型训练过程中，我们讨论了知识图谱的构建和优化。",
        "sentence_A": "我们在训练模型时，特别关注了如何高效构建和优化 KG，以提升模型的推理能力。",
        "sentence_B": "我们在训练模型时，特别关注了如何高效构建和优化知识图谱，以提升模型的推理能力。",
        "id": 587,
        "target_term": "KG",
        "is_hardcore": false
    },
    {
        "topic": "Knowledge Graph Embedding",
        "prefix": "在模型训练过程中，我们讨论如何优化知识图谱嵌入模型的性能。",
        "sentence_A": "在训练 KGE 模型时，我们发现通过增加负样本的数量可以显著提高模型的精度。",
        "sentence_B": "在训练知识图谱嵌入模型时，我们发现通过增加负样本的数量可以显著提高模型的精度。",
        "id": 588,
        "target_term": "KGE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到了KL散度的使用。",
        "sentence_A": "我们在训练这个模型的时候，发现使用 KL divergence 可以更好地优化损失函数。",
        "sentence_B": "我们在训练这个模型的时候，发现使用KL散度可以更好地优化损失函数。",
        "id": 589,
        "target_term": "KL divergence",
        "is_hardcore": true
    },
    {
        "topic": "KNN Algorithm in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了KNN算法的应用。",
        "sentence_A": "我们在训练这个分类模型时，尝试了用 KNN 来提高准确率。",
        "sentence_B": "我们在训练这个分类模型时，尝试了用K近邻算法来提高准确率。",
        "id": 590,
        "target_term": "KNN",
        "is_hardcore": true
    },
    {
        "topic": "Key Results in OKR Framework",
        "prefix": "在团队的季度目标讨论会上，项目经理提到了OKR框架中的KR部分。",
        "sentence_A": "咱们的 KR 需要明确，这样才能确保每个团队成员都清楚自己的目标。",
        "sentence_B": "我们的关键结果需要明确，这样才能确保每个团队成员都清楚自己的目标。",
        "id": 591,
        "target_term": "KR",
        "is_hardcore": false
    },
    {
        "topic": "Kernel Ridge Regression",
        "prefix": "在模型训练过程中，团队讨论如何优化回归模型的性能。",
        "sentence_A": "我们这次模型训练中，可以考虑用 KRR 来提升回归效果，毕竟它的正则化能力很强。",
        "sentence_B": "我们这次模型训练中，可以考虑使用核岭回归（KRR）来提升回归效果，毕竟它的正则化能力很强。",
        "id": 592,
        "target_term": "KRR",
        "is_hardcore": true
    },
    {
        "topic": "Knowledge Representation",
        "prefix": "在模型训练中讨论知识表示的重要性",
        "sentence_A": "在训练模型时，我们不仅需要大量的数据，还需要有效表示 Knowledge，这样才能提高模型的泛化能力。",
        "sentence_B": "在训练模型时，我们不仅需要大量的数据，还需要有效地表示知识，这样才能提高模型的泛化能力。",
        "id": 593,
        "target_term": "Knowledge",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在训练模型时，决定使用包含 LAB 标注的图像数据集，这样可以更好地捕捉颜色信息。",
        "sentence_B": "我们在训练模型时，决定使用包含实验室颜色空间（LAB）标注的图像数据集，这样可以更好地捕捉颜色信息。",
        "id": 594,
        "target_term": "LAB",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化大型语言模型的训练效率。",
        "sentence_A": "我们正在研究如何通过优化 LAM 的参数配置来提高训练速度。",
        "sentence_B": "我们正在研究如何通过优化大型语言模型（LAM）的参数配置来提高训练速度。",
        "id": 595,
        "target_term": "LAM",
        "is_hardcore": true
    },
    {
        "topic": "LAN in AI Development",
        "prefix": "在讨论模型部署的网络环境时",
        "sentence_A": "我们在部署模型时，需要确保服务器之间的 LAN 连接稳定，这样才能保证数据传输的效率。",
        "sentence_B": "在部署模型时，需要确保服务器之间的局域网连接稳定，这样才能保证数据传输的效率。",
        "id": 596,
        "target_term": "LAN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化模型的性能。",
        "sentence_A": "我们正在研究如何通过改进 LAS 模块来提升模型的准确性。",
        "sentence_B": "我们正在研究如何通过改进听写注意力机制（LAS）模块来提升模型的准确性。",
        "id": 597,
        "target_term": "LAS",
        "is_hardcore": true
    },
    {
        "topic": "Latent Variables in Model Training",
        "prefix": "在模型训练过程中讨论潜在变量的重要性",
        "sentence_A": "我们在训练模型时，LATENT 变量的处理非常重要，它直接影响模型的泛化能力。",
        "sentence_B": "我们在训练模型时，潜在变量的处理非常重要，它直接影响模型的泛化能力。",
        "id": 598,
        "target_term": "LATENT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化时",
        "sentence_A": "我们在训练 LAVIS 模型时，发现使用混合精度训练可以显著提升训练速度，同时在推理阶段通过模型量化进一步优化性能。",
        "sentence_B": "我们在训练多模态预训练模型时，发现使用混合精度训练可以显著提升训练速度，同时在推理阶段通过模型量化进一步优化性能。",
        "id": 599,
        "target_term": "LAVIS",
        "is_hardcore": true
    },
    {
        "topic": "LBFGS Optimization in Model Training",
        "prefix": "在讨论模型训练的优化算法时",
        "sentence_A": "我们这次模型训练用的是 LBFGS，效果还不错。",
        "sentence_B": "我们这次模型训练使用的是拟牛顿法（LBFGS），效果还不错。",
        "id": 600,
        "target_term": "LBFGS",
        "is_hardcore": true
    },
    {
        "topic": "LBP in Image Processing",
        "prefix": "在模型训练过程中，我们讨论了如何优化特征提取算法。",
        "sentence_A": "我们在模型训练中使用了 LBP 特征，发现它在人脸检测任务上表现非常出色。",
        "sentence_B": "我们在模型训练中使用了局部二值模式（LBP）特征，发现它在人脸检测任务上表现非常出色。",
        "id": 601,
        "target_term": "LBP",
        "is_hardcore": true
    },
    {
        "topic": "Lowest Common Ancestor",
        "prefix": "在讨论模型的树结构优化时",
        "sentence_A": "我们在处理这棵树的时候，需要找到每个节点的 LCA，这样才能确保我们的模型在推理时更高效。",
        "sentence_B": "我们在处理这棵树的时候，需要找到每个节点的最近公共祖先（LCA），这样才能确保我们的模型在推理时更高效。",
        "id": 602,
        "target_term": "LCA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练的效率时",
        "sentence_A": "我们在模型训练过程中发现，使用 LCM 可以显著提高训练速度。",
        "sentence_B": "我们在模型训练过程中发现，使用最小公倍数（LCM）可以显著提高训练速度。",
        "id": 603,
        "target_term": "LCM",
        "is_hardcore": true
    },
    {
        "topic": "LCP in Model Training",
        "prefix": "在讨论模型训练的性能优化时",
        "sentence_A": "我们在优化模型的训练速度时，发现 LCP 对整体性能提升有显著影响。",
        "sentence_B": "我们在优化模型的训练速度时，发现最长公共前缀（LCP）对整体性能提升有显著影响。",
        "id": 604,
        "target_term": "LCP",
        "is_hardcore": true
    },
    {
        "topic": "Longest Common Subsequence",
        "prefix": "在讨论模型训练的数据预处理阶段，团队成员在讨论如何优化数据对齐问题时",
        "sentence_A": "我们可以用 LCS 算法来优化数据对齐，这样可以提高训练效率。",
        "sentence_B": "我们可以用最长公共子序列算法来优化数据对齐，这样可以提高训练效率。",
        "id": 605,
        "target_term": "LCS",
        "is_hardcore": true
    },
    {
        "topic": "LDA in Model Training",
        "prefix": "在讨论如何优化文本主题模型的训练时",
        "sentence_A": "我们在用 LDA 模型进行主题建模时，发现数据预处理对结果影响很大。",
        "sentence_B": "我们在使用潜在狄利克雷分配（LDA）模型进行主题建模时，发现数据预处理对结果影响很大。",
        "id": 606,
        "target_term": "LDA",
        "is_hardcore": true
    },
    {
        "topic": "LDM in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了LDM的使用。",
        "sentence_A": "我们在训练这个模型的时候，用到了 LDM，效果还不错。",
        "sentence_B": "我们在训练这个模型的时候，使用了潜在扩散模型（LDM），效果还不错。",
        "id": 607,
        "target_term": "LDM",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，我们讨论了如何优化模型的性能指标。",
        "sentence_A": "我们发现通过调整参数可以显著提高模型的 LIFT，这对于我们的业务目标非常重要。",
        "sentence_B": "我们发现通过调整参数可以显著提高模型的提升度，这对于我们的业务目标非常重要。",
        "id": 608,
        "target_term": "LIFT",
        "is_hardcore": true
    },
    {
        "topic": "LIF Neuron Model",
        "prefix": "在模型训练过程中，团队讨论了不同神经元模型的优劣。",
        "sentence_A": "我们考虑使用 LIF 模型来提高模拟神经网络的效率，因为它在平衡准确性和计算成本方面表现很好。",
        "sentence_B": "我们考虑使用LIF模型来提高模拟神经网络的效率，因为它在平衡准确性和计算成本方面表现很好。",
        "id": 609,
        "target_term": "LIF",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretability",
        "prefix": "在模型训练过程中，我们经常需要解释模型的预测结果。",
        "sentence_A": "我们在训练模型时，使用了 LIME 来帮助我们理解模型的预测逻辑。",
        "sentence_B": "我们在训练模型时，使用了局部可解释模型（LIME）来帮助我们理解模型的预测逻辑。",
        "id": 610,
        "target_term": "LIME",
        "is_hardcore": true
    },
    {
        "topic": "Linear Algebra in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们这次的优化重点是调整 LINEAR 层的权重，以提高模型的收敛速度。",
        "sentence_B": "我们这次的优化重点是调整线性层的权重，以提高模型的收敛速度。",
        "id": 611,
        "target_term": "LINEAR",
        "is_hardcore": true
    },
    {
        "topic": "LIP",
        "prefix": "在讨论模型训练时，团队成员提到了LIP的重要性。",
        "sentence_A": "在训练这个模型时，我们一定要注意 LIP 的稳定性，这直接影响到最终的模型性能。",
        "sentence_B": "在训练这个模型时，我们一定要注意局部输入平滑性的稳定性，这直接影响到最终的模型性能。",
        "id": 612,
        "target_term": "LIP",
        "is_hardcore": true
    },
    {
        "topic": "LISP in AI Development",
        "prefix": "在讨论模型训练的数据预处理时，团队提到了一种经典编程语言。",
        "sentence_A": "我们在数据清洗阶段可以用 LISP 来处理一些复杂的数据结构，效率会高很多。",
        "sentence_B": "我们在数据清洗阶段可以使用 LISP 来处理一些复杂的数据结构，效率会高很多。",
        "id": 613,
        "target_term": "LISP",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率问题时",
        "sentence_A": "为了提高训练速度，我们决定用更高效的 LL 优化器来替换现有的 SGD 优化器。",
        "sentence_B": "为了提高训练速度，我们决定用更高效的梯度下降（Gradient Descent, GD）优化器来替换现有的随机梯度下降（Stochastic Gradient Descent, SGD）优化器。",
        "id": 614,
        "target_term": "LL",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论关于模型训练的优化方案。",
        "sentence_A": "我们在训练 LLAMA 模型时，发现它的收敛速度比预期的要慢。",
        "sentence_B": "我们在训练LLAMA模型时，发现它的收敛速度比预期的要慢。",
        "id": 615,
        "target_term": "LLAMA",
        "is_hardcore": true
    },
    {
        "topic": "LLM Fine-Tuning",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "我们在训练 LLM 时发现，通过增加数据量和调整超参数，可以显著提高模型的性能。",
        "sentence_B": "我们在训练语言模型时发现，通过增加数据量和调整超参数，可以显著提高模型的性能。",
        "id": 616,
        "target_term": "LLM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Optimization",
        "prefix": "在模型训练过程中，团队讨论了如何优化大模型的性能。",
        "sentence_A": "我们正在研究如何通过更好的数据预处理来提升 LLM 的训练效率。",
        "sentence_B": "我们正在研究如何通过更好的数据预处理来提升大语言模型的训练效率。",
        "id": 617,
        "target_term": "LLM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化模型的性能。",
        "sentence_A": "我们在训练模型时，发现使用 LME 可以显著提升模型的泛化能力。",
        "sentence_B": "我们在训练模型时，发现使用长短期记忆网络（LSTM）可以显著提升模型的泛化能力。",
        "id": 618,
        "target_term": "LME",
        "is_hardcore": true
    },
    {
        "topic": "Low-Rank Matrix Inversion",
        "prefix": "在讨论模型优化策略时",
        "sentence_A": "我们在模型训练中使用了 LMI 技术来加速低秩矩阵的逆运算，效果非常明显。",
        "sentence_B": "我们在模型训练中使用了低秩矩阵逆技术来加速低秩矩阵的逆运算，效果非常明显。",
        "id": 619,
        "target_term": "LMI",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据增强策略时",
        "sentence_A": "我们这次可以试试 LORAS，看看能不能提升模型的泛化能力。",
        "sentence_B": "我们这次可以试试局部随机采样技术（LORAS），看看能不能提升模型的泛化能力。",
        "id": 620,
        "target_term": "LORAS",
        "is_hardcore": true
    },
    {
        "topic": "Line-of-Sight (LOS) in Wireless Communication",
        "prefix": "在讨论无线通信模型的优化方案时，",
        "sentence_A": "我们需要考虑 LOS 的影响，这样才能确保模型在实际部署时的性能。",
        "sentence_B": "我们需要考虑视距（LOS）的影响，这样才能确保模型在实际部署时的性能。",
        "id": 621,
        "target_term": "LOS",
        "is_hardcore": true
    },
    {
        "topic": "Low Precision Training",
        "prefix": "在讨论模型训练的精度问题时",
        "sentence_A": "我们在训练模型时采用了 LP 技术，这样可以显著减少内存占用和计算时间。",
        "sentence_B": "我们在训练模型时采用了低精度技术，这样可以显著减少内存占用和计算时间。",
        "id": 622,
        "target_term": "LP",
        "is_hardcore": false
    },
    {
        "topic": "LQR Control in AI Systems",
        "prefix": "在讨论模型控制策略时，团队成员提到了LQR技术的应用。",
        "sentence_A": "我们这次在模型训练中使用了 LQR，效果非常不错。",
        "sentence_B": "我们在模型训练中使用了线性二次调节器（LQR），效果非常不错。",
        "id": 623,
        "target_term": "LQR",
        "is_hardcore": true
    },
    {
        "topic": "Logistic Regression",
        "prefix": "在讨论模型训练的优化方案时，团队成员提到了LR的使用。",
        "sentence_A": "在处理这个分类问题时，我们考虑用 LR 作为基线模型，看看效果如何。",
        "sentence_B": "在处理这个分类问题时，我们考虑用逻辑回归作为基线模型，看看效果如何。",
        "id": 624,
        "target_term": "LR",
        "is_hardcore": false
    },
    {
        "topic": "Learning Rate Scheduling",
        "prefix": "在讨论模型训练的参数优化时",
        "sentence_A": "我们在训练过程中使用了 LRS，发现它对模型的收敛速度有显著影响。",
        "sentence_B": "我们在训练过程中使用了学习率调度（LRS），发现它对模型的收敛速度有显著影响。",
        "id": 625,
        "target_term": "LRS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的代码评审中，团队成员讨论如何优化学习率策略。",
        "sentence_A": "我觉得我们可以试试用 LRT 来动态调整学习率，这样模型收敛可能会更快。",
        "sentence_B": "我觉得我们可以试试用学习率退火（Learning Rate Annealing, LRT）来动态调整学习率，这样模型收敛可能会更快。",
        "id": 626,
        "target_term": "LRT",
        "is_hardcore": true
    },
    {
        "topic": "Latent Semantic Analysis",
        "prefix": "在模型训练过程中，我们讨论了如何处理高维稀疏数据的问题。",
        "sentence_A": "我们在处理高维稀疏数据时，尝试使用了 LSA 方法，效果还不错。",
        "sentence_B": "我们在处理高维稀疏数据时，尝试使用了潜在语义分析方法，效果还不错。",
        "id": 627,
        "target_term": "LSA",
        "is_hardcore": true
    },
    {
        "topic": "Locality Sensitive Hashing",
        "prefix": "在讨论模型训练中的数据处理方法时",
        "sentence_A": "我们在模型训练中使用了 LSH 来加速近似最近邻搜索，效果非常显著。",
        "sentence_B": "我们在模型训练中使用了局部敏感哈希（LSH）来加速近似最近邻搜索，效果非常显著。",
        "id": 628,
        "target_term": "LSH",
        "is_hardcore": true
    },
    {
        "topic": "LSTM in Model Training",
        "prefix": "在讨论模型训练的效率和准确性时，团队成员提到了LSTM的使用。",
        "sentence_A": "我们在训练这个模型时，LSTM 的效果非常好，尤其是处理长序列数据时。",
        "sentence_B": "我们在训练这个模型时，长短期记忆网络的效果非常好，尤其是处理长序列数据时。",
        "id": 629,
        "target_term": "LSTM",
        "is_hardcore": true
    },
    {
        "topic": "LSTM in Model Training",
        "prefix": "在一次团队会议中，讨论模型训练的问题时，资深AI算法工程师提出了关于LSTMs的优化建议。",
        "sentence_A": "我们在训练模型时，LSTM 的梯度消失问题还是挺严重的，建议尝试使用 Layer Normalization 来优化一下。",
        "sentence_B": "我们在训练模型时，长短期记忆网络（LSTMs）的梯度消失问题还是挺严重的，建议尝试使用层归一化（Layer Normalization）来优化一下。",
        "id": 630,
        "target_term": "LSTM",
        "is_hardcore": true
    },
    {
        "topic": "LTL in Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化逻辑公式以提高模型的推理能力。",
        "sentence_A": "在训练模型时，我们发现使用 LTL 可以更好地表达时间逻辑，从而提高模型的推理效率。",
        "sentence_B": "在训练模型时，我们发现使用线性时序逻辑（LTL）可以更好地表达时间逻辑，从而提高模型的推理效率。",
        "id": 631,
        "target_term": "LTL",
        "is_hardcore": true
    },
    {
        "topic": "LVIS Dataset in Model Training",
        "prefix": "在讨论模型训练数据集的选择时",
        "sentence_A": "我们这次用 LVIS 数据集来训练模型，效果肯定会更好。",
        "sentence_B": "我们这次使用 LVIS 数据集来训练模型，效果肯定会更好。",
        "id": 632,
        "target_term": "LVIS",
        "is_hardcore": true
    },
    {
        "topic": "Data Labeling",
        "prefix": "在讨论模型训练数据的质量时",
        "sentence_A": "我们在做数据的 Labeling 时，一定要确保标签的准确性和一致性，这样才能提高模型的性能。",
        "sentence_B": "我们在进行数据标注时，一定要确保标签的准确性和一致性，这样才能提高模型的性能。",
        "id": 633,
        "target_term": "Labeling",
        "is_hardcore": true
    },
    {
        "topic": "Data Labeling",
        "prefix": "在讨论模型训练数据的质量时",
        "sentence_A": "这次的数据集质量不错，Label 都比较准确，模型训练效果应该会很好。",
        "sentence_B": "这次的数据集质量不错，标签都比较准确，模型训练效果应该会很好。",
        "id": 634,
        "target_term": "Label",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时的性能问题",
        "sentence_A": "我们在训练这个模型时，发现有明显的 Lag，特别是在大数据集上。",
        "sentence_B": "我们在训练这个模型时，发现有明显的延迟，特别是在大数据集上。",
        "id": 635,
        "target_term": "Lag",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练的计算资源时",
        "sentence_A": "我们可以在 AWS 上使用 Lambda 来动态调整计算资源，这样可以大大降低训练成本。",
        "sentence_B": "我们可以在 AWS 上使用 Lambda 函数来动态调整计算资源，这样可以大大降低训练成本。",
        "id": 636,
        "target_term": "AWS",
        "is_hardcore": true
    },
    {
        "topic": "Laplacian in Graph Neural Networks",
        "prefix": "在讨论图神经网络的优化时",
        "sentence_A": "我们在训练模型时，发现使用 Laplacian 正则化可以显著提升模型的泛化能力。",
        "sentence_B": "我们在训练模型时，发现使用拉普拉斯正则化可以显著提升模型的泛化能力。",
        "id": 637,
        "target_term": "Laplacian",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在优化模型的推理速度时，特别关注 Latency，因为它直接影响用户体验。",
        "sentence_B": "我们在优化模型的推理速度时，特别关注延迟，因为它直接影响用户体验。",
        "id": 638,
        "target_term": "Latency",
        "is_hardcore": true
    },
    {
        "topic": "Latent Variables in Model Training",
        "prefix": "在模型训练过程中，讨论隐变量的作用",
        "sentence_A": "我们在训练模型时，需要特别关注 latent 变量，因为它们能捕捉到数据中的隐含模式。",
        "sentence_B": "我们在训练模型时，需要特别关注隐变量，因为它们能捕捉到数据中的隐含模式。",
        "id": 639,
        "target_term": "latent",
        "is_hardcore": true
    },
    {
        "topic": "Lattice in Model Optimization",
        "prefix": "在讨论模型优化时，同事提到使用Lattice来提高模型的效率。",
        "sentence_A": "我们可以通过引入 Lattice 来优化模型的推理速度，这样可以显著提高效率。",
        "sentence_B": "我们可以通过引入格子结构来优化模型的推理速度，这样可以显著提高效率。",
        "id": 640,
        "target_term": "Lattice",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Architecture",
        "prefix": "在讨论模型结构时，团队成员提到：",
        "sentence_A": "在这个模型里，我们用了多个 Layer，每个 Layer 都有特定的功能，比如卷积 Layer 和全连接 Layer。",
        "sentence_B": "在这个模型中，我们使用了多个层，每个层都有特定的功能，比如卷积层和全连接层。",
        "id": 641,
        "target_term": "Layer",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们这次的模型调整主要集中在 Layer 的优化上，特别是增加了一些卷积层和归一化层，效果提升明显。",
        "sentence_B": "我们这次的模型调整主要集中在层的优化上，特别是增加了一些卷积层和归一化层，效果提升明显。",
        "id": 642,
        "target_term": "Layer",
        "is_hardcore": true
    },
    {
        "topic": "Data Leakage",
        "prefix": "在模型训练过程中，团队发现了一个潜在的问题。",
        "sentence_A": "我们在数据预处理阶段发现了一个潜在的 Leakage，这可能会导致训练集和测试集之间的数据污染。",
        "sentence_B": "我们在数据预处理阶段发现了一个潜在的数据泄露问题，这可能会导致训练集和测试集之间的数据污染。",
        "id": 643,
        "target_term": "Leakage",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中使用了 Len 来帮助我们更好地理解模型的中间状态。",
        "sentence_B": "我们在训练过程中使用了透镜（Lens）来帮助我们更好地理解模型的中间状态。",
        "id": 644,
        "target_term": "Len",
        "is_hardcore": true
    },
    {
        "topic": "NLP and Syntax Analysis",
        "prefix": "在模型训练过程中，我们讨论了如何处理词法分析的问题。",
        "sentence_A": "在训练模型时，我们发现处理 Lexical 信息对提升模型性能至关重要。",
        "sentence_B": "在训练模型时，我们发现处理词法信息对提升模型性能至关重要。",
        "id": 645,
        "target_term": "Lexical",
        "is_hardcore": true
    },
    {
        "topic": "Libraries in AI Development",
        "prefix": "在模型训练过程中，我们经常讨论各种库的使用和优化。",
        "sentence_A": "我们在模型训练时，经常会用到各种 Librarie，比如 TensorFlow 和 PyTorch，这些 Librarie 能大大提升我们的开发效率。",
        "sentence_B": "我们在模型训练时，经常会用到各种库，比如 TensorFlow 和 PyTorch，这些库能大大提升我们的开发效率。",
        "id": 646,
        "target_term": "Librarie",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要使用各种库来提高效率。",
        "sentence_A": "在训练这个模型时，我们主要依赖于 PyTorch 和 TensorFlow 这两个 Library。",
        "sentence_B": "在训练这个模型时，我们主要依赖于 PyTorch 和 TensorFlow 这两个库。",
        "id": 647,
        "target_term": "PyTorch",
        "is_hardcore": true
    },
    {
        "topic": "Licensing",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们需要确保模型的 Licensing 问题已经解决，这样才能顺利上线。",
        "sentence_B": "我们需要确保模型的许可问题已经解决，这样才能顺利上线。",
        "id": 648,
        "target_term": "Licensing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练模型时需要设置好 batch size 和 epoch 数，还要注意不要超过 GPU 的 memory limit 哦。",
        "sentence_B": "我们在训练模型时需要设置好批量大小和训练轮数，还要注意不要超过 GPU 的内存限制。",
        "id": 649,
        "target_term": "batch size",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据量时",
        "sentence_A": "这次的训练数据是 Limited，我们需要评估这对模型性能的影响。",
        "sentence_B": "这次的训练数据是有限的，我们需要评估这对模型性能的影响。",
        "id": 650,
        "target_term": "Limited",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在模型训练过程中，我们经常需要处理文本数据，这涉及到语言学的知识。",
        "sentence_A": "在训练这个模型时，我们发现 Linguistic 知识对提升模型的泛化能力非常有帮助。",
        "sentence_B": "在训练这个模型时，我们发现语言学知识对提升模型的泛化能力非常有帮助。",
        "id": 651,
        "target_term": "Linguistic",
        "is_hardcore": true
    },
    {
        "topic": "Graph Neural Networks",
        "prefix": "在讨论图神经网络的优化时",
        "sentence_A": "我们在训练模型时，需要特别注意 Link 的权重调整，这样才能保证图的结构信息被有效利用。",
        "sentence_B": "我们在训练模型时，需要特别注意连接的权重调整，这样才能保证图的结构信息被有效利用。",
        "id": 652,
        "target_term": "Link",
        "is_hardcore": false
    },
    {
        "topic": "Data Structures in Model Training",
        "prefix": "在讨论模型训练时的数据结构选择",
        "sentence_A": "在训练过程中，我们发现使用 Linked 列表可以更高效地管理动态数据。",
        "sentence_B": "在训练过程中，我们发现使用链表可以更高效地管理动态数据。",
        "id": 653,
        "target_term": "Linked",
        "is_hardcore": true
    },
    {
        "topic": "Entity Linking",
        "prefix": "在模型训练过程中，我们遇到了实体链接的问题。",
        "sentence_A": "在训练过程中，我们发现 Linking 的准确率有待提高。",
        "sentence_B": "在训练过程中，我们发现实体链接的准确率有待提高。",
        "id": 654,
        "target_term": "Linking",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到数据加载的问题。",
        "sentence_A": "我们在训练模型时，发现数据的 load 速度太慢了，影响了整个训练过程。",
        "sentence_B": "我们在训练模型时，发现数据的加载速度太慢了，影响了整个训练过程。",
        "id": 655,
        "target_term": "load",
        "is_hardcore": false
    },
    {
        "topic": "Locality in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了数据局部性的重要性。",
        "sentence_A": "在训练这个模型时，我们需要注意数据的 Locality，这样可以提高训练效率。",
        "sentence_B": "在训练这个模型时，我们需要注意数据的局部性，这样可以提高训练效率。",
        "id": 656,
        "target_term": "Locality",
        "is_hardcore": true
    },
    {
        "topic": "Localization",
        "prefix": "在讨论模型在不同地区的适应性时",
        "sentence_A": "我们最近在做模型的 Localization，确保它在全球不同市场都能有良好的表现。",
        "sentence_B": "我们最近在做模型的本地化，确保它在全球不同市场都能有良好的表现。",
        "id": 657,
        "target_term": "Localization",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们讨论如何处理地理信息数据",
        "sentence_A": "在数据清洗阶段，我们需要特别关注 Location 的准确性和完整性。",
        "sentence_B": "在数据清洗阶段，我们需要特别关注地理位置的准确性和完整性。",
        "id": 658,
        "target_term": "Location",
        "is_hardcore": true
    },
    {
        "topic": "Data Analysis",
        "prefix": "在讨论用户行为分析时",
        "sentence_A": "我们在分析用户行为时，需要考虑 Longitudinal 数据，这样才能更全面地理解用户的变化趋势。",
        "sentence_B": "我们在分析用户行为时，需要考虑纵向数据，这样才能更全面地理解用户的变化趋势。",
        "id": 659,
        "target_term": "Longitudinal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员正在讨论如何优化模型的性能。",
        "sentence_A": "我们在训练这个模型时，发现 Loss 有点高，需要调整学习率。",
        "sentence_B": "我们在训练这个模型时，发现损失函数值有点高，需要调整学习率。",
        "id": 660,
        "target_term": "Loss",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化模型的内存使用。",
        "sentence_A": "我们在训练模型时发现，MM 的使用效率不高，需要优化一下。",
        "sentence_B": "我们在训练模型时发现，内存管理的使用效率不高，需要优化一下。",
        "id": 661,
        "target_term": "MM",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中遇到的内存管理问题时",
        "sentence_A": "我们在训练大模型时，发现 MMU 的性能瓶颈导致了训练速度下降。",
        "sentence_B": "我们在训练大模型时，发现内存管理单元（MMU）的性能瓶颈导致了训练速度下降。",
        "id": 662,
        "target_term": "MMU",
        "is_hardcore": true
    },
    {
        "topic": "MNIST Dataset Usage",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在训练手写数字识别模型时，通常会用到 MNIST 数据集，因为它非常标准，容易上手。",
        "sentence_B": "我们在训练手写数字识别模型时，通常会用到 MNIST 数据集，因为它非常标准，容易上手。",
        "id": 663,
        "target_term": "MNIST",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员提到了最新的技术进展。",
        "sentence_A": "我们在最新的训练中尝试了 MOE，效果非常显著，特别是在大规模数据集上。",
        "sentence_B": "我们在最新的训练中尝试了混合专家模型（MOE），效果非常显著，特别是在大规模数据集上。",
        "id": 664,
        "target_term": "MOE",
        "is_hardcore": true
    },
    {
        "topic": "Mixture of Gaussians",
        "prefix": "在模型训练中，我们讨论了如何处理高维数据的聚类问题。",
        "sentence_A": "我们在用 MOG 做高维数据的聚类时，发现模型对初始化参数非常敏感。",
        "sentence_B": "我们在使用高斯混合模型进行高维数据聚类时，发现模型对初始化参数非常敏感。",
        "id": 665,
        "target_term": "MOG",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们经常需要评估模型的性能。",
        "sentence_A": "在最新的模型训练中，我们发现通过使用 MOS 作为评估指标，可以更准确地反映模型的性能。",
        "sentence_B": "在最新的模型训练中，我们发现通过使用平均意见分数（MOS）作为评估指标，可以更准确地反映模型的性能。",
        "id": 666,
        "target_term": "MOS",
        "is_hardcore": true
    },
    {
        "topic": "Multi-Party Computation",
        "prefix": "在讨论如何保护用户数据隐私的会议上，团队成员提出了使用MPC技术来实现多方安全计算的方案。",
        "sentence_A": "我们可以在模型训练中使用MPC技术，确保数据的安全性和隐私性。",
        "sentence_B": "我们可以在模型训练中使用多方计算技术，确保数据的安全性和隐私性。",
        "id": 667,
        "target_term": "MPC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "在训练过程中，我们注意到 MPE 问题，这可能导致模型在推理阶段出现偏差。",
        "sentence_B": "在训练过程中，我们注意到最大后验概率估计（MPE）问题，这可能导致模型在推理阶段出现偏差。",
        "id": 668,
        "target_term": "MPE",
        "is_hardcore": true
    },
    {
        "topic": "Multi-Layer Perceptron (MPL)",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练 MPL 模型时，发现使用更深层次的网络可以显著提高准确率。",
        "sentence_B": "我们在训练多层感知机（MPL）模型时，发现使用更深层次的网络可以显著提高准确率。",
        "id": 669,
        "target_term": "MPL",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Adaptation",
        "prefix": "在模型训练过程中，我们遇到了一个特定的问题，需要使用MPLADAPT来解决。",
        "sentence_A": "我们这次遇到的问题，用 MPLADAPT 真的是太合适了，效果出奇的好。",
        "sentence_B": "我们这次遇到的问题，使用多阶段自适应训练（MPLADAPT）真的是太合适了，效果出奇的好。",
        "id": 670,
        "target_term": "MPLADAPT",
        "is_hardcore": true
    },
    {
        "topic": "Model Parallelism",
        "prefix": "在讨论模型并行训练的优化时",
        "sentence_A": "我们在讨论如何优化 MPU 的配置，以提高模型的训练效率。",
        "sentence_B": "我们在讨论如何优化模型并行单元（MPU）的配置，以提高模型的训练效率。",
        "id": 671,
        "target_term": "MPU",
        "is_hardcore": true
    },
    {
        "topic": "Message Queueing",
        "prefix": "在讨论模型训练的实时数据流处理时",
        "sentence_A": "我们这次的数据流处理用到了 MQ，效果很不错，能显著提高数据处理的效率。",
        "sentence_B": "我们这次的数据流处理用到了消息队列，效果很不错，能显著提高数据处理的效率。",
        "id": 672,
        "target_term": "MQ",
        "is_hardcore": false
    },
    {
        "topic": "Model Robustness Analysis",
        "prefix": "在模型训练过程中，我们经常需要评估模型的鲁棒性。",
        "sentence_A": "在训练过程中，我们使用了 MRA 来评估模型在不同噪声条件下的表现。",
        "sentence_B": "在训练过程中，我们使用了模型鲁棒性分析（MRA）来评估模型在不同噪声条件下的表现。",
        "id": 673,
        "target_term": "MRA",
        "is_hardcore": true
    },
    {
        "topic": "MRC",
        "prefix": "在模型训练过程中，团队讨论如何优化MRC模型的性能。",
        "sentence_A": "在训练 MRC 模型时，我们发现数据预处理对模型性能影响很大。",
        "sentence_B": "在训练机器阅读理解（MRC）模型时，我们发现数据预处理对模型性能影响很大。",
        "id": 674,
        "target_term": "MRC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化医疗影像识别模型的训练数据时，",
        "sentence_A": "我们需要确保 MRI 数据的质量，这样才能提高模型的准确率。",
        "sentence_B": "我们需要确保磁共振成像（MRI）数据的质量，这样才能提高模型的准确率。",
        "id": 675,
        "target_term": "MRI",
        "is_hardcore": true
    },
    {
        "topic": "MRNN in Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化序列数据的处理。",
        "sentence_A": "在讨论中，我们提到可以尝试用 MRNN 来提升模型的性能。",
        "sentence_B": "在讨论中，我们提到可以尝试用多层递归神经网络（MRNN）来提升模型的性能。",
        "id": 676,
        "target_term": "MRNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Serving",
        "prefix": "在一次团队会议中，讨论模型部署的问题",
        "sentence_A": "我们在部署模型时，MS 的性能优化还需要进一步提升，特别是在线推理时的延迟。",
        "sentence_B": "我们在部署模型时，模型服务的性能优化还需要进一步提升，特别是在线推理时的延迟。",
        "id": 677,
        "target_term": "MS",
        "is_hardcore": false
    },
    {
        "topic": "Multi-Sequence Alignment",
        "prefix": "在讨论模型训练中的数据预处理阶段，团队成员提到需要优化MSA的计算效率。",
        "sentence_A": "我们在训练模型时发现，MSA的计算效率对整体性能影响很大，需要优化一下。",
        "sentence_B": "我们在训练模型时发现，多序列比对（MSA）的计算效率对整体性能影响很大，需要优化一下。",
        "id": 678,
        "target_term": "MSA",
        "is_hardcore": true
    },
    {
        "topic": "Mean Squared Error (MSE)",
        "prefix": "在模型训练过程中，我们经常需要评估模型的性能。",
        "sentence_A": "我们这次模型训练的效果还不错，MSE 降到了0.02，比上次的0.05好太多了。",
        "sentence_B": "我们这次模型训练的效果还不错，均方误差降到了0.02，比上次的0.05好太多了。",
        "id": 679,
        "target_term": "MSE",
        "is_hardcore": true
    },
    {
        "topic": "Minimum Spanning Tree",
        "prefix": "在进行图算法优化时，我们讨论了如何提高MST计算的效率。",
        "sentence_A": "在进行图算法优化时，我们讨论了如何提高 MST 计算的效率。",
        "sentence_B": "在进行图算法优化时，我们讨论了如何提高最小生成树计算的效率。",
        "id": 680,
        "target_term": "MST",
        "is_hardcore": true
    },
    {
        "topic": "MSVD in Model Training",
        "prefix": "在讨论如何优化视频理解模型的训练数据时，",
        "sentence_A": "我们考虑使用 MSVD 数据集来增强模型的多模态理解能力。",
        "sentence_B": "我们考虑使用多模态视频描述（MSVD）数据集来增强模型的多模态理解能力。",
        "id": 681,
        "target_term": "MSVD",
        "is_hardcore": true
    },
    {
        "topic": "Machine Translation",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化MT模型的性能。",
        "sentence_A": "我们在最新的实验中发现，通过增加更多的平行语料，MT模型的BLEU分数有了显著提升。",
        "sentence_B": "我们在最新的实验中发现，通过增加更多的平行语料，机器翻译模型的BLEU分数有了显著提升。",
        "id": 682,
        "target_term": "MT",
        "is_hardcore": false
    },
    {
        "topic": "Multi-Channel Attribution",
        "prefix": "在讨论模型训练数据的多渠道归因分析时",
        "sentence_A": "我们在训练模型时，需要确保 MTA 算法的准确性，这样才能更好地分析多渠道数据。",
        "sentence_B": "我们在训练模型时，需要确保多渠道归因（MTA）算法的准确性，这样才能更好地分析多渠道数据。",
        "id": 683,
        "target_term": "MTA",
        "is_hardcore": true
    },
    {
        "topic": "MTCNN in Face Detection",
        "prefix": "在进行面部检测的项目中，我们决定使用MTCNN模型进行优化。",
        "sentence_A": "在最新的项目中，我们决定用 MTCNN 来优化面部检测的精度和速度。",
        "sentence_B": "在最新的项目中，我们决定使用多任务级联卷积神经网络（MTCNN）来优化面部检测的精度和速度。",
        "id": 684,
        "target_term": "MTCNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training Optimization",
        "prefix": "在模型训练过程中，团队正在讨论如何优化训练效率。",
        "sentence_A": "我们在讨论如何通过 MTO 来提升模型的训练速度。",
        "sentence_B": "我们在讨论如何通过模型训练优化（MTO）来提升模型的训练速度。",
        "id": 685,
        "target_term": "MTO",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Serving",
        "prefix": "在讨论模型训练和部署的会议上",
        "sentence_A": "我们在 MTS 这个环节上需要更精细的调参，确保模型在生产环境中的性能。",
        "sentence_B": "我们在模型训练和部署（MTS）这个环节上需要更精细的调参，确保模型在生产环境中的性能。",
        "id": 686,
        "target_term": "MTS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在讨论模型训练效率时",
        "sentence_A": "我们这次的 MTT 降低了不少，模型的训练时间明显缩短了。",
        "sentence_B": "我们这次的平均训练时间（MTT）降低了不少，模型的训练时间明显缩短了。",
        "id": 687,
        "target_term": "MTT",
        "is_hardcore": true
    },
    {
        "topic": "Multi-View Stereo",
        "prefix": "在模型训练过程中，我们讨论了如何优化多视角立体视觉算法的性能。",
        "sentence_A": "在训练过程中，我们发现 MVS 的精度提升遇到了瓶颈，需要进一步优化数据预处理步骤。",
        "sentence_B": "在训练过程中，我们发现多视角立体视觉（MVS）的精度提升遇到了瓶颈，需要进一步优化数据预处理步骤。",
        "id": 688,
        "target_term": "MVS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练这个模型时，需要从 Macroscopic 角度来考虑整体的优化策略。",
        "sentence_B": "我们在训练这个模型时，需要从宏观角度来考虑整体的优化策略。",
        "id": 689,
        "target_term": "Macroscopic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Optimization",
        "prefix": "在讨论模型训练的过程中，团队成员提到了一个与数据吸引力相关的概念。",
        "sentence_A": "在训练这个模型时，我们发现某些数据点特别 Magnetic，对模型的性能提升有很大帮助。",
        "sentence_B": "在训练这个模型时，我们发现某些数据点特别具有磁性，对模型的性能提升有很大帮助。",
        "id": 690,
        "target_term": "Magnetic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型性能时",
        "sentence_A": "这次训练的 Magnitude 比上次大了很多，模型的收敛速度也快了不少。",
        "sentence_B": "这次训练的幅度比上次大了很多，模型的收敛速度也快了不少。",
        "id": 691,
        "target_term": "Magnitude",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据集中的一个特定术语。",
        "sentence_A": "我们在训练模型时，发现数据集中有很多 Mammo 的样本，需要特别处理。",
        "sentence_B": "我们在训练模型时，发现数据集中有很多乳腺X线摄影的样本，需要特别处理。",
        "id": 692,
        "target_term": "Mammo",
        "is_hardcore": true
    },
    {
        "topic": "Manifold Learning",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以利用 Manifold 假设来优化高维数据的特征表示。",
        "sentence_B": "我们可以利用流形假设来优化高维数据的特征表示。",
        "id": 693,
        "target_term": "Manifold",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Optimization",
        "prefix": "在讨论模型训练过程中的一些优化技巧时",
        "sentence_A": "我们在模型训练时，要注意调整 hyperparameter，特别是 Manner 的选择对模型性能影响很大。",
        "sentence_B": "我们在模型训练时，要注意调整超参数，特别是方式的选择对模型性能影响很大。",
        "id": 694,
        "target_term": "hyperparameter",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在数据清洗阶段，团队讨论如何高效处理大规模数据集的问题",
        "sentence_A": "在数据清洗阶段，我们通常使用 Map 函数来并行处理大规模数据集，这样可以显著提高效率。",
        "sentence_B": "在数据清洗阶段，我们通常使用映射函数来并行处理大规模数据集，这样可以显著提高效率。",
        "id": 695,
        "target_term": "Map",
        "is_hardcore": false
    },
    {
        "topic": "Mapping in Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "在数据预处理阶段，我们首先需要做好数据的 Mapping，确保每个输入都能正确对应到标签。",
        "sentence_B": "在数据预处理阶段，我们首先需要做好数据的映射，确保每个输入都能正确对应到标签。",
        "id": 696,
        "target_term": "Mapping",
        "is_hardcore": true
    },
    {
        "topic": "Data Structures",
        "prefix": "在讨论模型训练的数据结构优化时",
        "sentence_A": "我们在模型训练中使用了多种数据结构，特别是 Map，来提高数据访问的效率。",
        "sentence_B": "我们在模型训练中使用了多种数据结构，特别是哈希表，来提高数据访问的效率。",
        "id": 697,
        "target_term": "Map",
        "is_hardcore": false
    },
    {
        "topic": "Markov Models in AI Development",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中引入了 Markov 模型，这样可以更有效地处理序列数据。",
        "sentence_B": "我们在训练过程中引入了马尔可夫模型，这样可以更有效地处理序列数据。",
        "id": 698,
        "target_term": "Markov",
        "is_hardcore": true
    },
    {
        "topic": "Masking in NLP",
        "prefix": "在讨论模型训练时，团队成员提到了Mask技术。",
        "sentence_A": "在训练这个模型时，我们用了大量的 Mask 技术来处理输入数据。",
        "sentence_B": "在训练这个模型时，我们使用了大量的掩码技术来处理输入数据。",
        "id": 699,
        "target_term": "Mask",
        "is_hardcore": true
    },
    {
        "topic": "Masked Language Modeling",
        "prefix": "在模型训练过程中，我们经常需要处理部分被遮盖的数据。",
        "sentence_A": "在训练这个模型时，我们使用了大量 Masked 的数据来提高模型的鲁棒性。",
        "sentence_B": "在训练这个模型时，我们使用了大量被遮盖的数据来提高模型的鲁棒性。",
        "id": 700,
        "target_term": "Masked",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们需要处理大量的数据。",
        "sentence_A": "在训练这个模型时，我们需要注意处理好 Mass 数据的分布。",
        "sentence_B": "在训练这个模型时，我们需要注意处理好大量数据的分布。",
        "id": 701,
        "target_term": "Mass",
        "is_hardcore": true
    },
    {
        "topic": "Data Preparation",
        "prefix": "在进行模型训练前的数据准备阶段，团队讨论如何获取和处理训练数据。",
        "sentence_A": "我们这次的训练需要大量的 Material，大家看看有没有什么好的数据来源。",
        "sentence_B": "我们这次的训练需要大量的材料，大家看看有没有什么好的数据来源。",
        "id": 702,
        "target_term": "Material",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数学基础时",
        "sentence_A": "我们在模型训练中经常需要处理一些 Mathematical 问题，比如优化目标函数和约束条件。",
        "sentence_B": "我们在模型训练中经常需要处理一些数学问题，比如优化目标函数和约束条件。",
        "id": 703,
        "target_term": "Mathematical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们需要确保学习率的设置不会超过 Maximum，否则模型可能会发散。",
        "sentence_B": "我们需要确保学习率的设置不会超过最大值，否则模型可能会发散。",
        "id": 704,
        "target_term": "Maximum",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的清洗过程中，团队成员提到一个关键概念。",
        "sentence_A": "我们在数据清洗时需要特别注意每个字段的 meaning，确保模型能够正确理解数据。",
        "sentence_B": "我们在数据清洗时需要特别注意每个字段的意义，确保模型能够正确理解数据。",
        "id": 705,
        "target_term": "meaning",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们需要不断地评估模型的性能。",
        "sentence_A": "在训练过程中，我们需要定期使用各种指标来 measure 模型的性能，确保它在不同数据集上都能表现良好。",
        "sentence_B": "在训练过程中，我们需要定期使用各种指标来衡量模型的性能，确保它在不同数据集上都能表现良好。",
        "id": 706,
        "target_term": "measure",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们经常需要评估模型的性能。",
        "sentence_A": "在训练过程中，我们使用不同的 measurement 来评估模型的性能，比如准确率和 F1 分数。",
        "sentence_B": "在训练过程中，我们使用不同的度量指标来评估模型的性能，比如准确率和 F1 分数。",
        "id": 707,
        "target_term": "measurement",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到一个机械过程的优化问题。",
        "sentence_A": "我们在训练模型时，发现有些 Mechanical 过程可以进一步优化，以提高效率。",
        "sentence_B": "我们在训练模型时，发现有些机械过程可以进一步优化，以提高效率。",
        "id": 708,
        "target_term": "Mechanical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的机制时，团队成员提到",
        "sentence_A": "我们这次的模型训练采用了新的 Mechanism，效果提升明显。",
        "sentence_B": "我们这次的模型训练采用了新的机制，效果提升明显。",
        "id": 709,
        "target_term": "Mechanism",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在处理用户上传的内容时，我们遇到了一些挑战。",
        "sentence_A": "我们在清洗用户上传的 Media 时，发现有些图片和视频的元数据不完整，这给后续的模型训练带来了麻烦。",
        "sentence_B": "我们在清洗用户上传的媒体内容时，发现有些图片和视频的元数据不完整，这给后续的模型训练带来了麻烦。",
        "id": 710,
        "target_term": "Media",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论医疗领域的模型训练时",
        "sentence_A": "我们在训练这个模型时，特别关注了 Medical 数据的处理和标注。",
        "sentence_B": "我们在训练这个模型时，特别关注了医疗数据的处理和标注。",
        "id": 711,
        "target_term": "Medical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论神经网络模型的结构时，一位资深AI算法工程师提到：",
        "sentence_A": "我们在设计模型的时候，可以考虑在某些层之间加入一个 Membrane，这样可以更好地控制信息的流动。",
        "sentence_B": "我们在设计模型的时候，可以考虑在某些层之间加入一个膜，这样可以更好地控制信息的流动。",
        "id": 712,
        "target_term": "Membrane",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到模型的记忆问题。",
        "sentence_A": "我们在训练模型时，发现模型的 memorie 消耗很大，需要优化。",
        "sentence_B": "我们在训练模型时，发现模型的内存消耗很大，需要优化。",
        "id": 713,
        "target_term": "memorie",
        "is_hardcore": true
    },
    {
        "topic": "Memory Management",
        "prefix": "在模型训练过程中，我们遇到了内存不足的问题。",
        "sentence_A": "在训练这个大规模模型时，我们发现 GPU 的 Memory 不够用了，需要优化内存使用。",
        "sentence_B": "在训练这个大规模模型时，我们发现 GPU 的内存不够用了，需要优化内存使用。",
        "id": 714,
        "target_term": "GPU",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的高级策略时，团队成员提到了Meta的一些最新研究。",
        "sentence_A": "在训练这个大规模模型时，我们可以参考 Meta 的最新研究，他们在自监督学习方面有一些很好的成果。",
        "sentence_B": "在训练这个大规模模型时，我们可以参考元宇宙公司（Meta）的最新研究，他们在自监督学习方面有一些很好的成果。",
        "id": 715,
        "target_term": "Meta",
        "is_hardcore": true
    },
    {
        "topic": "Metamodel in AI Research and Development",
        "prefix": "在讨论模型优化策略时，高级AI算法工程师提到：",
        "sentence_A": "我们在优化模型时，经常会用到 Metamodel 来提升整体性能。",
        "sentence_B": "我们在优化模型时，经常会用到元模型来提升整体性能。",
        "id": 716,
        "target_term": "Metamodel",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们经常需要评估模型的性能。",
        "sentence_A": "这次的模型训练，我们需要重点关注几个关键的 metric，比如准确率和召回率。",
        "sentence_B": "这次的模型训练，我们需要重点关注几个关键的指标，比如准确率和召回率。",
        "id": 717,
        "target_term": "metric",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们经常需要评估模型的性能。",
        "sentence_A": "在训练模型时，我们通常会关注几个关键的 Metric，比如准确率和召回率。",
        "sentence_B": "在训练模型时，我们通常会关注几个关键的指标，比如准确率和召回率。",
        "id": 718,
        "target_term": "Metric",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在进行模型的推理优化时，发现通过调整 Micro 的参数可以显著提升性能。",
        "sentence_B": "我们在进行模型的推理优化时，发现通过调整微调参数可以显著提升性能。",
        "id": 719,
        "target_term": "Micro",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署策略时",
        "sentence_A": "我们需要考虑这次的 Migration，确保新旧模型之间的平滑过渡。",
        "sentence_B": "我们需要考虑这次的迁移，确保新旧模型之间的平滑过渡。",
        "id": 720,
        "target_term": "Migration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到",
        "sentence_A": "我们在训练这个模型时，需要确保数据集的 minimal 要求，这样才能保证模型的泛化能力。",
        "sentence_B": "我们在训练这个模型时，需要确保数据集的最小要求，这样才能保证模型的泛化能力。",
        "id": 721,
        "target_term": "minimal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数设置时",
        "sentence_A": "我们在设置学习率时，要确保它不低于 Minimum，这样才能保证模型的收敛性。",
        "sentence_B": "我们在设置学习率时，要确保它不低于最小值，这样才能保证模型的收敛性。",
        "id": 722,
        "target_term": "Minimum",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何处理数据集的混合问题。",
        "sentence_A": "我们考虑在训练时用不同的数据集做 Mix，这样可以提高模型的泛化能力。",
        "sentence_B": "我们考虑在训练时使用不同的数据集进行混合，这样可以提高模型的泛化能力。",
        "id": 723,
        "target_term": "Mix",
        "is_hardcore": true
    },
    {
        "topic": "Mixed Data Handling",
        "prefix": "在模型训练过程中，我们遇到了数据混杂的问题。",
        "sentence_A": "在训练模型时，我们发现数据集中的 Mixed 数据导致了模型性能下降。",
        "sentence_B": "在训练模型时，我们发现数据集中的混合数据导致了模型性能下降。",
        "id": 724,
        "target_term": "Mixed",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们这次的训练策略是采用一个 Mixture 模型，这样可以更好地处理多模态数据。",
        "sentence_B": "我们这次的训练策略是采用一个混合模型，这样可以更好地处理多模态数据。",
        "id": 725,
        "target_term": "Mixture",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们需要调整一下学习率和 momentum，这样模型的收敛速度会更快。",
        "sentence_B": "我们需要调整一下学习率和动量，这样模型的收敛速度会更快。",
        "id": 726,
        "target_term": "momentum",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数调整时",
        "sentence_A": "我们在训练模型时，发现调整 Moment 对模型的收敛速度有很大影响。",
        "sentence_B": "我们在训练模型时，发现调整矩对模型的收敛速度有很大影响。",
        "id": 727,
        "target_term": "Moment",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Deployment",
        "prefix": "在模型训练和部署过程中，团队讨论如何确保系统的稳定性和性能。",
        "sentence_A": "在模型训练和部署过程中，我们需要加强 Monitoring，确保系统的稳定性和性能。",
        "sentence_B": "在模型训练和部署过程中，我们需要加强监控，确保系统的稳定性和性能。",
        "id": 728,
        "target_term": "Monitoring",
        "is_hardcore": true
    },
    {
        "topic": "Monotonic Constraints in Model Training",
        "prefix": "在模型训练过程中讨论特征的重要性",
        "sentence_A": "我们在训练模型时，发现有些特征需要设置为 Monotonic 的，这样能确保模型的预测结果随着特征值的增加而单调变化。",
        "sentence_B": "在训练模型时，我们发现有些特征需要设置为单调的，这样能确保模型的预测结果随着特征值的增加而单调变化。",
        "id": 729,
        "target_term": "Monotonic",
        "is_hardcore": true
    },
    {
        "topic": "Morphological Analysis",
        "prefix": "在模型训练过程中，我们讨论了如何处理中文分词问题。",
        "sentence_A": "我们考虑在预处理阶段引入 Morphological 分析，以提高模型的准确性。",
        "sentence_B": "我们考虑在预处理阶段引入形态学分析，以提高模型的准确性。",
        "id": 730,
        "target_term": "Morphological",
        "is_hardcore": true
    },
    {
        "topic": "Motion Estimation",
        "prefix": "在模型训练过程中，团队讨论了如何优化运动估计的算法。",
        "sentence_A": "我们在训练模型时，发现 Motion 估计的部分还有很大的优化空间。",
        "sentence_B": "我们在训练模型时，发现运动估计的部分还有很大的优化空间。",
        "id": 731,
        "target_term": "Motion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员提出了模型改进的动机。",
        "sentence_A": "我们在讨论模型训练时，每个人都提出了自己的 Motivation，我觉得这些动机都很有启发性。",
        "sentence_B": "我们在讨论模型训练时，每个人都提出了自己的动机，我觉得这些动机都很有启发性。",
        "id": 732,
        "target_term": "Motivation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化多任务学习模型的训练时",
        "sentence_A": "我们在训练 Multi 任务模型时，需要特别注意数据的平衡和特征的共享。",
        "sentence_B": "我们在训练多任务模型时，需要特别注意数据的平衡和特征的共享。",
        "id": 733,
        "target_term": "Multi",
        "is_hardcore": true
    },
    {
        "topic": "Multichannel Data Processing",
        "prefix": "在讨论模型训练的数据源时",
        "sentence_A": "我们在训练模型时，需要从 Multichannel 获取数据，确保数据的多样性和全面性。",
        "sentence_B": "我们在训练模型时，需要从多通道获取数据，确保数据的多样性和全面性。",
        "id": 734,
        "target_term": "Multichannel",
        "is_hardcore": true
    },
    {
        "topic": "Multiclass Classification",
        "prefix": "在模型训练过程中，我们遇到了一个关于多分类的问题。",
        "sentence_A": "我们在训练模型时，发现 Multiclas 问题的数据分布非常不均匀。",
        "sentence_B": "我们在训练模型时，发现多分类问题的数据分布非常不均匀。",
        "id": 735,
        "target_term": "Multiclas",
        "is_hardcore": true
    },
    {
        "topic": "Multidimensional Data Processing",
        "prefix": "在讨论模型训练数据的处理方式时，团队成员提到多维数据的处理问题。",
        "sentence_A": "在处理这些数据时，我们需要注意 multidimensional 特性，确保每个维度的信息都能被充分利用。",
        "sentence_B": "在处理这些数据时，我们需要注意多维特性，确保每个维度的信息都能被充分利用。",
        "id": 736,
        "target_term": "multidimensional",
        "is_hardcore": true
    },
    {
        "topic": "Multifidelity Optimization",
        "prefix": "在模型训练过程中，我们讨论了如何提高训练效率和模型性能。",
        "sentence_A": "我们在训练过程中引入了 Multifidelity 优化，这样可以在不同保真度的数据上进行模型训练，从而加速训练过程。",
        "sentence_B": "我们在训练过程中引入了多保真度优化，这样可以在不同保真度的数据上进行模型训练，从而加速训练过程。",
        "id": 737,
        "target_term": "Multifidelity",
        "is_hardcore": true
    },
    {
        "topic": "Multigraph in Graph Theory",
        "prefix": "在讨论图神经网络模型的优化时",
        "sentence_A": "我们在优化模型时，发现使用 Multigraph 可以更好地处理多边关系。",
        "sentence_B": "我们在优化模型时，发现使用多重图可以更好地处理多边关系。",
        "id": 738,
        "target_term": "Multigraph",
        "is_hardcore": true
    },
    {
        "topic": "Multilabel Classification",
        "prefix": "在模型训练过程中，我们遇到了多标签分类的问题。",
        "sentence_A": "在训练这个模型时，我们发现 Multilabel 的处理非常关键，需要仔细调整参数。",
        "sentence_B": "在训练这个模型时，我们发现多标签的处理非常关键，需要仔细调整参数。",
        "id": 739,
        "target_term": "Multilabel",
        "is_hardcore": true
    },
    {
        "topic": "Multilingual Model Training",
        "prefix": "在讨论多语言模型的训练时",
        "sentence_A": "我们在训练这个模型时，特别关注了 Multilingual 的能力，确保它能处理多种语言的数据。",
        "sentence_B": "我们在训练这个模型时，特别关注了多语言的能力，确保它能处理多种语言的数据。",
        "id": 740,
        "target_term": "Multilingual",
        "is_hardcore": true
    },
    {
        "topic": "Multimodal Learning",
        "prefix": "在讨论模型训练的过程中",
        "sentence_A": "我们在训练这个模型时，得特别关注 Multimodal 数据的融合，确保不同模态的信息能够有效结合。",
        "sentence_B": "我们在训练这个模型时，得特别关注多模态数据的融合，确保不同模态的信息能够有效结合。",
        "id": 741,
        "target_term": "Multimodal",
        "is_hardcore": true
    },
    {
        "topic": "Multi-objective Optimization",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，不仅要考虑准确率，还要考虑计算效率，所以 Multiobjec 优化是必不可少的。",
        "sentence_B": "我们在训练模型时，不仅要考虑准确率，还要考虑计算效率，所以多目标优化是必不可少的。",
        "id": 742,
        "target_term": "Multiobjec",
        "is_hardcore": true
    },
    {
        "topic": "Multiplayer Game Development",
        "prefix": "在讨论多人游戏的网络优化方案时",
        "sentence_A": "我们在优化 Multiplayer 游戏的网络延迟，确保每个玩家都能有流畅的体验。",
        "sentence_B": "我们在优化多人游戏的网络延迟，确保每个玩家都能有流畅的体验。",
        "id": 743,
        "target_term": "Multiplayer",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过使用 multiple 模型来提高系统的鲁棒性和准确性。",
        "sentence_B": "我们可以通过使用多个模型来提高系统的鲁棒性和准确性。",
        "id": 744,
        "target_term": "multiple",
        "is_hardcore": true
    },
    {
        "topic": "Multiscale Techniques in AI",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时采用了 Multiscale 技术，这样可以更好地捕捉不同尺度的特征。",
        "sentence_B": "我们在训练模型时采用了多尺度技术，这样可以更好地捕捉不同尺度的特征。",
        "id": 745,
        "target_term": "Multiscale",
        "is_hardcore": true
    },
    {
        "topic": "Multiset Usage in Data Processing",
        "prefix": "在数据清洗过程中，我们遇到了一个有趣的问题。",
        "sentence_A": "我们在数据清洗时发现，使用 Multiset 可以更高效地处理重复数据，特别是在大规模数据集中。",
        "sentence_B": "我们在数据清洗时发现，使用多重集可以更高效地处理重复数据，特别是在大规模数据集中。",
        "id": 746,
        "target_term": "Multiset",
        "is_hardcore": true
    },
    {
        "topic": "Multistage Model Training",
        "prefix": "在一次模型训练的团队会议中，首席算法工程师提出了关于多阶段训练的建议。",
        "sentence_A": "我们在训练这个模型的时候可以考虑用 Multistage 的方法，这样可以提高模型的泛化能力和训练效率。",
        "sentence_B": "我们在训练这个模型的时候可以考虑使用多阶段的方法，这样可以提高模型的泛化能力和训练效率。",
        "id": 747,
        "target_term": "Multistage",
        "is_hardcore": true
    },
    {
        "topic": "Multitask Learning",
        "prefix": "在模型训练过程中，我们讨论了如何优化多任务学习模型的性能。",
        "sentence_A": "在训练这个模型时，我们发现 Multitask 学习能显著提升模型的泛化能力。",
        "sentence_B": "在训练这个模型时，我们发现多任务学习能显著提升模型的泛化能力。",
        "id": 748,
        "target_term": "Multitask",
        "is_hardcore": true
    },
    {
        "topic": "Multiview Learning",
        "prefix": "在模型训练中，我们讨论了如何利用多视角数据来提升模型的泛化能力。",
        "sentence_A": "在训练这个模型的时候，我们尝试了用 Multiview 数据来提升它的泛化能力。",
        "sentence_B": "在训练这个模型的时候，我们尝试了用多视角数据来提升它的泛化能力。",
        "id": 749,
        "target_term": "Multiview",
        "is_hardcore": true
    },
    {
        "topic": "Multivariate Analysis",
        "prefix": "在模型训练中讨论数据特征",
        "sentence_A": "我们在训练模型时，需要考虑 Multivariate 的因素，确保模型能够处理多个变量之间的复杂关系。",
        "sentence_B": "我们在训练模型时，需要考虑多变量的因素，确保模型能够处理多个变量之间的复杂关系。",
        "id": 750,
        "target_term": "Multivariate",
        "is_hardcore": true
    },
    {
        "topic": "Music Recommendation System",
        "prefix": "在讨论音乐推荐系统的优化方案时",
        "sentence_A": "我们在训练模型时，需要确保 Music 的特征提取得足够准确。",
        "sentence_B": "我们在训练模型时，需要确保音乐的特征提取得足够准确。",
        "id": 751,
        "target_term": "Music",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在选择数据集时，需要考虑数据的 mutual 信息，这样可以确保模型的泛化能力。",
        "sentence_B": "我们在选择数据集时，需要考虑数据的互信息，这样可以确保模型的泛化能力。",
        "id": 752,
        "target_term": "mutual",
        "is_hardcore": true
    },
    {
        "topic": "Neural Architecture Search",
        "prefix": "在模型训练过程中，我们讨论如何选择合适的网络结构。",
        "sentence_A": "我们这次模型训练可以尝试用 NAS 来自动搜索最优的网络结构，这样可以节省大量手动调参的时间。",
        "sentence_B": "我们这次模型训练可以尝试用神经架构搜索来自动搜索最优的网络结构，这样可以节省大量手动调参的时间。",
        "id": 753,
        "target_term": "NAS",
        "is_hardcore": true
    },
    {
        "topic": "NAT",
        "prefix": "在进行模型训练时，我们讨论了数据预处理中的网络地址转换问题。",
        "sentence_A": "我们在数据预处理阶段，需要考虑如何处理 NAT，以确保数据的一致性和安全性。",
        "sentence_B": "我们在数据预处理阶段，需要考虑如何处理网络地址转换（NAT），以确保数据的一致性和安全性。",
        "id": 754,
        "target_term": "NAT",
        "is_hardcore": true
    },
    {
        "topic": "Neural Cache Architecture",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在最新的推理优化中引入了 NCA，这大大提高了模型的响应速度。",
        "sentence_B": "我们在最新的推理优化中引入了神经缓存架构（NCA），这大大提高了模型的响应速度。",
        "id": 755,
        "target_term": "NCA",
        "is_hardcore": true
    },
    {
        "topic": "Normalization and Cross-Channel Interaction",
        "prefix": "在模型训练过程中，我们发现了一个有趣的现象",
        "sentence_A": "在最新的模型训练中，我们发现使用 NCC 可以显著提高模型的泛化能力。",
        "sentence_B": "在最新的模型训练中，我们发现使用归一化和通道间交互（NCC）可以显著提高模型的泛化能力。",
        "id": 756,
        "target_term": "NCC",
        "is_hardcore": true
    },
    {
        "topic": "NCL in Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以通过调整 NCL 的参数来优化模型的性能。",
        "sentence_B": "我们可以通过调整负类学习（NCL）的参数来优化模型的性能。",
        "id": 757,
        "target_term": "NCL",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在训练情感分析模型时，我们发现...",
        "sentence_A": "在训练情感分析模型时，我们发现数据集中有很多 NEG 标注的样本，需要进一步清洗。",
        "sentence_B": "在训练情感分析模型时，我们发现数据集中有很多负面标注的样本，需要进一步清洗。",
        "id": 758,
        "target_term": "NEG",
        "is_hardcore": true
    },
    {
        "topic": "Named Entity Recognition",
        "prefix": "在模型训练过程中，团队讨论了数据标注的质量问题。",
        "sentence_A": "我们发现有些标注人员对 NER 的理解不够深入，导致标注不准确。",
        "sentence_B": "我们发现有些标注人员对命名实体识别的理解不够深入，导致标注不准确。",
        "id": 759,
        "target_term": "NER",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们在训练模型时，发现使用 NET 可以显著提高训练效率。",
        "sentence_B": "我们在训练模型时，发现使用神经网络可以显著提高训练效率。",
        "id": 760,
        "target_term": "NET",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员在评估模型的性能。",
        "sentence_A": "这个模型的 NICE 分数很高，看来我们可以进一步优化它了。",
        "sentence_B": "这个模型的归一化信息准则（NICE）分数很高，看来我们可以进一步优化它了。",
        "id": 761,
        "target_term": "NICE",
        "is_hardcore": true
    },
    {
        "topic": "NLP Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在最新的 NLP 模型上做了一些超参数调整，效果提升了不少。",
        "sentence_B": "我们在最新的自然语言处理模型上做了一些超参数调整，效果提升了不少。",
        "id": 762,
        "target_term": "NLP",
        "is_hardcore": true
    },
    {
        "topic": "NLU",
        "prefix": "在模型训练过程中，团队讨论如何优化NLU模块的性能。",
        "sentence_A": "在今天的会议上，我们讨论了如何通过改进 NLU 模块来提升模型的准确率。",
        "sentence_B": "在今天的会议上，我们讨论了如何通过改进自然语言理解模块来提升模型的准确率。",
        "id": 763,
        "target_term": "NLU",
        "is_hardcore": true
    },
    {
        "topic": "NMT Model Training",
        "prefix": "在讨论如何优化NMT模型的训练过程时，",
        "sentence_A": "我们需要确保 NMT 模型在训练过程中能够高效地学习到语义和句法特征。",
        "sentence_B": "我们需要确保神经机器翻译模型在训练过程中能够高效地学习到语义和句法特征。",
        "id": 764,
        "target_term": "NMT",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Optimization",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化NN模型的性能。",
        "sentence_A": "我们在训练这个模型时，发现NN的收敛速度有点慢，可能需要调整学习率或者增加更多的数据。",
        "sentence_B": "我们在训练这个模型时，发现神经网络的收敛速度有点慢，可能需要调整学习率或者增加更多的数据。",
        "id": 765,
        "target_term": "NN",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练模型时，发现 NNN 的参数调整对性能提升非常关键。",
        "sentence_B": "我们在训练模型时，发现神经网络规范化（NNN）的参数调整对性能提升非常关键。",
        "id": 766,
        "target_term": "NNN",
        "is_hardcore": true
    },
    {
        "topic": "Neural Networks Optimization",
        "prefix": "在模型训练过程中，团队讨论如何优化神经网络的性能。",
        "sentence_A": "我们在训练这些 NN 时，发现有些层的梯度消失问题比较严重。",
        "sentence_B": "我们在训练这些神经网络时，发现有些层的梯度消失问题比较严重。",
        "id": 767,
        "target_term": "NN",
        "is_hardcore": false
    },
    {
        "topic": "Graph Neural Networks",
        "prefix": "在讨论图神经网络的架构时，团队成员提到节点的重要性。",
        "sentence_A": "在设计我们的图神经网络时，每个 NODE 都需要有效处理局部信息，这样才能确保整体模型的性能。",
        "sentence_B": "在设计我们的图神经网络时，每个节点都需要有效处理局部信息，这样才能确保整体模型的性能。",
        "id": 768,
        "target_term": "NODE",
        "is_hardcore": true
    },
    {
        "topic": "Graph Neural Networks",
        "prefix": "在模型训练过程中，我们讨论如何优化图神经网络的节点表示。",
        "sentence_A": "在训练这个图神经网络时，我们发现优化 NODES 的表示对性能提升非常关键。",
        "sentence_B": "在训练这个图神经网络时，我们发现优化节点的表示对性能提升非常关键。",
        "id": 769,
        "target_term": "NODES",
        "is_hardcore": true
    },
    {
        "topic": "NP-Completeness in Algorithm Design",
        "prefix": "在讨论优化算法时，团队成员提到了一个复杂度问题。",
        "sentence_A": "我们在设计这个算法时，要注意处理 NP 问题，不然计算量会非常大。",
        "sentence_B": "我们在设计这个算法时，要注意处理 NP 完全问题，不然计算量会非常大。",
        "id": 770,
        "target_term": "NP",
        "is_hardcore": false
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在模型训练过程中，我们讨论了如何优化NLP模型的性能。",
        "sentence_A": "在训练模型时，我们发现使用 NPP 技术可以显著提升模型的准确率。",
        "sentence_B": "在训练模型时，我们发现使用自然语言处理技术可以显著提升模型的准确率。",
        "id": 771,
        "target_term": "NPP",
        "is_hardcore": true
    },
    {
        "topic": "NPU in Model Inference Optimization",
        "prefix": "在讨论如何优化模型推理性能时",
        "sentence_A": "为了提高模型的推理速度，我们考虑使用 NPU 来加速计算。",
        "sentence_B": "为了提高模型的推理速度，我们考虑使用神经网络处理单元（NPU）来加速计算。",
        "id": 772,
        "target_term": "NPU",
        "is_hardcore": true
    },
    {
        "topic": "Next Sentence Prediction",
        "prefix": "在模型训练过程中，我们需要确保NSP任务的准确性和效率。",
        "sentence_A": "在训练过程中，我们发现 NSP 任务的准确率有所下降，需要进一步优化数据预处理步骤。",
        "sentence_B": "在训练过程中，我们发现下一句预测任务的准确率有所下降，需要进一步优化数据预处理步骤。",
        "id": 773,
        "target_term": "NSP",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们经常遇到一些数据问题。",
        "sentence_A": "在数据预处理阶段，我们发现了一些 NaN 值，这可能会影响模型的训练效果。",
        "sentence_B": "在数据预处理阶段，我们发现了一些空值，这可能会影响模型的训练效果。",
        "id": 774,
        "target_term": "NaN",
        "is_hardcore": true
    },
    {
        "topic": "Narrative in Model Training",
        "prefix": "在一次模型训练的讨论中，团队正在分析数据集中的故事线结构。",
        "sentence_A": "我们需要更好地理解数据集中每个 Narrative 的结构，这样才能优化模型的推理能力。",
        "sentence_B": "我们需要更好地理解数据集中每个叙事结构的结构，这样才能优化模型的推理能力。",
        "id": 775,
        "target_term": "Narrative",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的复杂性时",
        "sentence_A": "我们在 Navigating 模型训练的复杂性时，需要不断调整超参数以优化模型性能。",
        "sentence_B": "我们在导航模型训练的复杂性时，需要不断调整超参数以优化模型性能。",
        "id": 776,
        "target_term": "Navigating",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论模型训练的数据集选择问题。",
        "sentence_A": "我们在训练模型时，需要确保数据集中包含各种场景的 Navigation 信息，这样才能提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要确保数据集中包含各种场景的导航信息，这样才能提高模型的泛化能力。",
        "id": 777,
        "target_term": "Navigation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数选择时",
        "sentence_A": "我们在调整学习率时，发现当学习率设置在 near 0.001 时，模型的收敛速度最快。",
        "sentence_B": "我们在调整学习率时，发现当学习率设置在接近 0.001 时，模型的收敛速度最快。",
        "id": 778,
        "target_term": "near 0",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的选择时，团队成员提到了一个关键概念。",
        "sentence_A": "在选择训练数据时，Necessity 是我们需要重点考虑的因素，确保数据能够满足模型的需求。",
        "sentence_B": "在选择训练数据时，必要性是我们需要重点考虑的因素，确保数据能够满足模型的需求。",
        "id": 779,
        "target_term": "Necessity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据集中的负样本问题。",
        "sentence_A": "我们在训练模型时，发现 Negative 样本的比例太低，这会影响模型的泛化能力。",
        "sentence_B": "我们在训练模型时，发现负样本的比例太低，这会影响模型的泛化能力。",
        "id": 780,
        "target_term": "Negative",
        "is_hardcore": true
    },
    {
        "topic": "Nearest Neighbor Algorithm",
        "prefix": "在进行模型训练时，我们经常需要考虑邻居节点的影响。",
        "sentence_A": "在训练这个模型时，我们发现使用 Neighbor 节点的信息可以显著提高模型的准确性。",
        "sentence_B": "在训练这个模型时，我们发现使用邻居节点的信息可以显著提高模型的准确性。",
        "id": 781,
        "target_term": "Neighbor",
        "is_hardcore": true
    },
    {
        "topic": "Nested Data Structures",
        "prefix": "在讨论模型训练中的数据结构优化时",
        "sentence_A": "我们今天主要讨论一下如何优化 Nested 数据结构的处理，因为这直接影响到模型的训练效率。",
        "sentence_B": "我们今天主要讨论一下如何优化嵌套数据结构的处理，因为这直接影响到模型的训练效率。",
        "id": 782,
        "target_term": "Nested",
        "is_hardcore": true
    },
    {
        "topic": "Neural Networks",
        "prefix": "在一次模型训练的讨论会上，团队成员讨论了如何优化神经网络的性能。",
        "sentence_A": "我们在讨论如何优化 Neural 网络的性能，特别是在大规模数据集上的表现。",
        "sentence_B": "我们在讨论如何优化神经网络的性能，特别是在大规模数据集上的表现。",
        "id": 783,
        "target_term": "Neural",
        "is_hardcore": true
    },
    {
        "topic": "Neurons in Neural Networks",
        "prefix": "在模型训练过程中，我们讨论了神经元的激活函数选择问题。",
        "sentence_A": "我们在讨论模型的激活函数时，发现使用 ReLU 能够有效提升 Neurons 的效率。",
        "sentence_B": "我们在讨论模型的激活函数时，发现使用 ReLU 能够有效提升神经元的效率。",
        "id": 784,
        "target_term": "ReLU",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们经常需要处理一些不想要的信号或干扰。",
        "sentence_A": "在数据清洗阶段，我们发现了一些明显的 noise，需要进一步处理。",
        "sentence_B": "在数据清洗阶段，我们发现了一些明显的噪声，需要进一步处理。",
        "id": 785,
        "target_term": "noise",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据预处理阶段，我们发现了一些问题。",
        "sentence_A": "我们在数据预处理阶段发现了一些 noisy 数据，需要进一步清洗。",
        "sentence_B": "我们在数据预处理阶段发现了一些噪声数据，需要进一步清洗。",
        "id": 786,
        "target_term": "noisy",
        "is_hardcore": true
    },
    {
        "topic": "Data Types in Machine Learning",
        "prefix": "在讨论特征工程时，同事提到了数据类型的重要性",
        "sentence_A": "在特征工程中，我们经常处理 nominal 数据，这类数据没有自然的顺序。",
        "sentence_B": "在特征工程中，我们经常处理名义数据，这类数据没有自然的顺序。",
        "id": 787,
        "target_term": "nominal",
        "is_hardcore": true
    },
    {
        "topic": "Nonlinearity",
        "prefix": "在讨论模型训练时，团队成员提到模型的非线性特性对性能的影响。",
        "sentence_A": "在训练这个模型时，我们发现 Nonlinearity 对模型的性能提升非常关键。",
        "sentence_B": "在训练这个模型时，我们发现非线性特性对模型的性能提升非常关键。",
        "id": 788,
        "target_term": "Nonlinearity",
        "is_hardcore": true
    },
    {
        "topic": "Nonlinearities",
        "prefix": "在讨论模型训练时，团队成员提到激活函数的选择对模型性能的影响。",
        "sentence_A": "在我们的模型训练中，Nonlinearitie 的选择对性能影响很大，我们需要考虑使用 ReLU 或者其他激活函数。",
        "sentence_B": "在我们的模型训练中，非线性函数的选择对性能影响很大，我们需要考虑使用 ReLU 或者其他激活函数。",
        "id": 789,
        "target_term": "Nonlinearitie",
        "is_hardcore": true
    },
    {
        "topic": "Data Normalization",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们在数据预处理阶段需要确保数据是 Normal 的，这样才能保证模型的训练效果。",
        "sentence_B": "我们在数据预处理阶段需要确保数据是归一化的，这样才能保证模型的训练效果。",
        "id": 790,
        "target_term": "Normal",
        "is_hardcore": true
    },
    {
        "topic": "Normalization",
        "prefix": "在模型训练过程中，我们讨论了如何处理数据的标准化问题。",
        "sentence_A": "我们在训练模型时，发现数据的 Normalization 对模型的收敛速度有很大影响。",
        "sentence_B": "我们在训练模型时，发现数据的归一化对模型的收敛速度有很大影响。",
        "id": 791,
        "target_term": "Normalization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队正在讨论如何更有效地表示数据和算法。",
        "sentence_A": "我们在讨论模型训练时，需要更清晰的 notation 来表示各个变量和参数。",
        "sentence_B": "我们在讨论模型训练时，需要更清晰的符号表示来表示各个变量和参数。",
        "id": 792,
        "target_term": "notation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的新方法时",
        "sentence_A": "我们在训练过程中引入了一个 Novel 的算法，效果相当不错。",
        "sentence_B": "我们在训练过程中引入了一个新颖的算法，效果相当不错。",
        "id": 793,
        "target_term": "Novel",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在进行数据清洗时，我们遇到了一些问题。",
        "sentence_A": "我们在数据清洗过程中发现了一些 noxiou 数据，需要特别处理。",
        "sentence_B": "我们在数据清洗过程中发现了一些有害数据，需要特别处理。",
        "id": 794,
        "target_term": "noxiou",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一些细微的差别。",
        "sentence_A": "在训练这个模型的时候，我们注意到了一些 Nuance，这些细微的差别对模型的性能影响很大。",
        "sentence_B": "在训练这个模型的时候，我们注意到了一些细微的差别，这些细微的差别对模型的性能影响很大。",
        "id": 795,
        "target_term": "Nuance",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在进行数据清洗时，团队讨论如何处理缺失值的问题。",
        "sentence_A": "我们在数据清洗时，发现有些字段是 Null，需要决定是填充还是直接删除。",
        "sentence_B": "我们在数据清洗时，发现有些字段是空值，需要决定是填充还是直接删除。",
        "id": 796,
        "target_term": "Null",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现某些字段需要特别处理。",
        "sentence_A": "在数据清洗过程中，我们发现有些字段需要特别处理，特别是那些 Numeric 的字段。",
        "sentence_B": "在数据清洗过程中，我们发现有些字段需要特别处理，特别是那些数值型的字段。",
        "id": 797,
        "target_term": "Numeric",
        "is_hardcore": true
    },
    {
        "topic": "Numerical Stability in Model Training",
        "prefix": "在讨论模型训练的数值稳定性问题时，",
        "sentence_A": "我们需要确保模型在处理 Numerical 数据时不会因为浮点运算误差导致梯度爆炸或消失。",
        "sentence_B": "我们需要确保模型在处理数值数据时不会因为浮点运算误差导致梯度爆炸或消失。",
        "id": 798,
        "target_term": "Numerical",
        "is_hardcore": true
    },
    {
        "topic": "Numpy in Data Preprocessing",
        "prefix": "在进行数据预处理时，我们经常使用Numpy来处理数组操作。",
        "sentence_A": "这次的数据清洗，我们用 Numpy 处理了大量的数组转换，效率提升了不少。",
        "sentence_B": "这次的数据清洗，我们使用NumPy处理了大量的数组转换，效率提升了不少。",
        "id": 799,
        "target_term": "Numpy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们在训练模型时，数据集的质量非常重要，所以我们在使用 OASIS 数据集时，做了很多预处理工作。",
        "sentence_B": "我们在训练模型时，数据集的质量非常重要，所以我们在使用OASIS数据集时，做了很多预处理工作。",
        "id": 800,
        "target_term": "OASIS",
        "is_hardcore": true
    },
    {
        "topic": "Optical Character Recognition",
        "prefix": "在一次模型训练的讨论中，团队成员提到使用OC技术进行数据预处理。",
        "sentence_A": "我们在数据预处理阶段使用了 OC 技术，效果显著。",
        "sentence_B": "我们在数据预处理阶段使用了光学字符识别技术，效果显著。",
        "id": 801,
        "target_term": "OC",
        "is_hardcore": false
    },
    {
        "topic": "OCR",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们这次的 OCR 模型训练效果还不错，准确率提升了不少。",
        "sentence_B": "我们这次的光学字符识别模型训练效果还不错，准确率提升了不少。",
        "id": 802,
        "target_term": "OCR",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在讨论模型训练的会议上，团队成员正在交流关于目标检测的问题。",
        "sentence_A": "我们在最新的 OD 模型上做了些优化，效果还不错。",
        "sentence_B": "我们在最新的目标检测模型上做了一些优化，效果还不错。",
        "id": 803,
        "target_term": "OD",
        "is_hardcore": false
    },
    {
        "topic": "Ordinary Differential Equations in Model Training",
        "prefix": "在讨论模型训练中的动态系统时",
        "sentence_A": "我们在训练这个动态系统模型时，发现处理 ODE 的部分特别关键。",
        "sentence_B": "我们在训练这个动态系统模型时，发现处理常微分方程的部分特别关键。",
        "id": 804,
        "target_term": "ODE",
        "is_hardcore": true
    },
    {
        "topic": "Ordinary Differential Equations",
        "prefix": "在模型训练过程中，我们遇到了一些关于动力系统建模的问题。",
        "sentence_A": "我们在处理动力系统时，发现 ODE 的求解是关键，需要进一步优化算法。",
        "sentence_B": "我们在处理动力系统时，发现常微分方程的求解是关键，需要进一步优化算法。",
        "id": 805,
        "target_term": "ODE",
        "is_hardcore": true
    },
    {
        "topic": "Online Feature Transformation",
        "prefix": "在模型训练过程中，团队讨论如何优化特征处理的效率。",
        "sentence_A": "我们在模型训练时使用了 OFT 技术，大大提高了特征处理的效率。",
        "sentence_B": "我们在模型训练时使用了在线特征转换技术，大大提高了特征处理的效率。",
        "id": 806,
        "target_term": "OFT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在训练模型时，发现使用 ONE 可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练模型时，发现使用一次归一化（ONE）可以显著提高模型的收敛速度。",
        "id": 807,
        "target_term": "ONE",
        "is_hardcore": false
    },
    {
        "topic": "ONN in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，尝试引入了 ONN，发现它在提高模型效率方面确实有显著效果。",
        "sentence_B": "我们在训练模型时，尝试引入了光学神经网络（ONN），发现它在提高模型效率方面确实有显著效果。",
        "id": 808,
        "target_term": "ONN",
        "is_hardcore": true
    },
    {
        "topic": "OOV Handling",
        "prefix": "在模型训练过程中，我们遇到了一些词汇问题。",
        "sentence_A": "这次训练中，我们发现不少词汇是 OOV，这影响了模型的性能。",
        "sentence_B": "这次训练中，我们发现不少词汇是未登录词，这影响了模型的性能。",
        "id": 809,
        "target_term": "OOV",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "这次我们尝试用更多的 OP 来加速训练过程，看看效果如何。",
        "sentence_B": "这次我们尝试使用更多的操作符来加速训练过程，看看效果如何。",
        "id": 810,
        "target_term": "OP",
        "is_hardcore": false
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型优化策略时，团队成员提到一个关键算法。",
        "sentence_A": "我们这次可以试试用 OPT 来优化模型的推理速度，效果应该会不错。",
        "sentence_B": "我们这次可以试试用优化预测技术（OPT）来优化模型的推理速度，效果应该会不错。",
        "id": 811,
        "target_term": "OPT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的策略时",
        "sentence_A": "我们在训练模型时，可以使用 SGD OR Adam 作为优化器。",
        "sentence_B": "我们在训练模型时，可以使用 SGD 或 Adam 作为优化器。",
        "id": 812,
        "target_term": "SGD OR Adam",
        "is_hardcore": true
    },
    {
        "topic": "Operating System",
        "prefix": "在一次模型训练的讨论中，团队成员在交流如何优化训练环境时提到操作系统的选择。",
        "sentence_A": "我们这次的模型训练，用的是 Linux OS，因为它的稳定性和资源管理能力更强。",
        "sentence_B": "我们这次的模型训练，使用的是 Linux 操作系统，因为它的稳定性和资源管理能力更强。",
        "id": 813,
        "target_term": "Linux OS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们在处理数据时，需要特别注意处理 Outer 数据，这些数据点可能会对模型训练产生负面影响。",
        "sentence_B": "我们在处理数据时，需要特别注意处理外部数据，这些数据点可能会对模型训练产生负面影响。",
        "id": 814,
        "target_term": "Outer",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们发现了一个常见的问题。",
        "sentence_A": "在数据清洗阶段，我们发现了一些数据的 Overlapping 问题，这可能导致模型训练时出现偏差。",
        "sentence_B": "在数据清洗阶段，我们发现了一些数据的重叠问题，这可能导致模型训练时出现偏差。",
        "id": 815,
        "target_term": "Overlapping",
        "is_hardcore": true
    },
    {
        "topic": "Overfitting",
        "prefix": "在模型训练过程中，我们发现模型在训练集上的表现很好，但在验证集上的表现却差很多。",
        "sentence_A": "我们发现模型在训练集上表现很好，但在验证集上表现很差，这可能是 Overfitting 了。",
        "sentence_B": "我们发现模型在训练集上表现很好，但在验证集上表现很差，这可能是过拟合了。",
        "id": 816,
        "target_term": "Overfitting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在团队会议中讨论模型训练的整体情况",
        "sentence_A": "在今天的会议上，我们主要讨论了模型训练的 Overview，包括数据集的质量和训练过程中的优化策略。",
        "sentence_B": "在今天的会议上，我们主要讨论了模型训练的总体情况，包括数据集的质量和训练过程中的优化策略。",
        "id": 817,
        "target_term": "Overview",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到使用PALM进行多任务学习。",
        "sentence_A": "我们在训练多任务模型时，发现使用 PALM 可以显著提高模型的泛化能力。",
        "sentence_B": "我们在训练多任务模型时，发现使用路径感知语言模型（PALM）可以显著提高模型的泛化能力。",
        "id": 818,
        "target_term": "PALM",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型架构优化时",
        "sentence_A": "我们在设计模型时，可以考虑使用 PAN 结构来提高特征提取的效率。",
        "sentence_B": "我们在设计模型时，可以考虑使用金字塔注意网络（PAN）结构来提高特征提取的效率。",
        "id": 819,
        "target_term": "PAN",
        "is_hardcore": true
    },
    {
        "topic": "Principal Component Analysis",
        "prefix": "在讨论模型训练的数据预处理阶段，团队成员提到使用PCA进行维度缩减。",
        "sentence_A": "在数据预处理阶段，我们可以用 PCA 来减少特征维度，这样可以提高模型的训练效率。",
        "sentence_B": "在数据预处理阶段，我们可以使用主成分分析来减少特征维度，这样可以提高模型的训练效率。",
        "id": 820,
        "target_term": "PCA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的性能优化时",
        "sentence_A": "我们在训练模型时，发现使用 PCI 接口可以显著提升数据传输速度。",
        "sentence_B": "我们在训练模型时，发现使用PCI接口可以显著提升数据传输速度。",
        "id": 821,
        "target_term": "PCI",
        "is_hardcore": true
    },
    {
        "topic": "PCM in Model Training",
        "prefix": "在讨论模型训练过程中数据编码的优化方案时",
        "sentence_A": "我们在模型训练中使用了 PCM 技术，效果显著。",
        "sentence_B": "我们在模型训练中使用了脉冲编码调制（PCM）技术，效果显著。",
        "id": 822,
        "target_term": "PCM",
        "is_hardcore": true
    },
    {
        "topic": "Partial Differential Equations in AI Models",
        "prefix": "在讨论模型训练中的数学问题时",
        "sentence_A": "我们在训练模型时，需要解决一些 PDE 问题，以确保模型的稳定性和准确性。",
        "sentence_B": "我们在训练模型时，需要解决一些偏微分方程问题，以确保模型的稳定性和准确性。",
        "id": 823,
        "target_term": "PDE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的预处理方法时",
        "sentence_A": "我们在处理训练数据时，使用了 PDS 来优化数据的分布，这样可以更好地提高模型的泛化能力。",
        "sentence_B": "我们在处理训练数据时，使用了概率数据流（PDS）来优化数据的分布，这样可以更好地提高模型的泛化能力。",
        "id": 824,
        "target_term": "PDS",
        "is_hardcore": true
    },
    {
        "topic": "Positional Encoding",
        "prefix": "在讨论Transformer模型的训练过程中，团队成员提到PE的重要性。",
        "sentence_A": "在Transformer模型中，PE (Positional Encoding) 是非常关键的，它帮助模型理解序列中的位置信息。",
        "sentence_B": "在Transformer模型中，位置编码（Positional Encoding）是非常关键的，它帮助模型理解序列中的位置信息。",
        "id": 825,
        "target_term": "Transformer",
        "is_hardcore": true
    },
    {
        "topic": "Pre-trained Models",
        "prefix": "在讨论模型微调的时候，",
        "sentence_A": "我们最近在用的这个 PET 技术，真的挺厉害的，能显著提升模型的性能。",
        "sentence_B": "我们最近在使用的这个预训练技术，真的非常有效，能够显著提升模型的性能。",
        "id": 826,
        "target_term": "PET",
        "is_hardcore": true
    },
    {
        "topic": "Policy Gradient",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "在训练强化学习模型时，我们通常使用 PG 方法来优化策略。",
        "sentence_B": "在训练强化学习模型时，我们通常使用策略梯度（Policy Gradient）方法来优化策略。",
        "id": 827,
        "target_term": "PG",
        "is_hardcore": false
    },
    {
        "topic": "Adversarial Training",
        "prefix": "在讨论模型的对抗训练时",
        "sentence_A": "这次我们在模型训练中用到了 PGD，效果挺不错的。",
        "sentence_B": "这次我们在模型训练中使用了投影梯度下降（PGD），效果非常不错。",
        "id": 828,
        "target_term": "PGD",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在调整超参数的时候，需要特别关注 PI 的设置，这直接影响到模型的性能。",
        "sentence_B": "我们在调整超参数的时候，需要特别关注性能指标（PI）的设置，这直接影响到模型的性能。",
        "id": 829,
        "target_term": "PI",
        "is_hardcore": false
    },
    {
        "topic": "PID Control in AI Systems",
        "prefix": "在讨论模型训练过程中的控制算法时",
        "sentence_A": "我们在模型训练过程中使用了 PID 控制器来优化参数调整的速度和稳定性。",
        "sentence_B": "我们在模型训练过程中使用了比例积分微分（PID）控制器来优化参数调整的速度和稳定性。",
        "id": 830,
        "target_term": "PID",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在进行模型推理优化时，讨论了如何利用PIM技术提升性能",
        "sentence_A": "我们最近在研究如何通过 PIM 技术来优化模型的推理速度，效果还不错。",
        "sentence_B": "我们最近在研究如何通过处理指令集（PIM）技术来优化模型的推理速度，效果还不错。",
        "id": 831,
        "target_term": "PIM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的流程时",
        "sentence_A": "我们在训练过程中遇到了一些问题，特别是在 PIT 阶段，模型的性能明显下降。",
        "sentence_B": "我们在训练过程中遇到了一些问题，特别是在参数初始化阶段，模型的性能明显下降。",
        "id": 832,
        "target_term": "PIT",
        "is_hardcore": true
    },
    {
        "topic": "Programming Language",
        "prefix": "在讨论模型训练的脚本选择时",
        "sentence_A": "我们这次用 Python 来写训练脚本，因为它的 PL 支持库非常丰富，而且社区活跃。",
        "sentence_B": "我们这次用 Python 来写训练脚本，因为它的编程语言支持库非常丰富，而且社区活跃。",
        "id": 833,
        "target_term": "Python",
        "is_hardcore": true
    },
    {
        "topic": "Perceptron Learning Algorithm",
        "prefix": "在模型训练过程中，我们讨论了如何优化算法",
        "sentence_A": "在训练模型时，我们发现使用 PLA 可以显著提高分类的准确性。",
        "sentence_B": "在训练模型时，我们发现使用感知器学习算法可以显著提高分类的准确性。",
        "id": 834,
        "target_term": "PLA",
        "is_hardcore": true
    },
    {
        "topic": "Phrase-Level Learning",
        "prefix": "在讨论模型训练时，同事提到了一个关键的技术点",
        "sentence_A": "我们在训练这个模型时，用到了 PLL 技术，效果提升很明显。",
        "sentence_B": "我们在训练这个模型时，使用了短语级学习技术，效果提升非常明显。",
        "id": 835,
        "target_term": "PLL",
        "is_hardcore": true
    },
    {
        "topic": "Pre-trained Language Model",
        "prefix": "在模型训练过程中，团队讨论如何优化现有的预训练模型",
        "sentence_A": "我们在讨论如何通过微调现有的 PLM 来提高模型的性能。",
        "sentence_B": "我们在讨论如何通过微调现有的预训练语言模型来提高模型的性能。",
        "id": 836,
        "target_term": "PLM",
        "is_hardcore": true
    },
    {
        "topic": "Pre-trained Language Models",
        "prefix": "在讨论模型优化的会议上，团队成员正在讨论如何提高模型的泛化能力。",
        "sentence_A": "我们在用 PLM 做迁移学习时，需要注意模型的泛化能力，特别是在小样本任务上。",
        "sentence_B": "我们在使用预训练语言模型进行迁移学习时，需要注意模型的泛化能力，特别是在小样本任务上。",
        "id": 837,
        "target_term": "PLM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论模型训练的进度和计划。",
        "sentence_A": "我们最近的模型训练进度有点慢，PM 需要调整一下时间表。",
        "sentence_B": "我们最近的模型训练进度有点慢，项目经理需要调整一下时间表。",
        "id": 838,
        "target_term": "PM",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们需要在训练过程中引入 PNC 技术，以提高模型的泛化能力。",
        "sentence_B": "我们需要在训练过程中引入个性化归一化（PNC）技术，以提高模型的泛化能力。",
        "id": 839,
        "target_term": "PNC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练中的常见问题时",
        "sentence_A": "我们在训练过程中遇到了 PNF 问题，这导致模型在某些数据集上的表现不佳。",
        "sentence_B": "我们在训练过程中遇到了参数规范化失效（PNF）问题，这导致模型在某些数据集上的表现不佳。",
        "id": 840,
        "target_term": "PNF",
        "is_hardcore": true
    },
    {
        "topic": "PNN in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到PNN的性能优势。",
        "sentence_A": "我们在训练这个模型时，发现使用 PNN 可以显著提升性能，尤其是在处理大规模数据集时。",
        "sentence_B": "我们在训练这个模型时，发现使用概率神经网络（PNN）可以显著提升性能，尤其是在处理大规模数据集时。",
        "id": 841,
        "target_term": "PNN",
        "is_hardcore": true
    },
    {
        "topic": "PPO in Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们这次可以试试用 PPO 来优化策略网络，看看效果如何。",
        "sentence_B": "我们可以尝试使用近端策略优化（PPO）来优化策略网络，看看效果如何。",
        "id": 842,
        "target_term": "PPO",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "我们在训练模型时，发现 PPM 有些高，需要优化数据预处理流程。",
        "sentence_B": "我们在训练模型时，发现每分钟处理的图片数量（PPM）有些高，需要优化数据预处理流程。",
        "id": 843,
        "target_term": "PPM",
        "is_hardcore": true
    },
    {
        "topic": "Probabilistic Programming Networks",
        "prefix": "在模型训练过程中，我们遇到了一些性能瓶颈。",
        "sentence_A": "我们在调参的时候发现，使用 PPN 能够显著提升模型的训练效率。",
        "sentence_B": "我们在调参的时候发现，使用概率编程网络（PPN）能够显著提升模型的训练效率。",
        "id": 844,
        "target_term": "PPN",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，团队讨论了模型的性能指标。",
        "sentence_A": "咱们这次的 PR 值比上次高了不少，看来优化算法还是有效的。",
        "sentence_B": "这次的精确率值比上次高了不少，看来优化算法还是有效的。",
        "id": 845,
        "target_term": "PR",
        "is_hardcore": false
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，我们经常讨论各种性能指标。",
        "sentence_A": "在评估这个模型的时候，我们特别关注它的 PRA 曲线，因为它能更全面地反映模型在不同阈值下的表现。",
        "sentence_B": "在评估这个模型的时候，我们特别关注它的精度-召回率-面积（PRA）曲线，因为它能更全面地反映模型在不同阈值下的表现。",
        "id": 846,
        "target_term": "PRA",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们经常讨论模型的评估指标。",
        "sentence_A": "在模型训练时，我们不仅要关注 Recall，还要关注 Precision，这样才能确保模型在真实场景中的表现。",
        "sentence_B": "在模型训练时，我们不仅要关注召回率，还要关注精确率，这样才能确保模型在真实场景中的表现。",
        "id": 847,
        "target_term": "Recall",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的预处理阶段时",
        "sentence_A": "在训练模型之前，我们必须要确保数据的 Precondition，比如数据的格式、分布和完整性。",
        "sentence_B": "在训练模型之前，我们必须要确保数据的前置条件，比如数据的格式、分布和完整性。",
        "id": 848,
        "target_term": "Precondition",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的准备工作时",
        "sentence_A": "在开始训练模型之前，我们一定要检查好所有的 precondition，确保数据集和环境都准备妥当。",
        "sentence_B": "在开始训练模型之前，我们一定要检查好所有的前提条件，确保数据集和环境都准备妥当。",
        "id": 849,
        "target_term": "precondition",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在用 Pretrained 模型做微调的时候，发现效果比从头训练要好很多。",
        "sentence_B": "我们在用预训练模型做微调的时候，发现效果比从头训练要好很多。",
        "id": 850,
        "target_term": "Pretrained",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的高效方法时",
        "sentence_A": "我们可以通过 Pretraining 来提升模型的初始性能，这样在 Fine-tuning 阶段就能更快地收敛。",
        "sentence_B": "我们可以通过预训练来提升模型的初始性能，这样在微调阶段就能更快地收敛。",
        "id": 851,
        "target_term": "Pretraining",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，如果使用 Prima 方法，可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练模型时，如果使用主成分分析方法，可以显著提高模型的收敛速度。",
        "id": 852,
        "target_term": "Prima",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的代码审查中，高级工程师指出了一个常见的错误。",
        "sentence_A": "在定义模型的初始层时，我们不应该直接使用 TensorFlow 的 low-level Primitive，因为这会增加代码的复杂性和维护成本。",
        "sentence_B": "在定义模型的初始层时，我们不应该直接使用 TensorFlow 的低级原语，因为这会增加代码的复杂性和维护成本。",
        "id": 853,
        "target_term": "TensorFlow",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，高级工程师提到一个重要的角色",
        "sentence_A": "在我们的模型训练过程中，Principal 角色起到了关键作用，负责整体的技术方向和决策。",
        "sentence_B": "在我们的模型训练过程中，首席工程师角色起到了关键作用，负责整体的技术方向和决策。",
        "id": 854,
        "target_term": "Principal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型的训练过程时",
        "sentence_A": "我们在训练模型时，需要设置合理的 Prior，这样才能更好地引导模型学习。",
        "sentence_B": "我们在训练模型时，需要设置合理的先验，这样才能更好地引导模型学习。",
        "id": 855,
        "target_term": "Prior",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的优先级时",
        "sentence_A": "我们在训练数据时，需要确保 Prioritized 数据集优先处理，这样才能保证模型的性能。",
        "sentence_B": "我们在训练数据时，需要确保优先级高的数据集优先处理，这样才能保证模型的性能。",
        "id": 856,
        "target_term": "Prioritized",
        "is_hardcore": true
    },
    {
        "topic": "Data Privacy in Model Training",
        "prefix": "在讨论模型训练时的数据隐私问题时",
        "sentence_A": "我们需要确保在训练模型时，所有 Private 数据都经过了严格的脱敏处理。",
        "sentence_B": "我们需要确保在训练模型时，所有私有数据都经过了严格的脱敏处理。",
        "id": 857,
        "target_term": "Private",
        "is_hardcore": true
    },
    {
        "topic": "Data Access Control",
        "prefix": "在讨论数据访问控制策略时",
        "sentence_A": "我们在设计数据访问策略时，需要特别注意用户的 Privilege 管理，确保每个用户只能访问他们应该访问的数据。",
        "sentence_B": "我们在设计数据访问策略时，需要特别注意用户的权限管理，确保每个用户只能访问他们应该访问的数据。",
        "id": 858,
        "target_term": "Privilege",
        "is_hardcore": true
    },
    {
        "topic": "Probabilities in Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们需要更好地理解 probabilitie，这样才能在模型训练过程中做出更合理的决策。",
        "sentence_B": "我们需要更好地理解概率，这样才能在模型训练过程中做出更合理的决策。",
        "id": 859,
        "target_term": "probabilitie",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要检查模型的内部状态，以确保它按预期工作。",
        "sentence_A": "在训练过程中，我们通过 Probing 来检查模型的中间层输出，确保模型在各个阶段的表现都符合预期。",
        "sentence_B": "在训练过程中，我们通过探针来检查模型的中间层输出，确保模型在各个阶段的表现都符合预期。",
        "id": 860,
        "target_term": "Probing",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时，团队成员提到：",
        "sentence_A": "我们在 Production 环境中遇到了一些性能瓶颈，需要优化模型的推理速度。",
        "sentence_B": "我们在生产环境中遇到了一些性能瓶颈，需要优化模型的推理速度。",
        "id": 861,
        "target_term": "Production",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们需要优化这个 Program 的效率，确保在大规模数据集上训练时不会出现性能瓶颈。",
        "sentence_B": "我们需要优化这个程序的效率，确保在大规模数据集上训练时不会出现性能瓶颈。",
        "id": 862,
        "target_term": "Program",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化代码效率。",
        "sentence_A": "在模型训练过程中，我们发现通过优化 Programming 可以显著提升训练速度。",
        "sentence_B": "在模型训练过程中，我们发现通过优化编程可以显著提升训练速度。",
        "id": 863,
        "target_term": "Programming",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练流程时",
        "sentence_A": "我们可以通过优化 Program 来提高训练效率。",
        "sentence_B": "我们可以通过优化程序来提高训练效率。",
        "id": 864,
        "target_term": "Program",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在团队会议中讨论模型训练的最新进展",
        "sentence_A": "我们在模型训练的 progres 上取得了显著的进展，接下来需要优化推理速度。",
        "sentence_B": "我们在模型训练的进展上取得了显著的进展，接下来需要优化推理速度。",
        "id": 865,
        "target_term": "progres",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的进度时",
        "sentence_A": "我们这个 Project 的模型训练进度已经超过了70%，预计下周可以完成全部训练。",
        "sentence_B": "我们这个项目的模型训练进度已经超过了70%，预计下周可以完成全部训练。",
        "id": 866,
        "target_term": "Project",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们可以通过 Projection 来降低高维数据的复杂度，从而提高模型的训练效率。",
        "sentence_B": "我们可以通过投影来降低高维数据的复杂度，从而提高模型的训练效率。",
        "id": 867,
        "target_term": "Projection",
        "is_hardcore": true
    },
    {
        "topic": "Forward Propagation in Neural Networks",
        "prefix": "在讨论模型训练过程中，团队成员提到前向传播的重要性。",
        "sentence_A": "在训练过程中，Propagating 信息从输入层到输出层是确保模型学习到正确特征的关键步骤。",
        "sentence_B": "在训练过程中，前向传播信息从输入层到输出层是确保模型学习到正确特征的关键步骤。",
        "id": 868,
        "target_term": "Propagating",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中的误差传递问题时，团队成员提到：",
        "sentence_A": "在训练过程中，我们需要注意 error propagation 的影响，确保每个层的梯度都能正确传递。",
        "sentence_B": "在训练过程中，我们需要注意误差传播的影响，确保每个层的梯度都能正确传递。",
        "id": 869,
        "target_term": "error propagation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何改进模型的检测精度时，团队成员提出了一个新想法。",
        "sentence_A": "我们在讨论如何提高模型的检测精度时，小王提出了一个很好的 Proposal，可以显著提升模型的性能。",
        "sentence_B": "我们在讨论如何提高模型的检测精度时，小王提出了一个很好的提案，可以显著提升模型的性能。",
        "id": 870,
        "target_term": "Proposal",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在讨论目标检测模型的改进方案时",
        "sentence_A": "我们最近在讨论如何改进模型的 Proposal 生成部分，以提高检测的准确率。",
        "sentence_B": "我们最近在讨论如何改进模型的候选区域生成部分，以提高检测的准确率。",
        "id": 871,
        "target_term": "Proposal",
        "is_hardcore": true
    },
    {
        "topic": "Communication Protocols in AI Development",
        "prefix": "在讨论模型部署时，团队成员提到了通信协议的选择。",
        "sentence_A": "我们在讨论模型部署时，需要确定使用哪种 Protocol，确保系统之间的高效通信。",
        "sentence_B": "我们在讨论模型部署时，需要确定使用哪种通信协议，确保系统之间的高效通信。",
        "id": 872,
        "target_term": "Protocol",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论新模型的设计时，团队成员提到需要先做一个初步的模型来验证想法。",
        "sentence_A": "我们先做个 Prototype，验证一下这个想法是否可行。",
        "sentence_B": "我们先做个原型，验证一下这个想法是否可行。",
        "id": 873,
        "target_term": "Prototype",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初步方案时",
        "sentence_A": "我们在设计模型训练的 Prototype 时，需要考虑到多个因素，比如数据预处理和模型结构。",
        "sentence_B": "我们在设计模型训练的原型时，需要考虑到多个因素，比如数据预处理和模型结构。",
        "id": 874,
        "target_term": "Prototype",
        "is_hardcore": true
    },
    {
        "topic": "Proximal Gradient Methods",
        "prefix": "在讨论模型训练的优化算法时，团队成员提到：",
        "sentence_A": "我们在使用 Proximal 梯度方法时，发现模型的收敛速度更快，而且对不光滑的目标函数非常有效。",
        "sentence_B": "我们在使用近端梯度方法时，发现模型的收敛速度更快，而且对非光滑的目标函数非常有效。",
        "id": 875,
        "target_term": "Proximal",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型优化策略时",
        "sentence_A": "我们可以通过 Pruning 来减少模型的参数量，提高推理速度。",
        "sentence_B": "我们可以通过剪枝来减少模型的参数量，提高推理速度。",
        "id": 876,
        "target_term": "Pruning",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在处理文本数据时，我们经常需要处理标点符号的问题。",
        "sentence_A": "在数据清洗阶段，我们发现处理 Punctuation 对模型的性能有很大影响。",
        "sentence_B": "在数据清洗阶段，我们发现处理标点符号对模型的性能有很大影响。",
        "id": 877,
        "target_term": "Punctuation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练目标时",
        "sentence_A": "这次训练的 Purpose 就是提高模型在低资源环境下的性能。",
        "sentence_B": "这次训练的目的是提高模型在低资源环境下的性能。",
        "id": 878,
        "target_term": "Purpose",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了框架的选择。",
        "sentence_A": "我们在讨论模型训练的时候，决定使用 Pytorch，因为它的动态图机制非常适合我们的项目。",
        "sentence_B": "我们在讨论模型训练的时候，决定使用PyTorch，因为它的动态图机制非常适合我们的项目。",
        "id": 879,
        "target_term": "Pytorch",
        "is_hardcore": true
    },
    {
        "topic": "QA in Model Training",
        "prefix": "在模型训练过程中，我们经常需要进行QA测试来确保模型的准确性和鲁棒性。",
        "sentence_A": "在模型训练过程中，我们经常需要进行 QA 测试来确保模型的准确性和鲁棒性。",
        "sentence_B": "在模型训练过程中，我们经常需要进行质量保证测试来确保模型的准确性和鲁棒性。",
        "id": 880,
        "target_term": "QA",
        "is_hardcore": false
    },
    {
        "topic": "Quality Control in Model Training",
        "prefix": "在模型训练的最后阶段，我们需要进行一系列的质量检查。",
        "sentence_A": "在模型训练的最后阶段，我们需要进行一系列的 QC，确保模型的性能和稳定性。",
        "sentence_B": "在模型训练的最后阶段，我们需要进行一系列的质量控制，确保模型的性能和稳定性。",
        "id": 881,
        "target_term": "QC",
        "is_hardcore": false
    },
    {
        "topic": "QoS in Model Deployment",
        "prefix": "在讨论模型部署的性能优化时",
        "sentence_A": "我们在部署模型时，不仅要关注性能，还要确保 QoS 能够满足业务需求。",
        "sentence_B": "我们在部署模型时，不仅要关注性能，还要确保服务质量能够满足业务需求。",
        "id": 882,
        "target_term": "QoS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化模型的性能。",
        "sentence_A": "我们在讨论模型训练时，特别提到需要优化 QTL，以确保模型在高并发请求下的性能。",
        "sentence_B": "我们在讨论模型训练时，特别提到需要优化量化阈值限（QTL），以确保模型在高并发请求下的性能。",
        "id": 883,
        "target_term": "QTL",
        "is_hardcore": true
    },
    {
        "topic": "QTLS in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了一个优化技术。",
        "sentence_A": "我们在训练模型时，发现使用 QTLS 可以显著提高模型的性能。",
        "sentence_B": "我们在训练模型时，发现使用量子最优化算法（QTLS）可以显著提高模型的性能。",
        "id": 884,
        "target_term": "QTLS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了一些性能瓶颈。",
        "sentence_A": "我们在训练 Qbert 模型时，发现它的收敛速度比我们预期的要慢。",
        "sentence_B": "我们在训练 Qbert 模型时，发现它的收敛速度比我们预期的要慢。",
        "id": 885,
        "target_term": "Qbert",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，团队讨论了不同类型的评估方法。",
        "sentence_A": "我们在评估模型时，不仅要关注 Quantitative 的指标，还要考虑 Qualitative 的结果。",
        "sentence_B": "我们在评估模型时，不仅要关注定量的指标，还要考虑定性的结果。",
        "id": 886,
        "target_term": "Quantitative",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们可以通过 Quantification 来减少模型的存储和计算开销，同时保持性能。",
        "sentence_B": "我们可以通过量化来减少模型的存储和计算开销，同时保持性能。",
        "id": 887,
        "target_term": "Quantification",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型推理优化的过程中",
        "sentence_A": "我们在模型的推理优化中采用了 Quantization 技术，显著降低了模型的内存占用。",
        "sentence_B": "我们在模型的推理优化中采用了量化技术，显著降低了模型的内存占用。",
        "id": 888,
        "target_term": "Quantization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的特性时",
        "sentence_A": "我们在处理训练数据时，需要确保数据的 Quantitative 特征是准确的，这样才能保证模型的性能。",
        "sentence_B": "我们在处理训练数据时，需要确保数据的定量特征是准确的，这样才能保证模型的性能。",
        "id": 889,
        "target_term": "Quantitative",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中引入了 Quasi-Newton 方法，效果挺不错的。",
        "sentence_B": "我们在训练过程中引入了准牛顿方法，效果挺不错的。",
        "id": 890,
        "target_term": "Quasi-Newton",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的准备时",
        "sentence_A": "我们需要确保训练数据中的每个 Querie 都是高质量的，这样才能保证模型的性能。",
        "sentence_B": "我们需要确保训练数据中的每个查询都是高质量的，这样才能保证模型的性能。",
        "id": 891,
        "target_term": "Querie",
        "is_hardcore": true
    },
    {
        "topic": "Query Processing",
        "prefix": "在讨论模型训练数据的预处理阶段时",
        "sentence_A": "我们在处理数据时，需要特别注意每个 Query 的格式和内容，确保它们符合模型的输入要求。",
        "sentence_B": "我们在处理数据时，需要特别注意每个查询的格式和内容，确保它们符合模型的输入要求。",
        "id": 892,
        "target_term": "Query",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们遇到了一个关于用户反馈的问题。",
        "sentence_A": "在数据清洗阶段，我们遇到了一个关于用户反馈的 Question。",
        "sentence_B": "在数据清洗阶段，我们遇到了一个关于用户反馈的问题。",
        "id": 893,
        "target_term": "Question",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，数据标注的质量直接影响模型的性能。",
        "sentence_A": "我们在数据标注阶段遇到了很多 Question，需要确保每个标注都是准确无误的。",
        "sentence_B": "我们在数据标注阶段遇到了很多问题，需要确保每个标注都是准确无误的。",
        "id": 894,
        "target_term": "Question",
        "is_hardcore": false
    },
    {
        "topic": "Memory Management",
        "prefix": "在优化模型推理性能时，我们经常讨论内存使用情况。",
        "sentence_A": "为了提高模型的推理速度，我们需要优化对 RAM 的使用，确保不会因为内存瓶颈影响性能。",
        "sentence_B": "为了提高模型的推理速度，我们需要优化对内存的使用，确保不会因为内存瓶颈影响性能。",
        "id": 895,
        "target_term": "RAM",
        "is_hardcore": true
    },
    {
        "topic": "RBF Kernel in Machine Learning",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在模型训练中使用了 RBF 核函数，效果非常好。",
        "sentence_B": "我们在模型训练中使用了径向基函数（RBF）核函数，效果非常好。",
        "id": 896,
        "target_term": "RBF",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在讨论模型训练和评估的过程中",
        "sentence_A": "我们在训练模型时，发现使用 RC 方法可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练模型时，发现使用残差连接（RC）方法可以显著提高模型的收敛速度。",
        "id": 897,
        "target_term": "RC",
        "is_hardcore": false
    },
    {
        "topic": "RCNN in Object Detection",
        "prefix": "在模型训练阶段，团队讨论如何优化目标检测模型的性能。",
        "sentence_A": "我们在训练 RCNN 模型时，发现数据集中的标注有些问题，需要进一步清洗。",
        "sentence_B": "我们在训练区域卷积神经网络（RCNN）模型时，发现数据集中的标注有些问题，需要进一步清洗。",
        "id": 898,
        "target_term": "RCNN",
        "is_hardcore": true
    },
    {
        "topic": "RDB in Model Training",
        "prefix": "在讨论模型训练数据存储方案时",
        "sentence_A": "我们在模型训练中使用了 RDB 来存储中间结果，这样可以提高数据查询的效率。",
        "sentence_B": "我们在模型训练中使用了关系数据库（RDB）来存储中间结果，这样可以提高数据查询的效率。",
        "id": 899,
        "target_term": "RDB",
        "is_hardcore": true
    },
    {
        "topic": "RDP in Model Training",
        "prefix": "在模型训练过程中，我们经常需要远程调试。",
        "sentence_A": "在训练这个复杂的模型时，我们通常会用 RDP 连接到远程服务器进行调试，这样效率会高很多。",
        "sentence_B": "在训练这个复杂的模型时，我们通常会使用远程桌面协议（RDP）连接到远程服务器进行调试，这样效率会高很多。",
        "id": 900,
        "target_term": "RDP",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中讨论特征工程的重要性",
        "sentence_A": "我们在处理文本数据时，RE 特征对模型的性能提升非常明显。",
        "sentence_B": "我们在处理文本数据时，关系抽取（RE）特征对模型的性能提升非常明显。",
        "id": 901,
        "target_term": "RE",
        "is_hardcore": false
    },
    {
        "topic": "Model Inference",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在做模型推理优化时，REASONING 部分的效率提升特别关键，这直接影响了模型的响应时间。",
        "sentence_B": "我们在进行模型推理优化时，推理部分的效率提升特别关键，这直接影响了模型的响应时间。",
        "id": 902,
        "target_term": "REASONING",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据选择时",
        "sentence_A": "我们在训练模型时，需要确保数据集中的 REC 足够丰富，这样才能提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要确保数据集中的推荐记录（REC）足够丰富，这样才能提高模型的泛化能力。",
        "id": 903,
        "target_term": "REC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到一个关键概念。",
        "sentence_A": "我们可以通过引入 RED 来优化模型的训练过程，这样可以更有效地减少过拟合。",
        "sentence_B": "我们可以通过引入残差网络（Residual Network, ResNet）来优化模型的训练过程，这样可以更有效地减少过拟合。",
        "id": 904,
        "target_term": "RED",
        "is_hardcore": true
    },
    {
        "topic": "Activation Function",
        "prefix": "在讨论模型训练的效率和效果时",
        "sentence_A": "我们在训练模型时发现，使用 RELU 作为激活函数可以显著提高训练速度和模型性能。",
        "sentence_B": "我们在训练模型时发现，使用ReLU作为激活函数可以显著提高训练速度和模型性能。",
        "id": 905,
        "target_term": "RELU",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练中的数据表示方法时",
        "sentence_A": "我们这次可以用 REP 来优化特征表示，这样模型的泛化能力会更强。",
        "sentence_B": "我们这次可以用表示学习（Representation Learning）来优化特征表示，这样模型的泛化能力会更强。",
        "id": 906,
        "target_term": "REP",
        "is_hardcore": true
    },
    {
        "topic": "Resource Allocation in Model Training",
        "prefix": "在讨论模型训练资源分配时",
        "sentence_A": "我们需要确保每个任务都能在分配到足够的 RES 后顺利进行。",
        "sentence_B": "我们需要确保每个任务都能在分配到足够的资源后顺利进行。",
        "id": 907,
        "target_term": "RES",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Optimization",
        "prefix": "在讨论模型训练过程中遇到的频率共振问题时",
        "sentence_A": "我们在模型训练时发现了一个频率上的 RESONANCE 问题，这导致了模型的性能下降。",
        "sentence_B": "我们在模型训练时发现了一个频率上的共振问题，这导致了模型的性能下降。",
        "id": 908,
        "target_term": "RESONANCE",
        "is_hardcore": true
    },
    {
        "topic": "Random Forest",
        "prefix": "在模型训练过程中，团队讨论了不同算法的优劣。",
        "sentence_A": "在选择模型时，我们考虑了 RF 和其他几种算法的性能。",
        "sentence_B": "在选择模型时，我们考虑了随机森林和其他几种算法的性能。",
        "id": 909,
        "target_term": "RF",
        "is_hardcore": false
    },
    {
        "topic": "Object Detection with FRCNN",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们最近在用 FRCNN 做目标检测，效果还不错，不过在大规模数据集上还需要进一步微调。",
        "sentence_B": "我们最近在使用快速区域卷积神经网络（FRCNN）进行目标检测，效果还不错，不过在大规模数据集上还需要进一步微调。",
        "id": 910,
        "target_term": "FRCNN",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到使用RL来提高模型的性能。",
        "sentence_A": "我们在训练过程中发现，用 RL 可以显著提升模型的性能，尤其是在复杂环境下的决策能力。",
        "sentence_B": "我们在训练过程中发现，使用强化学习可以显著提升模型的性能，尤其是在复杂环境下的决策能力。",
        "id": 911,
        "target_term": "RL",
        "is_hardcore": false
    },
    {
        "topic": "Reinforcement Learning Algorithms",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到使用了最新的RLA技术。",
        "sentence_A": "我们在最新的模型训练中采用了 RLA，效果提升非常明显。",
        "sentence_B": "我们在最新的模型训练中采用了强化学习算法（RLA），效果提升非常明显。",
        "id": 912,
        "target_term": "RLA",
        "is_hardcore": true
    },
    {
        "topic": "RLHF in Model Training",
        "prefix": "在讨论模型训练过程中如何优化对话质量时，同事提到了一种技术。",
        "sentence_A": "我们在用 RLHF 来提升模型的对话质量，效果还不错。",
        "sentence_B": "我们在使用强化学习与人类反馈（RLHF）来提升模型的对话质量，效果还不错。",
        "id": 913,
        "target_term": "RLHF",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning Systems",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在最新的 RLS 算法上做了很多优化，现在模型的性能提升明显。",
        "sentence_B": "我们在最新的强化学习系统算法上做了很多优化，现在模型的性能提升明显。",
        "id": 914,
        "target_term": "RLS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们需要监控各种指标来确保模型的性能。",
        "sentence_A": "在模型训练过程中，我们通常会用到 RMS 误差来评估模型的性能。",
        "sentence_B": "在模型训练过程中，我们通常会用到均方根误差（RMS）来评估模型的性能。",
        "id": 915,
        "target_term": "RMS",
        "is_hardcore": true
    },
    {
        "topic": "RNN in Model Training",
        "prefix": "在模型训练过程中，我们经常讨论RNN的应用。",
        "sentence_A": "我们在训练这个模型时，发现使用 RNN 可以更好地处理时间序列数据。",
        "sentence_B": "我们在训练这个模型时，发现使用循环神经网络可以更好地处理时间序列数据。",
        "id": 916,
        "target_term": "RNN",
        "is_hardcore": true
    },
    {
        "topic": "RNNs in Model Training",
        "prefix": "在讨论模型训练的会议中，团队正在评估不同模型的性能。",
        "sentence_A": "我们在训练 RNNS 时发现，它的长序列处理能力比其他模型更强。",
        "sentence_B": "我们在训练循环神经网络时发现，它的长序列处理能力比其他模型更强。",
        "id": 917,
        "target_term": "RNNS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议上，讨论如何优化模型的训练过程。",
        "sentence_A": "我们在训练模型时，需要特别注意 ROB 的设置，这直接影响到模型的稳定性和性能。",
        "sentence_B": "我们在训练模型时，需要特别注意随机过拟合批处理（ROB）的设置，这直接影响到模型的稳定性和性能。",
        "id": 918,
        "target_term": "ROB",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Deployment",
        "prefix": "在讨论模型训练和部署的会议上，团队成员提到了一个关键的技术组件。",
        "sentence_A": "在训练这个模型的时候，我们用到了 ROMA 来优化数据传输，效果显著。",
        "sentence_B": "在训练这个模型的时候，我们用到了远程对象管理架构（ROMA）来优化数据传输，效果显著。",
        "id": 919,
        "target_term": "ROMA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们这次的模型训练可以尝试用 ROMAN 方法来提高效率。",
        "sentence_B": "我们这次的模型训练可以尝试用随机优化方法来提高效率。",
        "id": 920,
        "target_term": "ROMAN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的随机性问题。",
        "sentence_A": "我们在训练模型时，发现 RP 的设置对最终效果影响很大。",
        "sentence_B": "我们在训练模型时，发现随机性参数（Random Parameter, RP）的设置对最终效果影响很大。",
        "id": 921,
        "target_term": "RP",
        "is_hardcore": false
    },
    {
        "topic": "Reinforcement Learning Policy",
        "prefix": "在模型训练过程中，我们讨论了如何优化策略网络的问题。",
        "sentence_A": "我们在训练模型时，发现使用 RPL 可以显著提高策略网络的稳定性。",
        "sentence_B": "我们在训练模型时，发现使用强化学习策略（RPL）可以显著提高策略网络的稳定性。",
        "id": 922,
        "target_term": "RPL",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率时，同事提到一个关键指标",
        "sentence_A": "我们最近在优化模型的 RQ，发现通过调整超参数可以显著提高训练效率。",
        "sentence_B": "我们最近在优化模型的检索质量（RQ），发现通过调整超参数可以显著提高训练效率。",
        "id": 923,
        "target_term": "RQ",
        "is_hardcore": false
    },
    {
        "topic": "Recommendation System",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练 RS 模型时，发现使用更精细的用户特征可以显著提升推荐效果。",
        "sentence_B": "我们在训练推荐系统模型时，发现使用更精细的用户特征可以显著提升推荐效果。",
        "id": 924,
        "target_term": "RS",
        "is_hardcore": false
    },
    {
        "topic": "RSS in Model Training",
        "prefix": "在讨论模型训练资源管理时",
        "sentence_A": "我们在训练模型时，需要注意监控每个节点的 RSS，确保不会因为内存溢出而导致训练中断。",
        "sentence_B": "我们在训练模型时，需要注意监控每个节点的驻留集大小（RSS），确保不会因为内存溢出而导致训练中断。",
        "id": 925,
        "target_term": "RSS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了RST的问题",
        "sentence_A": "在训练最新的NLP模型时，我们发现 RST 的处理对模型的性能影响很大。",
        "sentence_B": "在训练最新的NLP模型时，我们发现句法树（RST）的处理对模型的性能影响很大。",
        "id": 926,
        "target_term": "NLP",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们这次部署的模型在实际运行中的 RT 非常稳定，基本没有出现过卡顿的情况。",
        "sentence_B": "我们这次部署的模型在实际运行中的响应时间非常稳定，基本没有出现过卡顿的情况。",
        "id": 927,
        "target_term": "RT",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中发现，RTE 的性能提升非常显著，特别是在处理大规模数据集时。",
        "sentence_B": "我们在训练过程中发现，阅读理解任务（RTE）的性能提升非常显著，特别是在处理大规模数据集时。",
        "id": 928,
        "target_term": "RTE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在团队讨论模型训练的优化方案时",
        "sentence_A": "我们在讨论如何通过 RTL 来优化模型的训练效率。",
        "sentence_B": "我们在讨论如何通过反向传播来优化模型的训练效率。",
        "id": 929,
        "target_term": "RTL",
        "is_hardcore": true
    },
    {
        "topic": "RTMP Protocol in Video Streaming",
        "prefix": "在讨论视频流媒体传输优化时，",
        "sentence_A": "我们在优化视频流媒体传输时，使用了 RTMP 协议来确保低延迟和高稳定性。",
        "sentence_B": "我们在优化视频流媒体传输时，使用了实时消息传输协议（RTMP）来确保低延迟和高稳定性。",
        "id": 930,
        "target_term": "RTMP",
        "is_hardcore": true
    },
    {
        "topic": "Real-Time Processing",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在处理实时数据流时，RTP 的性能提升非常关键。",
        "sentence_B": "我们在处理实时数据流时，实时处理（RTP）的性能提升非常关键。",
        "id": 931,
        "target_term": "RTP",
        "is_hardcore": true
    },
    {
        "topic": "Network Latency Optimization",
        "prefix": "在讨论模型部署上线时",
        "sentence_A": "我们在优化模型部署时，一定要关注 RTT，因为它直接影响到用户的体验。",
        "sentence_B": "我们在优化模型部署时，一定要关注往返时间（RTT），因为它直接影响到用户的体验。",
        "id": 932,
        "target_term": "RTT",
        "is_hardcore": true
    },
    {
        "topic": "RUL Estimation in Industrial AI",
        "prefix": "在模型训练过程中，我们讨论了如何提高RUL预测的准确性。",
        "sentence_A": "在训练模型时，我们发现通过优化特征提取器可以显著提高 RUL 的预测精度。",
        "sentence_B": "在训练模型时，我们发现通过优化特征提取器可以显著提高剩余使用寿命（RUL）的预测精度。",
        "id": 933,
        "target_term": "RUL",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段",
        "sentence_A": "我们在准备训练数据时，需要确保数据集中的 RW 标注是准确的，这样才能提高模型的泛化能力。",
        "sentence_B": "我们在准备训练数据时，需要确保数据集中的读写标注是准确的，这样才能提高模型的泛化能力。",
        "id": 934,
        "target_term": "RW",
        "is_hardcore": false
    },
    {
        "topic": "Distributed Consensus Algorithm",
        "prefix": "在讨论分布式系统的共识算法时",
        "sentence_A": "我们在设计这个分布式系统时，决定采用 Raft 算法来保证数据的一致性。",
        "sentence_B": "我们在设计这个分布式系统时，决定采用Raft算法来保证数据的一致性。",
        "id": 935,
        "target_term": "Raft",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初期阶段，团队成员正在交流如何逐步提高模型的性能。",
        "sentence_A": "我们在训练初期需要逐步提高学习率，这个过程叫做 Ramp up，确保模型能够稳定收敛。",
        "sentence_B": "我们在训练初期需要逐步提高学习率，这个过程叫做逐步提升，确保模型能够稳定收敛。",
        "id": 936,
        "target_term": "Ramp up",
        "is_hardcore": true
    },
    {
        "topic": "Random Initialization in Neural Networks",
        "prefix": "在讨论神经网络的初始化方法时",
        "sentence_A": "我们在模型训练时，通常会用 Random 初始化来打破对称性，这样可以让网络更有效地学习。",
        "sentence_B": "我们在模型训练时，通常会用随机初始化来打破对称性，这样可以让网络更有效地学习。",
        "id": 937,
        "target_term": "Random",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行模型训练前的数据清洗过程中，我们讨论了如何处理数值特征的范围问题。",
        "sentence_A": "在数据清洗的时候，我们需要注意数值特征的 Range，确保它们在合理的范围内。",
        "sentence_B": "在数据清洗的时候，我们需要注意数值特征的范围，确保它们在合理的范围内。",
        "id": 938,
        "target_term": "Range",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化排名算法的性能。",
        "sentence_A": "在训练过程中，我们发现调整模型的 Rank 机制可以显著提升推荐系统的精度。",
        "sentence_B": "在训练过程中，我们发现调整模型的排名机制可以显著提升推荐系统的精度。",
        "id": 939,
        "target_term": "Rank",
        "is_hardcore": false
    },
    {
        "topic": "Ranking Algorithms",
        "prefix": "在模型训练中讨论排序算法的优化",
        "sentence_A": "我们在最新的模型训练中，尝试了几种不同的 Ranking 算法，效果提升明显。",
        "sentence_B": "我们在最新的模型训练中，尝试了几种不同的排序算法，效果提升明显。",
        "id": 940,
        "target_term": "Ranking",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以通过调整 Rank 来优化模型的性能。",
        "sentence_B": "我们可以通过调整秩来优化模型的性能。",
        "id": 941,
        "target_term": "Rank",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "我们这次的训练结果还不错，测试集上的准确率比上一轮提高了5%的 ratio。",
        "sentence_B": "我们这次的训练结果还不错，测试集上的准确率比上一轮提高了5%的比例。",
        "id": 942,
        "target_term": "5",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们讨论了如何处理不同特征的比例问题。",
        "sentence_A": "在数据清洗阶段，我们特别关注了不同特征的 Ratio，确保它们在模型训练中不会因为比例差异过大而影响性能。",
        "sentence_B": "在数据清洗阶段，我们特别关注了不同特征的比例，确保它们在模型训练中不会因为比例差异过大而影响性能。",
        "id": 943,
        "target_term": "Ratio",
        "is_hardcore": false
    },
    {
        "topic": "Distributed Computing",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以通过使用 Ray 来加速分布式训练，这样可以显著提高训练效率。",
        "sentence_B": "我们可以通过使用 Ray 来加速分布式训练，这样可以显著提高训练效率。",
        "id": 944,
        "target_term": "Ray",
        "is_hardcore": true
    },
    {
        "topic": "Relevance in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到特征的重要性",
        "sentence_A": "在训练这个推荐系统时，我们特别关注特征的 Relevance，确保模型能够学到用户的真实偏好。",
        "sentence_B": "在训练这个推荐系统时，我们特别关注特征的相关性，确保模型能够学到用户的真实偏好。",
        "id": 945,
        "target_term": "Relevance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时",
        "sentence_A": "我们不仅要关注模型的性能，还要确保它的 Reliability，这样才能在实际应用中保持一致的精度。",
        "sentence_B": "我们不仅要关注模型的性能，还要确保它的可靠性，这样才能在实际应用中保持一致的精度。",
        "id": 946,
        "target_term": "Reliability",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时，团队成员提到一个令人印象深刻的改进。",
        "sentence_A": "这次的训练结果真是 Remarkable，模型的准确率提升了5个百分点。",
        "sentence_B": "这次的训练结果真是显著，模型的准确率提升了5个百分点。",
        "id": 947,
        "target_term": "Remarkable",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Deployment",
        "prefix": "在讨论模型训练和部署的过程中，团队成员提到了远程服务器的使用。",
        "sentence_A": "我们在训练模型时，通常会用到 Remote 服务器，因为本地资源有限。",
        "sentence_B": "我们在训练模型时，通常会用到远程服务器，因为本地资源有限。",
        "id": 948,
        "target_term": "Remote",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练过程中，我们发现模型在某些数据上表现不佳，需要进行调整。",
        "sentence_A": "我们需要对这些数据进行 Repair，以确保模型在这些边缘案例上也能表现良好。",
        "sentence_B": "我们需要对这些数据进行修复，以确保模型在这些边缘案例上也能表现良好。",
        "id": 949,
        "target_term": "Repair",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们发现了一些问题",
        "sentence_A": "在数据清洗过程中，我们发现了一些 Repeated 的记录，需要进一步处理。",
        "sentence_B": "在数据清洗过程中，我们发现了一些重复的记录，需要进一步处理。",
        "id": 950,
        "target_term": "Repeated",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing and Analysis",
        "prefix": "在模型训练过程中，我们经常需要监控和分析数据的各个指标。",
        "sentence_A": "在训练过程中，我们使用了多种工具来处理 Reporting，确保数据的准确性和一致性。",
        "sentence_B": "在训练过程中，我们使用了多种工具来处理报表，确保数据的准确性和一致性。",
        "id": 951,
        "target_term": "Reporting",
        "is_hardcore": true
    },
    {
        "topic": "Version Control",
        "prefix": "在讨论项目代码管理时",
        "sentence_A": "我们最近在更新我们的代码库，确保每个分支都能稳定运行，这次的改动主要集中在 Repository 的优化上。",
        "sentence_B": "我们最近在更新我们的代码库，确保每个分支都能稳定运行，这次的改动主要集中在代码仓库的优化上。",
        "id": 952,
        "target_term": "Repository",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在讨论数据预处理时",
        "sentence_A": "在数据预处理阶段，我们经常需要对输入数据进行 Reshaping，以确保模型能够正确处理。",
        "sentence_B": "在数据预处理阶段，我们经常需要对输入数据进行重塑，以确保模型能够正确处理。",
        "id": 953,
        "target_term": "Reshaping",
        "is_hardcore": true
    },
    {
        "topic": "Residual Networks",
        "prefix": "在讨论模型训练时，团队成员提到了Residual的概念。",
        "sentence_A": "我们在训练这个模型时，发现使用 Residual 结构可以有效提升模型的性能。",
        "sentence_B": "我们在训练这个模型时，发现使用残差结构可以有效提升模型的性能。",
        "id": 954,
        "target_term": "Residual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何提高模型在复杂环境下的稳定性时",
        "sentence_A": "我们在训练模型时，要特别关注模型的 Resilience，确保它在各种复杂环境下都能保持高性能。",
        "sentence_B": "我们在训练模型时，要特别关注模型的韧性，确保它在各种复杂环境下都能保持高性能。",
        "id": 955,
        "target_term": "Resilience",
        "is_hardcore": true
    },
    {
        "topic": "Image Processing",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们这次用的训练集图像的 Resolution 比较高，对模型的训练效果帮助很大。",
        "sentence_B": "我们这次使用的训练集图像的分辨率比较高，对模型的训练效果帮助很大。",
        "id": 956,
        "target_term": "Resolution",
        "is_hardcore": true
    },
    {
        "topic": "ResNet in Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到ResNet的使用。",
        "sentence_A": "我们在训练这个模型时，发现使用 ResNet 可以显著提升精度。",
        "sentence_B": "我们在训练这个模型时，发现使用残差网络可以显著提升精度。",
        "id": 957,
        "target_term": "ResNet",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了使用ResNet18进行迁移学习的可能性。",
        "sentence_A": "我们打算用 ResNet18 做迁移学习，这样可以快速提升模型的性能。",
        "sentence_B": "我们打算用ResNet18做迁移学习，这样可以快速提升模型的性能。",
        "id": 958,
        "target_term": "ResNet18",
        "is_hardcore": true
    },
    {
        "topic": "Residual Networks (ResNets)",
        "prefix": "在讨论模型训练的优化方法时",
        "sentence_A": "我们在训练 ResNet 时，发现使用了更深的网络层后，模型的性能反而下降了，这可能是因为梯度消失问题。",
        "sentence_B": "我们在训练残差网络（ResNets）时，发现使用了更深的网络层后，模型的性能反而下降了，这可能是因为梯度消失问题。",
        "id": 959,
        "target_term": "ResNet",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "这次的数据清洗中，我们特别关注了图像的 Restoration，确保输入模型的数据质量。",
        "sentence_B": "这次的数据清洗中，我们特别关注了图像的恢复，确保输入模型的数据质量。",
        "id": 960,
        "target_term": "Restoration",
        "is_hardcore": true
    },
    {
        "topic": "Data Access Control",
        "prefix": "在讨论模型训练的数据访问权限时",
        "sentence_A": "我们需要确保只有经过授权的团队成员才能访问这些 Restricted 数据集。",
        "sentence_B": "我们需要确保只有经过授权的团队成员才能访问这些受限数据集。",
        "id": 961,
        "target_term": "Restricted",
        "is_hardcore": true
    },
    {
        "topic": "Reversal in Model Training",
        "prefix": "在模型训练过程中，我们遇到了一个棘手的问题。",
        "sentence_A": "在训练过程中，我们发现模型的性能出现了 Reversal，原本表现良好的模型突然变得不稳定。",
        "sentence_B": "在训练过程中，我们发现模型的性能出现了反转，原本表现良好的模型突然变得不稳定。",
        "id": 962,
        "target_term": "Reversal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到需要逆向操作某个步骤。",
        "sentence_A": "在训练过程中，我们可能需要对某些步骤进行 Reverse 操作，以确保模型的稳定性和准确性。",
        "sentence_B": "在训练过程中，我们可能需要对某些步骤进行逆向操作，以确保模型的稳定性和准确性。",
        "id": 963,
        "target_term": "Reverse",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论如何优化强化学习模型的训练过程时",
        "sentence_A": "我们可以通过调整 Reward 来优化模型的训练效果。",
        "sentence_B": "我们可以通过调整奖励来优化模型的训练效果。",
        "id": 964,
        "target_term": "Reward",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论模型训练的会议中",
        "sentence_A": "我们在设计算法时，必须确保 Reward 的设置能够正确引导模型学习。",
        "sentence_B": "我们在设计算法时，必须确保奖励的设置能够正确引导模型学习。",
        "id": 965,
        "target_term": "Reward",
        "is_hardcore": true
    },
    {
        "topic": "Robotics and AI Integration",
        "prefix": "在讨论如何将机器人集成到现有的AI系统中时",
        "sentence_A": "我们需要确保这个 Robot 能够在新的环境中稳定运行。",
        "sentence_B": "我们需要确保这个机器人能够在新的环境中稳定运行。",
        "id": 966,
        "target_term": "Robot",
        "is_hardcore": true
    },
    {
        "topic": "Robotic Process Automation",
        "prefix": "在模型训练阶段，团队讨论如何优化自动化流程。",
        "sentence_A": "在训练模型时，我们发现使用 Robotic Process Automation 可以大幅提高数据处理的效率。",
        "sentence_B": "在训练模型时，我们发现使用机器人流程自动化可以大幅提高数据处理的效率。",
        "id": 967,
        "target_term": "Robotic Process Automation",
        "is_hardcore": true
    },
    {
        "topic": "Robotics",
        "prefix": "在讨论模型训练时，团队成员提到了机器人技术的重要性。",
        "sentence_A": "在训练这个模型时，我们特别关注了 Robotic 方面的最新进展。",
        "sentence_B": "在训练这个模型时，我们特别关注了机器人技术方面的最新进展。",
        "id": 968,
        "target_term": "Robotic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时",
        "sentence_A": "这个模型的 Robust 性能很好，即使在数据噪声很大的情况下也能保持高精度。",
        "sentence_B": "这个模型的鲁棒性能很好，即使在数据噪声很大的情况下也能保持高精度。",
        "id": 969,
        "target_term": "Robust",
        "is_hardcore": true
    },
    {
        "topic": "Model Robustness",
        "prefix": "在模型训练过程中，我们经常讨论模型的鲁棒性。",
        "sentence_A": "在模型训练时，我们特别关注模型的 Robustnes，确保它在各种输入下都能表现稳定。",
        "sentence_B": "在模型训练时，我们特别关注模型的鲁棒性，确保它在各种输入下都能表现稳定。",
        "id": 970,
        "target_term": "Robustnes",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的分工时",
        "sentence_A": "在这个项目中，每个人都需要清楚自己的 Role，这样才能确保模型训练的顺利进行。",
        "sentence_B": "在这个项目中，每个人都需要清楚自己的角色，这样才能确保模型训练的顺利进行。",
        "id": 971,
        "target_term": "Role",
        "is_hardcore": false
    },
    {
        "topic": "Tree Data Structures in AI Models",
        "prefix": "在讨论模型的树状数据结构时",
        "sentence_A": "我们在处理这棵树时，需要特别关注 Root 节点的初始化。",
        "sentence_B": "我们在处理这棵树时，需要特别关注根节点的初始化。",
        "id": 972,
        "target_term": "Root",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在模型训练中使用了 Rotational 优化器，效果显著。",
        "sentence_B": "我们在模型训练中使用了旋转优化器，效果显著。",
        "id": 973,
        "target_term": "Rotational",
        "is_hardcore": true
    },
    {
        "topic": "Rounding in Model Training",
        "prefix": "在讨论模型训练中的数值处理问题时",
        "sentence_A": "我们在训练模型时，需要注意 Rounding 误差的累积，这可能会影响模型的最终精度。",
        "sentence_B": "我们在训练模型时，需要注意舍入误差的累积，这可能会影响模型的最终精度。",
        "id": 974,
        "target_term": "Rounding",
        "is_hardcore": true
    },
    {
        "topic": "Data Aggregation and Summary",
        "prefix": "在模型训练过程中，我们需要对数据进行汇总和处理。",
        "sentence_A": "在训练模型时，我们需要对每天的数据进行一个 Roundup，确保数据的完整性和一致性。",
        "sentence_B": "在训练模型时，我们需要对每天的数据进行一个汇总，确保数据的完整性和一致性。",
        "id": 975,
        "target_term": "Roundup",
        "is_hardcore": true
    },
    {
        "topic": "Rule-based System",
        "prefix": "在讨论模型训练时，团队成员提到规则的重要性",
        "sentence_A": "在模型训练中，我们不仅要依赖数据，还要利用一些预先定义的 Rule 来增强模型的泛化能力。",
        "sentence_B": "在模型训练中，我们不仅要依赖数据，还要利用一些预先定义的规则来增强模型的泛化能力。",
        "id": 976,
        "target_term": "Rule",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到...",
        "sentence_A": "我们这次的模型训练，可以考虑用 SA 技术来优化数据标注过程，提高标注效率。",
        "sentence_B": "我们这次的模型训练，可以考虑使用半监督学习技术来优化数据标注过程，提高标注效率。",
        "id": 977,
        "target_term": "SA",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们在训练这个强化学习模型时，决定采用 SAC 算法，因为它在连续动作空间中表现很好。",
        "sentence_B": "我们在训练这个强化学习模型时，决定采用软演员-评论家（SAC）算法，因为它在连续动作空间中表现很好。",
        "id": 978,
        "target_term": "SAC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化模型的训练效率。",
        "sentence_A": "我们在讨论如何通过使用 SAM 来提高模型的训练效率。",
        "sentence_B": "我们在讨论如何通过使用自适应矩估计方法（SAMs）来提高模型的训练效率。",
        "id": 979,
        "target_term": "SAM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化SAN的性能。",
        "sentence_A": "在模型训练过程中，我们讨论了如何优化 SAN 的性能，特别是如何减少训练时间。",
        "sentence_B": "在模型训练过程中，我们讨论了如何优化自注意力网络的性能，特别是如何减少训练时间。",
        "id": 980,
        "target_term": "SAN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，需要关注 SAT 的性能，这样才能确保模型在实际应用中的效果。",
        "sentence_B": "我们在训练模型时，需要关注可满足性问题（SAT）的性能，这样才能确保模型在实际应用中的效果。",
        "id": 981,
        "target_term": "SAT",
        "is_hardcore": true
    },
    {
        "topic": "SCADA System Integration",
        "prefix": "在讨论模型训练数据源的会议上，团队成员提到SCADA系统的数据。",
        "sentence_A": "我们在模型训练中需要使用 SCADA 系统提供的实时数据，以确保模型的准确性和实时性。",
        "sentence_B": "我们在模型训练中需要使用SCADA系统提供的实时数据，以确保模型的准确性和实时性。",
        "id": 982,
        "target_term": "SCADA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何更好地处理不同场景的数据。",
        "sentence_A": "我们要针对不同的 SCENE 来调整模型的参数，确保在各种情况下都能有好的表现。",
        "sentence_B": "我们要针对不同的场景来调整模型的参数，确保在各种情况下都能有好的表现。",
        "id": 983,
        "target_term": "SCENE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中发现，使用 SD 方法可以有效减少梯度爆炸的问题。",
        "sentence_B": "我们在训练过程中发现，使用随机梯度下降（SD）方法可以有效减少梯度爆炸的问题。",
        "id": 984,
        "target_term": "SD",
        "is_hardcore": false
    },
    {
        "topic": "Session Description Protocol",
        "prefix": "在讨论实时通信系统的优化方案时",
        "sentence_A": "我们在最新的模型训练中引入了 SDP，这极大地提升了我们系统的实时性和稳定性。",
        "sentence_B": "我们在最新的模型训练中引入了会话描述协议（SDP），这极大地提升了我们系统的实时性和稳定性。",
        "id": 985,
        "target_term": "SDP",
        "is_hardcore": true
    },
    {
        "topic": "SEGAN in Model Training",
        "prefix": "在模型训练过程中，我们遇到了一些挑战。",
        "sentence_A": "在训练 SEGAN 的过程中，我们发现数据集的质量对模型性能影响很大。",
        "sentence_B": "在训练生成对抗网络（SEGAN）的过程中，我们发现数据集的质量对模型性能影响很大。",
        "id": 986,
        "target_term": "SEGAN",
        "is_hardcore": true
    },
    {
        "topic": "Search Engine Marketing",
        "prefix": "在一次模型训练的数据清洗阶段，团队讨论如何优化广告投放的策略。",
        "sentence_A": "我们在数据清洗阶段发现，SEM的数据质量对模型效果影响很大，需要进一步优化。",
        "sentence_B": "我们在数据清洗阶段发现，搜索引擎营销（SEM）的数据质量对模型效果影响很大，需要进一步优化。",
        "id": 987,
        "target_term": "SEM",
        "is_hardcore": true
    },
    {
        "topic": "Sequence Modeling",
        "prefix": "在讨论模型训练时，同事们提到了一个重要的数据结构",
        "sentence_A": "我们在训练这个模型时，需要特别注意处理好每个 SEQ 的输入和输出。",
        "sentence_B": "我们在训练这个模型时，需要特别注意处理好每个序列的输入和输出。",
        "id": 988,
        "target_term": "SEQ",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在训练模型时，发现使用 SF 可以显著提升模型的收敛速度。",
        "sentence_B": "我们在训练模型时，发现使用随机森林（SF）可以显著提升模型的收敛速度。",
        "id": 989,
        "target_term": "SF",
        "is_hardcore": false
    },
    {
        "topic": "SGD in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到使用SGD进行优化。",
        "sentence_A": "我们在训练这个模型时，用的是SGD，效果还不错。",
        "sentence_B": "我们在训练这个模型时，使用的是随机梯度下降（SGD），效果还不错。",
        "id": 990,
        "target_term": "SGD",
        "is_hardcore": true
    },
    {
        "topic": "Optimization Techniques in Deep Learning",
        "prefix": "在讨论模型训练优化策略时",
        "sentence_A": "我们在训练时使用了 SGDM，效果比普通的 SGD 好很多。",
        "sentence_B": "我们在训练时使用了带有动量的随机梯度下降（SGDM），效果比普通的随机梯度下降（SGD）好很多。",
        "id": 991,
        "target_term": "SGDM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training Optimization",
        "prefix": "在讨论如何优化模型训练的性能时",
        "sentence_A": "我们可以通过使用 SGE 来优化大规模模型的训练过程，这样可以显著提高训练效率。",
        "sentence_B": "我们可以通过使用并行计算框架（Scalable Grid Engine, SGE）来优化大规模模型的训练过程，这样可以显著提高训练效率。",
        "id": 992,
        "target_term": "SGE",
        "is_hardcore": true
    },
    {
        "topic": "Scene Graph Generation",
        "prefix": "在模型训练过程中，我们讨论了如何优化场景图生成算法的性能。",
        "sentence_A": "我们在讨论 SGG 的时候，发现数据预处理对模型性能有显著影响。",
        "sentence_B": "我们在讨论场景图生成（SGG）的时候，发现数据预处理对模型性能有显著影响。",
        "id": 993,
        "target_term": "SGG",
        "is_hardcore": true
    },
    {
        "topic": "Stochastic Gradient Langevin Dynamics (SGLD) in Model Training",
        "prefix": "在讨论模型训练的优化方法时",
        "sentence_A": "我们可以在模型训练中使用 SGLD 来提高模型的泛化能力。",
        "sentence_B": "我们可以在模型训练中使用随机梯度朗之万动力学（SGLD）来提高模型的泛化能力。",
        "id": 994,
        "target_term": "SGLD",
        "is_hardcore": true
    },
    {
        "topic": "Feature Extraction",
        "prefix": "在讨论图像处理算法时，团队成员提到SIFT算法的性能和应用。",
        "sentence_A": "我们最近在用 SIFT 做特征提取，效果挺好的，但计算复杂度还是有点高。",
        "sentence_B": "我们最近在使用尺度不变特征变换（SIFT）进行特征提取，效果很好，但计算复杂度仍然较高。",
        "id": 995,
        "target_term": "SIFT",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们在优化模型推理时，发现使用 SIM 卡片的方法可以显著提高性能。",
        "sentence_B": "我们在优化模型推理时，发现使用SIM卡的方法可以显著提高性能。",
        "id": 996,
        "target_term": "SIM",
        "is_hardcore": true
    },
    {
        "topic": "Signal-to-Interference Ratio",
        "prefix": "在讨论无线通信系统性能时",
        "sentence_A": "我们在训练模型时，发现 SIN 对于信号质量的影响很大，需要特别关注。",
        "sentence_B": "我们在训练模型时，发现信号干扰比（SIN）对于信号质量的影响很大，需要特别关注。",
        "id": 997,
        "target_term": "SIN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的预处理时",
        "sentence_A": "我们在数据预处理阶段使用了 SIP 技术，效果非常好。",
        "sentence_B": "我们在数据预处理阶段使用了会话初始化协议（SIP）技术，效果非常好。",
        "id": 998,
        "target_term": "SIP",
        "is_hardcore": true
    },
    {
        "topic": "Supervised Learning",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在做 SL 的时候，需要特别关注数据的质量和标注的准确性。",
        "sentence_B": "我们在进行监督学习时，需要特别关注数据的质量和标注的准确性。",
        "id": 999,
        "target_term": "SL",
        "is_hardcore": false
    },
    {
        "topic": "SLAM",
        "prefix": "在讨论如何优化机器人导航算法时",
        "sentence_A": "我们最近在研究如何通过改进 SLAM 算法来提高机器人的环境感知能力。",
        "sentence_B": "我们最近在研究如何通过改进同时定位与地图构建（SLAM）算法来提高机器人的环境感知能力。",
        "id": 1000,
        "target_term": "SLAM",
        "is_hardcore": true
    },
    {
        "topic": "Superpixel Segmentation",
        "prefix": "在讨论图像分割算法的选择时",
        "sentence_A": "我们这次用 SLIC 算法来做超像素分割，效果应该会不错。",
        "sentence_B": "我们这次使用 SLIC 算法来进行超像素分割，效果应该会不错。",
        "id": 1001,
        "target_term": "SLIC",
        "is_hardcore": true
    },
    {
        "topic": "Sequence-to-Sequence Models",
        "prefix": "在一次模型训练的会议上，团队讨论了如何优化当前的模型架构。",
        "sentence_A": "我们在讨论如何优化 SLM 的训练流程，以提高模型的泛化能力。",
        "sentence_B": "我们在讨论如何优化序列到序列模型的训练流程，以提高模型的泛化能力。",
        "id": 1002,
        "target_term": "SLM",
        "is_hardcore": true
    },
    {
        "topic": "Secure Multi-Party Computation",
        "prefix": "在讨论如何保护用户隐私数据时，团队提到了一种技术方案。",
        "sentence_A": "为了确保数据安全，我们可以用 SMC 技术来实现多方安全计算，这样就能在不泄露数据的情况下完成模型的训练。",
        "sentence_B": "为了确保数据安全，我们可以使用安全多方计算（SMC）技术来实现多方安全计算，这样就能在不泄露数据的情况下完成模型的训练。",
        "id": 1003,
        "target_term": "SMC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数优化时",
        "sentence_A": "我们可以通过调整 SMO 算法的参数来优化模型的训练效率。",
        "sentence_B": "我们可以通过调整序列最小优化算法的参数来优化模型的训练效率。",
        "id": 1004,
        "target_term": "SMO",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在最新的模型训练中使用了 SMP，效果非常不错。",
        "sentence_B": "我们在最新的模型训练中使用了单机多进程（SMP），效果非常不错。",
        "id": 1005,
        "target_term": "SMP",
        "is_hardcore": true
    },
    {
        "topic": "Statistical Machine Translation",
        "prefix": "在模型训练时，我们遇到了一些性能瓶颈。",
        "sentence_A": "在优化 SMT 模型时，我们发现数据预处理的效率对最终的翻译质量影响很大。",
        "sentence_B": "在优化统计机器翻译模型时，我们发现数据预处理的效率对最终的翻译质量影响很大。",
        "id": 1006,
        "target_term": "SMT",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论模型训练的最新进展时。",
        "sentence_A": "我们在最新的实验中尝试了 SMTNN，发现它在处理大规模数据集时表现得非常出色。",
        "sentence_B": "我们在最新的实验中尝试了同步多任务神经网络（SMTNN），发现它在处理大规模数据集时表现得非常出色。",
        "id": 1007,
        "target_term": "SMTNN",
        "is_hardcore": true
    },
    {
        "topic": "Signal-to-Noise Ratio (SNR) in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到信号噪声比对模型性能的影响。",
        "sentence_A": "我们在训练模型时，发现 SNR 对结果影响很大，特别是在噪声数据较多的情况下。",
        "sentence_B": "我们在训练模型时，发现信噪比对结果影响很大，特别是在噪声数据较多的情况下。",
        "id": 1008,
        "target_term": "SNR",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的硬件选择时，",
        "sentence_A": "我们需要确保服务器配置的 SOC 能够支持大规模的并行计算。",
        "sentence_B": "我们需要确保服务器配置的系统芯片（SOC）能够支持大规模的并行计算。",
        "id": 1009,
        "target_term": "SOC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时，团队成员提出了关于数据标注的问题。",
        "sentence_A": "我们在准备 SOD 的数据集时，发现标注的质量直接影响了模型的性能。",
        "sentence_B": "我们在准备结构化对象检测的数据集时，发现标注的质量直接影响了模型的性能。",
        "id": 1010,
        "target_term": "SOD",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在团队会议中，讨论最新的模型训练结果。",
        "sentence_A": "我们的新模型在最新的数据集上已经达到了 SOTA 的性能，下一步是优化推理速度。",
        "sentence_B": "我们的新模型在最新的数据集上已经达到了最先进的性能，下一步是优化推理速度。",
        "id": 1011,
        "target_term": "SOTA",
        "is_hardcore": true
    },
    {
        "topic": "Sparse Data Handling",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何处理稀疏数据的问题。",
        "sentence_A": "我们在处理这个数据集的时候，发现 SPARSE 数据的问题真的很头疼，需要找一个高效的解决方案。",
        "sentence_B": "我们在处理这个数据集的时候，发现稀疏数据的问题真的很头疼，需要找一个高效的解决方案。",
        "id": 1012,
        "target_term": "SPARSE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的性能指标时",
        "sentence_A": "我们在训练模型时，需要特别关注 SPEC，因为它直接影响到模型的性能。",
        "sentence_B": "我们在训练模型时，需要特别关注性能指标（SPEC），因为它直接影响到模型的性能。",
        "id": 1013,
        "target_term": "SPEC",
        "is_hardcore": true
    },
    {
        "topic": "Super Resolution",
        "prefix": "在讨论模型训练时",
        "sentence_A": "这次的 SR 模型训练效果很不错，我们可以在下次项目会议上详细讨论一下。",
        "sentence_B": "这次的超分辨率模型训练效果很不错，我们可以在下次项目会议上详细讨论一下。",
        "id": 1014,
        "target_term": "SR",
        "is_hardcore": false
    },
    {
        "topic": "Super-Resolution Convolutional Neural Network (SRCNN)",
        "prefix": "在一次模型训练的讨论中，团队成员正在探讨如何优化超分辨率模型的性能。",
        "sentence_A": "我们在用 SRCNN 做超分辨率的时候，发现模型的训练时间特别长，需要优化一下。",
        "sentence_B": "我们在使用超分辨率卷积神经网络（SRCNN）进行超分辨率处理时，发现模型的训练时间特别长，需要进行优化。",
        "id": 1015,
        "target_term": "SRCNN",
        "is_hardcore": true
    },
    {
        "topic": "Semantic Role Labeling",
        "prefix": "在模型训练过程中，我们遇到了一些标注数据的问题。",
        "sentence_A": "我们在处理训练数据时发现，SRL 的标注质量直接影响了模型的性能。",
        "sentence_B": "我们在处理训练数据时发现，语义角色标注的标注质量直接影响了模型的性能。",
        "id": 1016,
        "target_term": "SRL",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，发现使用 Self-Supervised (SS) 方法可以显著提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，发现使用自监督（Self-Supervised）方法可以显著提高模型的泛化能力。",
        "id": 1017,
        "target_term": "Self-Supervised",
        "is_hardcore": true
    },
    {
        "topic": "SSL in Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在最新的项目中使用了 SSL 技术，效果非常显著。",
        "sentence_B": "我们在最新的项目中使用了自监督学习（SSL）技术，效果非常显著。",
        "id": 1018,
        "target_term": "SSL",
        "is_hardcore": true
    },
    {
        "topic": "SSLM in Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们这次可以试试用 SSLM 来提升模型的泛化能力，看看效果如何。",
        "sentence_B": "我们这次可以试试用自监督语言模型（SSLM）来提升模型的泛化能力，看看效果如何。",
        "id": 1019,
        "target_term": "SSLM",
        "is_hardcore": true
    },
    {
        "topic": "Sequence-to-Sequence Models",
        "prefix": "在讨论模型选择时，团队成员提到使用 SSMs 来处理序列数据。",
        "sentence_A": "我们这次可以尝试用 SSM，看看能不能在序列任务上提升效果。",
        "sentence_B": "我们可以尝试使用序列到序列模型（SSMs），看看能否在序列任务上提升效果。",
        "id": 1020,
        "target_term": "SSM",
        "is_hardcore": true
    },
    {
        "topic": "Data Privacy and Security",
        "prefix": "在讨论用户数据保护时，团队提到需要确保在模型训练中正确处理SSN字段。",
        "sentence_A": "我们得确保在模型训练时正确处理这个用户的 SSN，不能泄露了。",
        "sentence_B": "我们需要确保在模型训练时正确处理用户的社保号，不能泄露。",
        "id": 1021,
        "target_term": "SSN",
        "is_hardcore": true
    },
    {
        "topic": "Spatial Transformer Network (STN)",
        "prefix": "在进行模型训练时，我们经常需要处理图像的几何变换问题。",
        "sentence_A": "这次我们在模型中引入了 STN，效果提升非常明显。",
        "sentence_B": "这次我们在模型中引入了空间变换网络（STN），效果提升非常明显。",
        "id": 1022,
        "target_term": "STN",
        "is_hardcore": true
    },
    {
        "topic": "Spatial Transformer Networks",
        "prefix": "在讨论模型训练的优化方案时，",
        "sentence_A": "我们在模型中引入了 STN，这大大提高了模型的鲁棒性和泛化能力。",
        "sentence_B": "我们在模型中引入了空间变换网络（STNs），这大大提高了模型的鲁棒性和泛化能力。",
        "id": 1023,
        "target_term": "STN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型性能。",
        "sentence_A": "我们这次的模型训练需要好好 STUDY 一下数据分布，看看能不能提高准确率。",
        "sentence_B": "我们这次的模型训练需要好好研究一下数据分布，看看能不能提高准确率。",
        "id": 1024,
        "target_term": "STUDY",
        "is_hardcore": true
    },
    {
        "topic": "Support Vector Machines in Model Training",
        "prefix": "在讨论模型训练的过程中，同事们提到了支持向量机的使用。",
        "sentence_A": "我们在训练模型时发现，使用 SV 可以显著提高分类效果。",
        "sentence_B": "我们在训练模型时发现，使用支持向量机可以显著提高分类效果。",
        "id": 1025,
        "target_term": "SV",
        "is_hardcore": false
    },
    {
        "topic": "SVD in Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在模型训练中使用了 SVD 来优化特征矩阵，效果显著。",
        "sentence_B": "我们在模型训练中使用了奇异值分解（SVD）来优化特征矩阵，效果显著。",
        "id": 1026,
        "target_term": "SVD",
        "is_hardcore": true
    },
    {
        "topic": "SVM in Model Training",
        "prefix": "在模型训练过程中讨论SVM的使用",
        "sentence_A": "我们在训练这个分类模型的时候，决定用 SVM，因为它的边界清晰，泛化能力也不错。",
        "sentence_B": "我们在训练这个分类模型的时候，决定使用支持向量机（SVM），因为它的边界清晰，泛化能力也不错。",
        "id": 1027,
        "target_term": "SVM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练的过程中，我们经常讨论如何优化模型的性能。",
        "sentence_A": "我们在训练模型时，用了一些 SWAG 技巧来提升模型的收敛速度。",
        "sentence_B": "我们在训练模型时，使用了一些随机权重平均（SWAG）技巧来提升模型的收敛速度。",
        "id": 1028,
        "target_term": "SWAG",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在设计模型时，应该充分利用 SYNERGISTIC 效应，让不同模块之间更好地协作。",
        "sentence_B": "我们在设计模型时，应该充分利用协同效应，让不同模块之间更好地协作。",
        "id": 1029,
        "target_term": "SYNERGISTIC",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在训练过程中发现，SYST 的参数调整对模型的性能提升非常明显。",
        "sentence_B": "我们在训练过程中发现，系统参数的调整对模型的性能提升非常明显。",
        "id": 1030,
        "target_term": "SYST",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，讨论模型的安全性问题",
        "sentence_A": "我们在训练模型时，必须确保模型的 Safety，避免出现任何潜在的有害输出。",
        "sentence_B": "我们在训练模型时，必须确保模型的安全性，避免出现任何潜在的有害输出。",
        "id": 1031,
        "target_term": "Safety",
        "is_hardcore": true
    },
    {
        "topic": "Data Sampling",
        "prefix": "在讨论模型训练的数据选择时",
        "sentence_A": "我们在训练模型时，使用了不同的 Sampling 方法来确保数据的多样性。",
        "sentence_B": "我们在训练模型时，使用了不同的采样方法来确保数据的多样性。",
        "id": 1032,
        "target_term": "Sampling",
        "is_hardcore": true
    },
    {
        "topic": "Scalar in Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在调整学习率的时候，需要注意学习率其实是一个 Scalar，它的值对模型的收敛速度有很大影响。",
        "sentence_B": "我们在调整学习率的时候，需要注意学习率其实是一个标量，它的值对模型的收敛速度有很大影响。",
        "id": 1033,
        "target_term": "Scalar",
        "is_hardcore": true
    },
    {
        "topic": "Model Scaling",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们需要考虑如何在不影响模型性能的前提下，提高模型的 Scale，以应对更大的数据集和更高的计算需求。",
        "sentence_B": "我们需要考虑如何在不影响模型性能的前提下，提高模型的规模，以应对更大的数据集和更高的计算需求。",
        "id": 1034,
        "target_term": "Scale",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何处理大规模数据集时",
        "sentence_A": "我们最近在讨论如何处理大规模数据集时，大家都提到了 Scaling 问题，毕竟这对模型的性能和资源管理非常重要。",
        "sentence_B": "我们最近在讨论如何处理大规模数据集时，大家都提到了扩展问题，毕竟这对模型的性能和资源管理非常重要。",
        "id": 1035,
        "target_term": "Scaling",
        "is_hardcore": true
    },
    {
        "topic": "Data Distribution in Model Training",
        "prefix": "在讨论模型训练的数据分布时",
        "sentence_A": "这次训练的数据分布有点奇怪，Scatter 图看起来不均匀，可能需要重新检查数据预处理的逻辑。",
        "sentence_B": "这次训练的数据分布有点奇怪，散点图看起来不均匀，可能需要重新检查数据预处理的逻辑。",
        "id": 1036,
        "target_term": "Scatter",
        "is_hardcore": true
    },
    {
        "topic": "Scheduling in Model Training",
        "prefix": "在讨论模型训练过程中资源分配的问题时",
        "sentence_A": "我们今天主要讨论一下模型训练中的 Scheduling 问题，特别是如何优化 GPU 的资源分配。",
        "sentence_B": "我们今天主要讨论一下模型训练中的调度问题，特别是如何优化 GPU 的资源分配。",
        "id": 1037,
        "target_term": "Scheduling",
        "is_hardcore": true
    },
    {
        "topic": "Data Schema in Model Training",
        "prefix": "在讨论模型训练的数据结构时",
        "sentence_A": "我们在设计数据的 Schema 时，需要确保每个字段的类型和格式都符合要求，这样才能保证模型训练的顺利进行。",
        "sentence_B": "我们在设计数据的模式时，需要确保每个字段的类型和格式都符合要求，这样才能保证模型训练的顺利进行。",
        "id": 1038,
        "target_term": "Schema",
        "is_hardcore": true
    },
    {
        "topic": "Phonetics in NLP",
        "prefix": "在处理中文语音识别时，我们遇到了一个语音学上的问题。",
        "sentence_A": "我们发现，在处理中文语音识别时，Schwa 的出现频率非常高，这对我们的模型训练提出了新的挑战。",
        "sentence_B": "我们发现，在处理中文语音识别时，中性元音的出现频率非常高，这对我们的模型训练提出了新的挑战。",
        "id": 1039,
        "target_term": "Schwa",
        "is_hardcore": true
    },
    {
        "topic": "Scoping in AI Project Management",
        "prefix": "在讨论新项目的需求和计划时，团队成员提到需要明确项目范围。",
        "sentence_A": "在开始模型训练之前，我们需要好好做一下 Scoping，确保每个人都清楚项目的目标和范围。",
        "sentence_B": "在开始模型训练之前，我们需要好好做一下项目范围界定，确保每个人都清楚项目的目标和范围。",
        "id": 1040,
        "target_term": "Scoping",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练阶段，团队正在进行模型评估。",
        "sentence_A": "我们在训练阶段需要对模型的性能进行 Scoring，以确保它在测试集上的表现符合预期。",
        "sentence_B": "我们在训练阶段需要对模型的性能进行评分，以确保它在测试集上的表现符合预期。",
        "id": 1041,
        "target_term": "Scoring",
        "is_hardcore": true
    },
    {
        "topic": "Search Algorithm Optimization",
        "prefix": "在模型训练过程中，我们在讨论如何优化搜索算法的效率。",
        "sentence_A": "我们在训练模型时，发现 Search 算法的效率还有提升空间，需要进一步优化。",
        "sentence_B": "我们在训练模型时，发现搜索算法的效率还有提升空间，需要进一步优化。",
        "id": 1042,
        "target_term": "Search",
        "is_hardcore": false
    },
    {
        "topic": "Search Algorithms",
        "prefix": "在讨论如何优化搜索引擎的效率时",
        "sentence_A": "我们最近在优化 Searche 的速度，发现通过调整索引结构可以显著提升查询效率。",
        "sentence_B": "我们最近在优化搜索的速度，发现通过调整索引结构可以显著提升查询效率。",
        "id": 1043,
        "target_term": "Searche",
        "is_hardcore": true
    },
    {
        "topic": "Time Series Analysis",
        "prefix": "在讨论时间序列模型的季节性特征时",
        "sentence_A": "我们在模型训练中发现，数据的 Seasonal 特征对预测结果影响很大。",
        "sentence_B": "我们在模型训练中发现，数据的季节性特征对预测结果影响很大。",
        "id": 1044,
        "target_term": "Seasonal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数时",
        "sentence_A": "我们把学习率每 100 个 epochs 降低一个数量级，Second，我们会在验证集上定期检查模型的性能。",
        "sentence_B": "我们把学习率每 100 个 epochs 降低一个数量级，其次，我们会在验证集上定期检查模型的性能。",
        "id": 1045,
        "target_term": "100",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据的安全性和隐私保护。",
        "sentence_A": "在训练模型时，我们需要注意数据的 Secret，确保敏感信息不会泄露。",
        "sentence_B": "在训练模型时，我们需要注意数据的机密性，确保敏感信息不会泄露。",
        "id": 1046,
        "target_term": "Secret",
        "is_hardcore": true
    },
    {
        "topic": "Data Security",
        "prefix": "在讨论模型训练数据的保护措施时",
        "sentence_A": "我们在处理训练数据时，必须确保 Security，防止数据泄露。",
        "sentence_B": "我们在处理训练数据时，必须确保数据安全，防止数据泄露。",
        "id": 1047,
        "target_term": "Security",
        "is_hardcore": true
    },
    {
        "topic": "Data Query and Selection",
        "prefix": "在讨论数据处理和模型训练的过程中",
        "sentence_A": "我们可以通过 SQL 的 Select 语句来选择特定的特征列，这样可以提高模型训练的效率。",
        "sentence_B": "我们可以通过 SQL 的选择语句来选择特定的特征列，这样可以提高模型训练的效率。",
        "id": 1048,
        "target_term": "SQL",
        "is_hardcore": true
    },
    {
        "topic": "Feature Selection in Model Training",
        "prefix": "在讨论如何优化模型训练时",
        "sentence_A": "我们在模型训练中需要考虑如何进行 feature Selection，这直接影响到模型的性能。",
        "sentence_B": "我们在模型训练中需要考虑如何进行特征选择，这直接影响到模型的性能。",
        "id": 1049,
        "target_term": "feature Selection",
        "is_hardcore": true
    },
    {
        "topic": "Self-Attention Mechanism",
        "prefix": "在讨论模型优化时，同事提到了一个关键的机制",
        "sentence_A": "我们在模型的 Self 注意力机制上做了一些改进，效果显著。",
        "sentence_B": "我们在模型的自注意力机制上做了一些改进，效果显著。",
        "id": 1050,
        "target_term": "Self",
        "is_hardcore": true
    },
    {
        "topic": "Semantics in NLP",
        "prefix": "在模型训练过程中，我们经常需要处理文本的语义问题。",
        "sentence_A": "在训练这个模型时，我们特别注意了 Semantic 的处理，确保模型能够准确理解句子的深层含义。",
        "sentence_B": "在训练这个模型时，我们特别注意了语义的处理，确保模型能够准确理解句子的深层含义。",
        "id": 1051,
        "target_term": "Semantic",
        "is_hardcore": true
    },
    {
        "topic": "Sensors Integration in IoT Systems",
        "prefix": "在讨论物联网系统的传感器集成时",
        "sentence_A": "我们在模型训练中需要确保 Sensor 的数据采集是高精度的，这样才能提高模型的准确性。",
        "sentence_B": "我们在模型训练中需要确保传感器的数据采集是高精度的，这样才能提高模型的准确性。",
        "id": 1052,
        "target_term": "Sensor",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型优化策略时",
        "sentence_A": "我们在训练这个模型时，发现使用 Separable 卷积可以显著减少计算量，提高推理速度。",
        "sentence_B": "我们在训练这个模型时，发现使用可分离卷积可以显著减少计算量，提高推理速度。",
        "id": 1053,
        "target_term": "Separable",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行数据清洗时，我们讨论了如何处理不同数据集之间的分离问题。",
        "sentence_A": "在数据清洗阶段，我们需要确保不同数据集之间的 Separation，以避免数据泄露。",
        "sentence_B": "在数据清洗阶段，我们需要确保不同数据集之间的分离，以避免数据泄露。",
        "id": 1054,
        "target_term": "Separation",
        "is_hardcore": true
    },
    {
        "topic": "Server Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们需要确保新的模型在 Server 上的性能是稳定的。",
        "sentence_B": "我们需要确保新的模型在服务器上的性能是稳定的。",
        "id": 1055,
        "target_term": "Server",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时，团队成员提到服务器的配置问题。",
        "sentence_A": "我们在部署模型时，需要确保 Server 的性能足够支持高并发请求。",
        "sentence_B": "我们在部署模型时，需要确保服务器的性能足够支持高并发请求。",
        "id": 1056,
        "target_term": "Server",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了数据的形状问题。",
        "sentence_A": "我们需要确保输入数据的 Shape 是一致的，这样才能避免训练过程中的错误。",
        "sentence_B": "我们需要确保输入数据的形状是一致的，这样才能避免训练过程中的错误。",
        "id": 1057,
        "target_term": "Shape",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据预处理的重要性。",
        "sentence_A": "我们得确保输入数据的 Shape 正确，这样才能避免模型训练时出问题。",
        "sentence_B": "我们必须确保输入数据的形状正确，这样才能避免模型训练时出现问题。",
        "id": 1058,
        "target_term": "Shape",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在训练模型时，需要考虑数据的 Sharing 机制，确保数据的安全性和隐私性。",
        "sentence_B": "我们在训练模型时，需要考虑数据的共享机制，确保数据的安全性和隐私性。",
        "id": 1059,
        "target_term": "Sharing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何处理数据分布的变化问题。",
        "sentence_A": "我们这次训练的数据集和上次的分布有些不同，需要考虑如何处理这个 data Shift 问题。",
        "sentence_B": "我们这次训练的数据集和上次的分布有些不同，需要考虑如何处理这个数据偏移问题。",
        "id": 1060,
        "target_term": "data Shift",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们在训练这个模型时，发现如果输入的序列太短，会影响模型的性能，所以我们需要在数据预处理阶段处理这些 short 序列。",
        "sentence_B": "我们在训练这个模型时，发现如果输入的序列太短，会影响模型的性能，所以我们需要在数据预处理阶段处理这些短序列。",
        "id": 1061,
        "target_term": "short",
        "is_hardcore": true
    },
    {
        "topic": "SiamRPN in Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化跟踪算法的性能。",
        "sentence_A": "我们今天主要讨论了如何在训练过程中优化 SiamRPN 的性能，毕竟这个模型在目标跟踪任务上表现得非常出色。",
        "sentence_B": "我们今天主要讨论了如何在训练过程中优化 Siamese Region Proposal Network (SiamRPN) 的性能，毕竟这个模型在目标跟踪任务上表现得非常出色。",
        "id": 1062,
        "target_term": "SiamRPN",
        "is_hardcore": true
    },
    {
        "topic": "Similarity Calculation in Model Training",
        "prefix": "在讨论模型训练过程中如何计算两个向量的相似度时，团队成员提出了不同的方法。",
        "sentence_A": "我们在计算两个向量的 Similarity 时，可以尝试使用余弦相似度，这样能更好地反映它们之间的关系。",
        "sentence_B": "我们在计算两个向量的相似度时，可以尝试使用余弦相似度，这样能更好地反映它们之间的关系。",
        "id": 1063,
        "target_term": "Similarity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时",
        "sentence_A": "我们这次用 Simulated 数据进行预训练，效果应该会更好。",
        "sentence_B": "我们这次用模拟数据进行预训练，效果应该会更好。",
        "id": 1064,
        "target_term": "Simulated",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的准确性和效率时",
        "sentence_A": "我们在做模型训练的时候，经常需要用 Simulation 来验证模型在不同环境下的表现。",
        "sentence_B": "我们在进行模型训练时，经常需要通过仿真来验证模型在不同环境下的表现。",
        "id": 1065,
        "target_term": "Simulation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在设置模型训练的参数时，通常会使用 Single 的方式来初始化权重。",
        "sentence_B": "我们在设置模型训练的参数时，通常会使用单个的方式来初始化权重。",
        "id": 1066,
        "target_term": "Single",
        "is_hardcore": true
    },
    {
        "topic": "AI Model Training",
        "prefix": "在讨论模型训练的瓶颈时",
        "sentence_A": "我们在模型训练中遇到了一些瓶颈，特别是在处理 Singularity 问题时，需要更多的数据来优化模型。",
        "sentence_B": "我们在模型训练中遇到了一些瓶颈，特别是在处理奇点问题时，需要更多的数据来优化模型。",
        "id": 1067,
        "target_term": "Singularity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练数据集时",
        "sentence_A": "我们需要确保每个 Site 的数据都是干净的，这样才能提高模型的准确性。",
        "sentence_B": "我们需要确保每个站点的数据都是干净的，这样才能提高模型的准确性。",
        "id": 1068,
        "target_term": "Site",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中遇到的问题时",
        "sentence_A": "在训练过程中，我们遇到了一个特殊的 Situation，模型的收敛速度明显变慢了。",
        "sentence_B": "在训练过程中，我们遇到了一个特殊的情况，模型的收敛速度明显变慢了。",
        "id": 1069,
        "target_term": "Situation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在处理人体姿态估计的数据集时，发现很多样本的 Skeleton 不完整，需要进一步清洗。",
        "sentence_B": "我们在处理人体姿态估计的数据集时，发现很多样本的骨架不完整，需要进一步清洗。",
        "id": 1070,
        "target_term": "Skeleton",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何提升模型效果的会议上，一位资深AI算法工程师提到：",
        "sentence_A": "我们在训练模型时，不仅要关注数据的质量，还要提升我们的 data preprocessing skill。",
        "sentence_B": "我们在训练模型时，不仅要关注数据的质量，还要提升我们的数据预处理技能。",
        "id": 1071,
        "target_term": "data preprocessing skill",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员正在交流各自的技术专长。",
        "sentence_A": "我们这次模型训练需要大家的 various skill，特别是对深度学习框架的熟悉程度。",
        "sentence_B": "我们这次模型训练需要大家的多种技能，特别是对深度学习框架的熟悉程度。",
        "id": 1072,
        "target_term": "various skill",
        "is_hardcore": true
    },
    {
        "topic": "Data Slicing in Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理不同子集的数据来优化模型性能。",
        "sentence_A": "在训练过程中，我们通常会对数据进行 Slicing，以便更好地分析和优化模型的性能。",
        "sentence_B": "在训练过程中，我们通常会对数据进行切片，以便更好地分析和优化模型的性能。",
        "id": 1073,
        "target_term": "Slicing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数配置时",
        "sentence_A": "我们在训练这个模型时，需要为每个输入定义好 Slot，这些 Slot 会直接影响模型的性能。",
        "sentence_B": "我们在训练这个模型时，需要为每个输入定义好槽位，这些槽位会直接影响模型的性能。",
        "id": 1074,
        "target_term": "Slot",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的过程中",
        "sentence_A": "我们在数据集中加入了更多的 Smartphone 相关的用户行为数据，以提高模型的泛化能力。",
        "sentence_B": "我们在数据集中加入了更多的智能手机相关的用户行为数据，以提高模型的泛化能力。",
        "id": 1075,
        "target_term": "Smartphone",
        "is_hardcore": true
    },
    {
        "topic": "Network Communication",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们通常使用 Socket 进行网络通信，确保模型能够高效地与服务器交互。",
        "sentence_B": "我们通常使用套接字进行网络通信，确保模型能够高效地与服务器交互。",
        "id": 1076,
        "target_term": "Socket",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数设置时，",
        "sentence_A": "我们在设置学习率衰减策略时，可以采用 Soft 重启的方法，这样可以避免学习率过快下降。",
        "sentence_B": "我们在设置学习率衰减策略时，可以采用软重启的方法，这样可以避免学习率过快下降。",
        "id": 1077,
        "target_term": "Soft",
        "is_hardcore": true
    },
    {
        "topic": "Softmax Function in Neural Networks",
        "prefix": "在讨论模型训练的最后一步时",
        "sentence_A": "我们在最后一层用 Softmax 函数来确保输出的概率分布是合理的。",
        "sentence_B": "我们在最后一层使用 Softmax 函数来确保输出的概率分布是合理的。",
        "id": 1078,
        "target_term": "Softmax",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的可行性时",
        "sentence_A": "我们在讨论模型的 Solvability 时，需要考虑数据集的完整性和特征工程的有效性。",
        "sentence_B": "我们在讨论模型的可解性时，需要考虑数据集的完整性和特征工程的有效性。",
        "id": 1079,
        "target_term": "Solvability",
        "is_hardcore": true
    },
    {
        "topic": "Optimization Techniques in Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到了一个关键组件。",
        "sentence_A": "我们可以通过调整 Solver 的参数来优化模型的训练速度和效果。",
        "sentence_B": "我们可以通过调整求解器的参数来优化模型的训练速度和效果。",
        "id": 1080,
        "target_term": "Solver",
        "is_hardcore": true
    },
    {
        "topic": "Optimization in Model Training",
        "prefix": "在模型训练过程中，我们经常需要选择合适的优化器来提高训练效率和模型性能。",
        "sentence_A": "在选择 Solver 的时候，我们通常会考虑 Adam、SGD 和 RMSprop，因为它们在不同的任务中表现各异。",
        "sentence_B": "在选择优化器的时候，我们通常会考虑 Adam、SGD 和 RMSprop，因为它们在不同的任务中表现各异。",
        "id": 1081,
        "target_term": "Solver",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们需要优化这个模型在不同 Space 下的表现，确保在各种场景下都能有良好的性能。",
        "sentence_B": "我们需要优化这个模型在不同空间下的表现，确保在各种场景下都能有良好的性能。",
        "id": 1082,
        "target_term": "Space",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了数据的组织和存储方式。",
        "sentence_A": "我们在训练模型时，发现使用不同的 Space 可以显著提高数据处理的效率。",
        "sentence_B": "我们在训练模型时，发现使用不同的空间可以显著提高数据处理的效率。",
        "id": 1083,
        "target_term": "Space",
        "is_hardcore": true
    },
    {
        "topic": "Spam Detection",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何提高垃圾信息检测的准确性。",
        "sentence_A": "我们在训练模型时，需要特别注意处理大量的 Spam 数据，这样才能提高模型的准确率。",
        "sentence_B": "我们在训练模型时，需要特别注意处理大量的垃圾信息数据，这样才能提高模型的准确率。",
        "id": 1084,
        "target_term": "Spam",
        "is_hardcore": true
    },
    {
        "topic": "Spatial Data Processing",
        "prefix": "在讨论模型训练时，团队成员提出了一个关于数据处理的问题。",
        "sentence_A": "我们在处理 Spatial 数据时，需要特别注意坐标系的转换，不然模型的精度会大打折扣。",
        "sentence_B": "我们在处理空间数据时，需要特别注意坐标系的转换，不然模型的精度会大打折扣。",
        "id": 1085,
        "target_term": "Spatial",
        "is_hardcore": true
    },
    {
        "topic": "Speaker Recognition",
        "prefix": "在一次模型训练的讨论中",
        "sentence_A": "我们这次训练的模型主要是用来识别不同的 Speaker，效果还不错。",
        "sentence_B": "我们这次训练的模型主要是用来识别不同的说话人，效果还不错。",
        "id": 1086,
        "target_term": "Speaker",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队在讨论如何处理特定的数据集。",
        "sentence_A": "我们在处理这个数据集的时候，需要特别注意这些 Special 的样本，它们可能会影响模型的性能。",
        "sentence_B": "我们在处理这个数据集的时候，需要特别注意这些特殊样本，它们可能会影响模型的性能。",
        "id": 1087,
        "target_term": "Special",
        "is_hardcore": true
    },
    {
        "topic": "Spectral Clustering",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练聚类模型时，发现 Spectral 方法在处理高维数据时效果特别好。",
        "sentence_B": "我们在训练聚类模型时，发现谱方法在处理高维数据时效果特别好。",
        "id": 1088,
        "target_term": "Spectral",
        "is_hardcore": true
    },
    {
        "topic": "Spectrometer in AI Model Training",
        "prefix": "在讨论如何优化模型以处理光谱数据时，团队成员提到",
        "sentence_A": "我们这次用的 Spectrometer 数据质量很高，模型训练效果应该会很好。",
        "sentence_B": "我们这次使用的光谱仪数据质量很高，模型训练效果应该会很好。",
        "id": 1089,
        "target_term": "Spectrometer",
        "is_hardcore": true
    },
    {
        "topic": "Speech Recognition",
        "prefix": "在模型训练过程中，我们遇到了一些问题。",
        "sentence_A": "我们在处理 Speech 数据时发现模型的准确率突然下降了。",
        "sentence_B": "我们在处理语音数据时发现模型的准确率突然下降了。",
        "id": 1090,
        "target_term": "Speech",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化的过程中，团队成员提到一个关键指标。",
        "sentence_A": "这次模型的 inference speed 提升了20%，真是个不错的进展。",
        "sentence_B": "这次模型的推理速度提高了20%，真是个不错的进展。",
        "id": 1091,
        "target_term": "inference speed",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化数据的几何表示",
        "sentence_A": "我们在训练模型时，发现使用 Sphere 作为数据的几何表示可以显著提升模型的泛化能力。",
        "sentence_B": "我们在训练模型时，发现使用球体作为数据的几何表示可以显著提升模型的泛化能力。",
        "id": 1092,
        "target_term": "Sphere",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化时，团队成员提到一个关键的技术点。",
        "sentence_A": "我们在训练模型时，要注意 Spi 的设置，这会直接影响模型的性能。",
        "sentence_B": "我们在训练模型时，要注意服务提供者接口（SPI）的设置，这会直接影响模型的性能。",
        "id": 1093,
        "target_term": "Spi",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要对数据进行预处理。",
        "sentence_A": "我们在数据预处理阶段使用了 Splice 技术，将多个数据片段高效地拼接在一起。",
        "sentence_B": "我们在数据预处理阶段使用了拼接技术，将多个数据片段高效地拼接在一起。",
        "id": 1094,
        "target_term": "Splice",
        "is_hardcore": true
    },
    {
        "topic": "Data Splitting",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在准备训练数据时，通常会用到 train-test split，确保模型的泛化能力。",
        "sentence_B": "我们在准备训练数据时，通常会使用训练-测试分割，确保模型的泛化能力。",
        "id": 1095,
        "target_term": "train-test split",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在讨论数据预处理的策略时，同事提到了数据分割的重要性。",
        "sentence_A": "在进行模型训练时，正确的 Splitting 数据集是非常关键的，这能确保模型的泛化能力。",
        "sentence_B": "在进行模型训练时，正确地分割数据集是非常关键的，这能确保模型的泛化能力。",
        "id": 1096,
        "target_term": "Splitting",
        "is_hardcore": true
    },
    {
        "topic": "Feature Selection",
        "prefix": "在模型训练过程中，我们发现了一些奇怪的特征。",
        "sentence_A": "在特征选择阶段，我们发现了一些 spuriou 的特征，这些特征虽然在训练集上表现很好，但在测试集上却完全失效了。",
        "sentence_B": "在特征选择阶段，我们发现了一些虚假的特征，这些特征虽然在训练集上表现很好，但在测试集上却完全失效了。",
        "id": 1097,
        "target_term": "spuriou",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化问答模型的训练数据时",
        "sentence_A": "我们最近在用 Squad 数据集来训练模型，效果还不错。",
        "sentence_B": "我们最近在使用 Squad 数据集来训练模型，效果还不错。",
        "id": 1098,
        "target_term": "Squad",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现模型的性能在不同批次的数据上波动较大。",
        "sentence_A": "我们需要提高模型的 Stability，确保在不同数据批次上的表现更加一致。",
        "sentence_B": "我们需要提高模型的稳定性，确保在不同数据批次上的表现更加一致。",
        "id": 1099,
        "target_term": "Stability",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论模型的稳定性和性能问题。",
        "sentence_A": "我们在训练这个模型的时候，需要确保它的性能是 Stable 的，这样才能保证在实际应用中不出问题。",
        "sentence_B": "我们在训练这个模型的时候，需要确保它的性能是稳定的，这样才能保证在实际应用中不出问题。",
        "id": 1100,
        "target_term": "Stable",
        "is_hardcore": true
    },
    {
        "topic": "Data Structure in AI Development",
        "prefix": "在讨论模型部署时，团队成员提到使用特定的数据结构来优化性能。",
        "sentence_A": "我们可以在部署时使用一个 Stack 来管理模型的推理过程，这样可以提高效率。",
        "sentence_B": "我们可以在部署时使用一个栈来管理模型的推理过程，这样可以提高效率。",
        "id": 1101,
        "target_term": "Stack",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型架构时，团队成员提到了Stacked的概念",
        "sentence_A": "我们这次的模型设计采用了 Stacked 的结构，这样可以更好地捕捉数据的深层次特征。",
        "sentence_B": "我们这次的模型设计采用了堆叠的结构，这样可以更好地捕捉数据的深层次特征。",
        "id": 1102,
        "target_term": "Stacked",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的标准流程时",
        "sentence_A": "我们通常会按照 Standard 流程来训练模型，确保每一步都符合行业最佳实践。",
        "sentence_B": "我们通常会按照标准流程来训练模型，确保每一步都符合行业最佳实践。",
        "id": 1103,
        "target_term": "Standard",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中参数的处理方式时",
        "sentence_A": "在训练模型时，我们通常会把一些参数设为 static，这样可以减少计算量，提高训练效率。",
        "sentence_B": "在训练模型时，我们通常会把一些参数设为静态，这样可以减少计算量，提高训练效率。",
        "id": 1104,
        "target_term": "static",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的细节时",
        "sentence_A": "我们这次的模型训练需要在每个 Station 上都进行数据校准，确保数据的一致性和准确性。",
        "sentence_B": "我们这次的模型训练需要在每个站点上都进行数据校准，确保数据的一致性和准确性。",
        "id": 1105,
        "target_term": "Station",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论时间序列模型的稳定性时",
        "sentence_A": "我们需要注意数据的 Stationary 性，这直接影响模型的预测效果。",
        "sentence_B": "我们需要注意数据的平稳性，这直接影响模型的预测效果。",
        "id": 1106,
        "target_term": "Stationary",
        "is_hardcore": true
    },
    {
        "topic": "Statistical Methods in Model Evaluation",
        "prefix": "在模型评估时，我们经常讨论统计方法的有效性。",
        "sentence_A": "在评估模型时，我们通常会用到 Statistical 方法来分析模型的性能。",
        "sentence_B": "在评估模型时，我们通常会用到统计方法来分析模型的性能。",
        "id": 1107,
        "target_term": "Statistical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中如何调整超参数时",
        "sentence_A": "我们在训练这个模型时，需要特别注意 Steer 这个超参数，它对模型的收敛速度影响很大。",
        "sentence_B": "我们在训练这个模型时，需要特别注意转向（Steering）这个超参数，它对模型的收敛速度影响很大。",
        "id": 1108,
        "target_term": "Steer",
        "is_hardcore": true
    },
    {
        "topic": "Stereo Vision",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在考虑使用包含 Stereo 图像的数据集来训练模型，以提高深度感知的准确性。",
        "sentence_B": "我们在考虑使用包含立体图像的数据集来训练模型，以提高深度感知的准确性。",
        "id": 1109,
        "target_term": "Stereo",
        "is_hardcore": true
    },
    {
        "topic": "Stochastic Gradient Descent",
        "prefix": "在讨论模型训练时，我们经常提到随机梯度下降算法。",
        "sentence_A": "我们在训练模型时，通常会用到 Stochastic Gradient Descent，这样可以有效减少计算开销，提高训练效率。",
        "sentence_B": "我们在训练模型时，通常会用到随机梯度下降算法，这样可以有效减少计算开销，提高训练效率。",
        "id": 1110,
        "target_term": "Stochastic Gradient Descent",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何提高模型训练效率时，团队成员提到几种策略。",
        "sentence_A": "我们在训练模型时，采用了几种不同的 Strategie，比如分批训练和数据增强，效果很不错。",
        "sentence_B": "我们在训练模型时，采用了不同的策略，比如分批训练和数据增强，效果很不错。",
        "id": 1111,
        "target_term": "Strategie",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在训练过程中需要考虑不同的 Strategy，以提高模型的泛化能力和训练效率。",
        "sentence_B": "我们在训练过程中需要考虑不同的策略，以提高模型的泛化能力和训练效率。",
        "id": 1112,
        "target_term": "Strategy",
        "is_hardcore": true
    },
    {
        "topic": "Streaming Data Processing",
        "prefix": "在讨论模型训练的数据管道优化时，团队正在考虑如何处理实时数据流。",
        "sentence_A": "我们在考虑用 Streaming 数据处理来优化模型训练的速度和效率。",
        "sentence_B": "我们在考虑用流式数据处理来优化模型训练的速度和效率。",
        "id": 1113,
        "target_term": "Streaming",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到模型的强度。",
        "sentence_A": "我们在训练模型时，需要特别关注模型的 Strength，这直接影响到最终的性能。",
        "sentence_B": "我们在训练模型时，需要特别关注模型的强度，这直接影响到最终的性能。",
        "id": 1114,
        "target_term": "Strength",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到一些性能问题。",
        "sentence_A": "我们在训练过程中遇到了一些性能问题，特别是在高负载情况下，模型的性能明显下降，这可能是由于模型对 Stres 的处理不当。",
        "sentence_B": "我们在训练过程中遇到了一些性能问题，特别是在高负载情况下，模型的性能明显下降，这可能是由于模型对压力的处理不当。",
        "id": 1115,
        "target_term": "Stres",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在进行数据清洗时，我们发现了一个常见问题。",
        "sentence_A": "在做数据清洗的时候，我们发现很多地方需要处理 String 类型的数据，特别是在文本处理模块。",
        "sentence_B": "在进行数据清洗时，我们发现很多地方需要处理字符串类型的数据，特别是在文本处理模块。",
        "id": 1116,
        "target_term": "String",
        "is_hardcore": true
    },
    {
        "topic": "String Processing in Data Cleaning",
        "prefix": "在数据清洗阶段，我们经常需要处理各种字符串问题。",
        "sentence_A": "在数据清洗阶段，我们经常需要处理各种 String 问题，比如去除空格、转换大小写、替换特殊字符等。",
        "sentence_B": "在数据清洗阶段，我们经常需要处理各种字符串问题，比如去除空格、转换大小写、替换特殊字符等。",
        "id": 1117,
        "target_term": "String",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的策略时",
        "sentence_A": "我们这次可以尝试用 Student 模型来加速训练过程，看看效果如何。",
        "sentence_B": "我们这次可以尝试用学生模型来加速训练过程，看看效果如何。",
        "id": 1118,
        "target_term": "Student",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过调整每个 batch 的 sub 来优化模型的收敛速度。",
        "sentence_B": "我们可以通过调整每个 batch 的子集来优化模型的收敛速度。",
        "id": 1119,
        "target_term": "batch",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在准备训练数据时，需要确保每个 Subject 的标签都是准确的。",
        "sentence_B": "我们在准备训练数据时，需要确保每个主题的标签都是准确的。",
        "id": 1120,
        "target_term": "Subject",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们讨论了如何处理高维数据中的低维子流形问题。",
        "sentence_A": "在数据清洗时，我们发现高维数据中的 submanifold 问题对模型训练影响很大。",
        "sentence_B": "在数据清洗时，我们发现高维数据中的子流形问题对模型训练影响很大。",
        "id": 1121,
        "target_term": "submanifold",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在讨论模型的评估和提交时",
        "sentence_A": "我们在准备模型的 Submission 时，需要确保所有的测试数据都已正确标注。",
        "sentence_B": "我们在准备模型的提交时，需要确保所有的测试数据都已正确标注。",
        "id": 1122,
        "target_term": "Submission",
        "is_hardcore": true
    },
    {
        "topic": "Subsequence in Algorithm Optimization",
        "prefix": "在优化算法模型时，我们经常需要处理子序列问题。",
        "sentence_A": "在优化模型的时候，我们发现处理 Subsequence 的方法对提高推理速度特别有效。",
        "sentence_B": "在优化模型时，我们发现处理子序列的方法对提高推理速度特别有效。",
        "id": 1123,
        "target_term": "Subsequence",
        "is_hardcore": true
    },
    {
        "topic": "Subsequences in Sequence Processing",
        "prefix": "在讨论模型训练数据预处理时",
        "sentence_A": "我们在处理序列数据时，经常会用到 Subsequence，这样可以更好地捕捉时间上的依赖关系。",
        "sentence_B": "我们在处理序列数据时，经常会用到子序列，这样可以更好地捕捉时间上的依赖关系。",
        "id": 1124,
        "target_term": "Subsequence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型性能提升时",
        "sentence_A": "这次的模型优化带来了 Substantial 的性能提升，尤其是在推理速度上。",
        "sentence_B": "这次的模型优化带来了显著的性能提升，尤其是在推理速度上。",
        "id": 1125,
        "target_term": "Substantial",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练平台的架构时，团队成员提到了一个关键技术层",
        "sentence_A": "我们在设计模型训练平台时，考虑使用 Substrate 作为底层架构，这样可以更好地支持多模型训练和资源管理。",
        "sentence_B": "我们在设计模型训练平台时，考虑使用基板作为底层架构，这样可以更好地支持多模型训练和资源管理。",
        "id": 1126,
        "target_term": "Substrate",
        "is_hardcore": true
    },
    {
        "topic": "Data Sufficiency for Model Training",
        "prefix": "在讨论模型训练数据集时",
        "sentence_A": "这个数据集的量已经 Sufficient 了，我们可以开始训练模型了。",
        "sentence_B": "这个数据集的量已经足够了，我们可以开始训练模型了。",
        "id": 1127,
        "target_term": "Sufficient",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化模型的性能。",
        "sentence_A": "在今天的会议上，我们讨论了如何提高模型的准确率，提出了几个 Suggestion。",
        "sentence_B": "在今天的会议上，我们讨论了如何提高模型的准确率，提出了几条建议。",
        "id": 1128,
        "target_term": "Suggestion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的选择时，团队成员对数据集的适用性进行了评估。",
        "sentence_A": "我们在评估这个数据集的 Suitability 时，发现它在某些场景下表现不佳。",
        "sentence_B": "我们在评估这个数据集的适用性时，发现它在某些场景下表现不佳。",
        "id": 1129,
        "target_term": "Suitability",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在训练模型时，需要计算每个批次的 sum 来评估损失函数。",
        "sentence_B": "我们在训练模型时，需要计算每个批次的和来评估损失函数。",
        "id": 1130,
        "target_term": "sum",
        "is_hardcore": false
    },
    {
        "topic": "Text Summarization",
        "prefix": "在今天的模型训练中，我们遇到了一个问题。",
        "sentence_A": "我们在做 Summarization 模型的训练时，发现数据集的质量对结果影响很大。",
        "sentence_B": "我们在进行文本摘要模型的训练时，发现数据集的质量对结果影响很大。",
        "id": 1131,
        "target_term": "Summarization",
        "is_hardcore": true
    },
    {
        "topic": "Text Summarization",
        "prefix": "在模型训练过程中，我们讨论了如何提高文本摘要的准确性。",
        "sentence_A": "在训练过程中，我们发现 Summarizing 的效果还有很大的提升空间。",
        "sentence_B": "在训练过程中，我们发现文本摘要的效果还有很大的提升空间。",
        "id": 1132,
        "target_term": "Summarizing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数优化时",
        "sentence_A": "我们这次的超参数优化效果特别好，尤其是用了 Super 参数调整方法。",
        "sentence_B": "我们这次的超参数优化效果特别好，尤其是使用了超级参数调整方法。",
        "id": 1133,
        "target_term": "Super",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的配置时",
        "sentence_A": "这个模型的训练配置需要我们确保有足够的 GPU 支持，不然训练速度会大大降低。",
        "sentence_B": "这个模型的训练配置需要我们确保有足够的 GPU 支持，否则训练速度会大大降低。",
        "id": 1134,
        "target_term": "GPU",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何处理数据集中的表面特征。",
        "sentence_A": "在训练模型时，我们发现处理数据集中的 Surface 特征非常重要。",
        "sentence_B": "在训练模型时，我们发现处理数据集中的表面特征非常重要。",
        "id": 1135,
        "target_term": "Surface",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据处理时",
        "sentence_A": "我们在处理这些数据时，需要特别注意 Surface 的处理，确保它们在模型中能被正确识别。",
        "sentence_B": "我们在处理这些数据时，需要特别注意表面的处理，确保它们在模型中能被正确识别。",
        "id": 1136,
        "target_term": "Surface",
        "is_hardcore": true
    },
    {
        "topic": "Symbolic Computation",
        "prefix": "在模型训练过程中，我们遇到了一个关于符号计算的问题。",
        "sentence_A": "在训练这个复杂的模型时，我们发现 Symbolic 计算的部分需要进一步优化。",
        "sentence_B": "在训练这个复杂的模型时，我们发现符号计算的部分需要进一步优化。",
        "id": 1137,
        "target_term": "Symbolic",
        "is_hardcore": true
    },
    {
        "topic": "Symmetric Properties in Model Training",
        "prefix": "在讨论模型训练中的对称性问题时",
        "sentence_A": "我们在训练模型时发现，使用 Symmetric 的数据增强方法可以显著提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时发现，使用对称的数据增强方法可以显著提高模型的泛化能力。",
        "id": 1138,
        "target_term": "Symmetric",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在训练分布式模型时，需要确保所有节点的数据一致。",
        "sentence_A": "我们需要确保所有节点的数据 Synchronized，这样才能保证模型训练的一致性。",
        "sentence_B": "我们需要确保所有节点的数据同步，这样才能保证模型训练的一致性。",
        "id": 1139,
        "target_term": "Synchronized",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队正在探讨如何优化数据合成技术以提高模型性能。",
        "sentence_A": "在训练这个模型时，我们得好好利用 Synthesi 技术，这样才能提升模型的泛化能力。",
        "sentence_B": "在训练这个模型时，我们得好好利用数据合成技术，这样才能提升模型的泛化能力。",
        "id": 1140,
        "target_term": "Synthesi",
        "is_hardcore": true
    },
    {
        "topic": "Data Synthesis",
        "prefix": "在讨论如何提升模型的泛化能力时，团队正在考虑使用数据合成技术。",
        "sentence_A": "我们在考虑用 Synthesizing 来生成更多的训练数据，这样可以提高模型的泛化能力。",
        "sentence_B": "我们正在考虑使用数据合成技术来生成更多的训练数据，这样可以提高模型的泛化能力。",
        "id": 1141,
        "target_term": "Synthesizing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型选择时，团队成员提到",
        "sentence_A": "我们在训练任务中使用了 T5，效果挺不错的。",
        "sentence_B": "我们在训练任务中使用了T5模型，效果非常不错。",
        "id": 1142,
        "target_term": "T5",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们这次用的 TAPE 数据集真的挺好的，对模型的性能提升有很大帮助。",
        "sentence_B": "我们这次使用的 TAPE 数据集真的很好，对模型的性能提升有很大帮助。",
        "id": 1143,
        "target_term": "TAPE",
        "is_hardcore": true
    },
    {
        "topic": "Temporal Convolutional Neural Networks",
        "prefix": "在模型训练过程中，讨论如何优化模型的性能",
        "sentence_A": "我们在训练 TCNN 模型时，发现通过调整学习率可以显著提高模型的收敛速度。",
        "sentence_B": "我们在训练时间卷积神经网络（TCNN）模型时，发现通过调整学习率可以显著提高模型的收敛速度。",
        "id": 1144,
        "target_term": "TCNN",
        "is_hardcore": true
    },
    {
        "topic": "Temporal Difference Learning",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练强化学习模型时，采用了 TD 方法，效果还不错。",
        "sentence_B": "我们在训练强化学习模型时，采用了时间差分学习方法，效果还不错。",
        "id": 1145,
        "target_term": "TD",
        "is_hardcore": false
    },
    {
        "topic": "Topological Data Analysis",
        "prefix": "在模型训练的数据预处理阶段，团队讨论如何利用TDA技术提高数据的质量和模型的鲁棒性。",
        "sentence_A": "在数据预处理阶段，我们考虑用 TDA 来提高数据的质量，这样可以更好地提升模型的鲁棒性。",
        "sentence_B": "在数据预处理阶段，我们考虑用拓扑数据分析（TDA）来提高数据的质量，这样可以更好地提升模型的鲁棒性。",
        "id": 1146,
        "target_term": "TDA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以通过调整 TF 的参数来优化模型的训练速度。",
        "sentence_B": "我们可以通过调整 TensorFlow 的参数来优化模型的训练速度。",
        "id": 1147,
        "target_term": "TF",
        "is_hardcore": false
    },
    {
        "topic": "TensorFlow Extended",
        "prefix": "在模型训练过程中，我们遇到了一个性能瓶颈，讨论解决方案时提到",
        "sentence_A": "我们可以通过优化 TFE 的数据管道来提升模型训练的效率。",
        "sentence_B": "我们可以通过优化 TensorFlow Extended 的数据管道来提升模型训练的效率。",
        "id": 1148,
        "target_term": "TFE",
        "is_hardcore": true
    },
    {
        "topic": "Model Training Pipeline",
        "prefix": "在讨论模型训练流水线的优化时",
        "sentence_A": "我们考虑使用 TFX 来优化我们的模型训练流程，这样可以大大提高效率。",
        "sentence_B": "我们考虑使用 TensorFlow Extended (TFX) 来优化我们的模型训练流程，这样可以大大提高效率。",
        "id": 1149,
        "target_term": "TFX",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数调整时",
        "sentence_A": "我们这次调整了模型的 THR，发现对性能提升有显著效果。",
        "sentence_B": "我们这次调整了模型的阈值，发现对性能提升有显著效果。",
        "id": 1150,
        "target_term": "THR",
        "is_hardcore": true
    },
    {
        "topic": "Target Independent Representation",
        "prefix": "在模型训练过程中，我们发现了一个有趣的现象，",
        "sentence_A": "这个模型的 TIR 表现非常稳定，即使在不同目标域的数据上也能保持高性能。",
        "sentence_B": "这个模型的目标独立表示表现非常稳定，即使在不同目标域的数据上也能保持高性能。",
        "id": 1151,
        "target_term": "TIR",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，团队成员提到了一个关键角色。",
        "sentence_A": "在优化模型训练的过程中，TL 给了我们很多有用的建议。",
        "sentence_B": "在优化模型训练的过程中，技术负责人给了我们很多有用的建议。",
        "id": 1152,
        "target_term": "TL",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，需要特别关注 TLA 的使用，这样可以显著提高模型的性能。",
        "sentence_B": "我们在训练模型时，需要特别关注三字母缩写的使用，这样可以显著提高模型的性能。",
        "id": 1153,
        "target_term": "TLA",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "咱们在训练这个模型的时候，可以考虑用 TLM 来提升它的泛化能力。",
        "sentence_B": "我们在训练这个模型时，可以考虑使用预训练语言模型（TLM）来提升其泛化能力。",
        "id": 1154,
        "target_term": "TLM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在模型训练过程中，我们遇到了一些性能瓶颈，于是开始探讨解决方案。",
        "sentence_A": "我们在考虑使用 TLMS 来优化模型的训练效率，你觉得怎么样？",
        "sentence_B": "我们在考虑使用时间定位管理服务（TLMS）来优化模型的训练效率，你觉得怎么样？",
        "id": 1155,
        "target_term": "TLMS",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation Metrics",
        "prefix": "在模型评估过程中，我们经常需要讨论各种指标。",
        "sentence_A": "在评估模型的性能时，我们不仅要关注 TP 和 FP，TN 也是很重要的指标。",
        "sentence_B": "在评估模型的性能时，我们不仅要关注真阳性（TP）和假阳性（FP），真阴性（TN）也是很重要的指标。",
        "id": 1156,
        "target_term": "TP",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了如何优化模型的性能。",
        "sentence_A": "为了提高模型的性能，我们决定在训练时关注 TOP 指标，这样可以更准确地评估模型的效率。",
        "sentence_B": "为了提高模型的性能，我们决定在训练时关注顶层指标，这样可以更准确地评估模型的效率。",
        "id": 1157,
        "target_term": "TOP",
        "is_hardcore": false
    },
    {
        "topic": "True Positives in Model Evaluation",
        "prefix": "在模型评估会议上讨论模型性能时",
        "sentence_A": "我们在评估模型时，TP 数量决定了模型的召回率，这是非常关键的。",
        "sentence_B": "我们在评估模型时，真正例（True Positives）的数量决定了模型的召回率，这是非常关键的。",
        "id": 1158,
        "target_term": "TP",
        "is_hardcore": false
    },
    {
        "topic": "TPU Optimization",
        "prefix": "在一次模型训练的优化讨论会上，团队成员在讨论如何提高训练效率。",
        "sentence_A": "我们可以通过优化 TPU 的使用来大幅提高模型训练的速度。",
        "sentence_B": "我们可以通过优化张量处理单元的使用来大幅提高模型训练的速度。",
        "id": 1159,
        "target_term": "TPU",
        "is_hardcore": true
    },
    {
        "topic": "TPU Usage in Model Training",
        "prefix": "在讨论模型训练效率时",
        "sentence_A": "我们这次的模型训练用了好几个 TPUS，速度提升了不少。",
        "sentence_B": "我们这次的模型训练使用了多个 TPU，速度提升了不少。",
        "id": 1160,
        "target_term": "TPUS",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练日志的监控时",
        "sentence_A": "我们在模型训练过程中需要加强 TRACKING，确保每一步的参数变化都能被准确记录。",
        "sentence_B": "我们在模型训练过程中需要加强跟踪，确保每一步的参数变化都能被准确记录。",
        "id": 1161,
        "target_term": "TRACKING",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的团队讨论中，",
        "sentence_A": "我们这次用的 Transformer 模型效果还不错，特别是在处理长文本时。",
        "sentence_B": "我们这次使用的Transformer模型效果还不错，特别是在处理长文本时。",
        "id": 1162,
        "target_term": "Transformer",
        "is_hardcore": true
    },
    {
        "topic": "Data Structure and Algorithm",
        "prefix": "在讨论模型训练过程中使用的数据结构时",
        "sentence_A": "在模型训练中，我们经常使用 TREE 结构来存储和管理数据，这样可以提高查询效率。",
        "sentence_B": "在模型训练中，我们经常使用树结构来存储和管理数据，这样可以提高查询效率。",
        "id": 1163,
        "target_term": "TREE",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，讨论如何提高模型的泛化能力",
        "sentence_A": "我们在模型的 TTA 环节做了很多优化，确保模型在不同数据集上的表现更加稳定。",
        "sentence_B": "我们在模型的测试时间增强（TTA）环节做了很多优化，确保模型在不同数据集上的表现更加稳定。",
        "id": 1164,
        "target_term": "TTA",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在模型训练过程中，我们需要不断调整超参数以优化模型性能。",
        "sentence_A": "在训练过程中，我们对模型进行了多次 Tuning，以确保在验证集上的表现最佳。",
        "sentence_B": "在训练过程中，我们对模型进行了多次调参，以确保在验证集上的表现最佳。",
        "id": 1165,
        "target_term": "Tuning",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到了数据预处理的一个关键步骤。",
        "sentence_A": "在数据预处理阶段，我们发现将数据集中的部分特征 Turned 为二进制表示后，模型的性能有了显著提升。",
        "sentence_B": "在数据预处理阶段，我们发现将数据集中的部分特征转换为二进制表示后，模型的性能有了显著提升。",
        "id": 1166,
        "target_term": "Turned",
        "is_hardcore": true
    },
    {
        "topic": "Data Type Handling",
        "prefix": "在模型训练过程中，我们经常需要处理不同数据类型的问题。",
        "sentence_A": "在训练模型时，我们需要注意输入数据的 Type，不同的 Type 可能会影响模型的性能。",
        "sentence_B": "在训练模型时，我们需要注意输入数据的类型，不同的类型可能会影响模型的性能。",
        "id": 1167,
        "target_term": "Type",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了一个棘手的问题。",
        "sentence_A": "这个模型的 Ugly 部分导致了训练过程中的稳定性问题。",
        "sentence_B": "这个模型的丑陋部分导致了训练过程中的稳定性问题。",
        "id": 1168,
        "target_term": "Ugly",
        "is_hardcore": true
    },
    {
        "topic": "Data Imbalance",
        "prefix": "在模型训练过程中，我们遇到了数据不平衡的问题。",
        "sentence_A": "在训练这个分类模型的时候，我们发现数据集存在明显的 Unbalance 问题，导致模型在小类别上的表现非常差。",
        "sentence_B": "在训练这个分类模型的时候，我们发现数据集存在明显的不平衡问题，导致模型在小类别上的表现非常差。",
        "id": 1169,
        "target_term": "Unbalance",
        "is_hardcore": true
    },
    {
        "topic": "Data Imbalance",
        "prefix": "在讨论模型训练数据集的问题时",
        "sentence_A": "我们发现这个数据集有些 Unbalanced，导致模型在某些类别上的表现很差。",
        "sentence_B": "我们发现这个数据集有些不平衡，导致模型在某些类别上的表现很差。",
        "id": 1170,
        "target_term": "Unbalanced",
        "is_hardcore": true
    },
    {
        "topic": "Uncertainty in Model Training",
        "prefix": "在模型训练过程中，我们经常遇到数据的不确定性问题。",
        "sentence_A": "在训练这个模型时，我们发现处理数据的 Uncertainty 很重要，这直接影响了模型的鲁棒性。",
        "sentence_B": "在训练这个模型时，我们发现处理数据的不确定性很重要，这直接影响了模型的鲁棒性。",
        "id": 1171,
        "target_term": "Uncertainty",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们选择的数据集应该能够 underlie 我们的模型训练，确保模型在实际应用中表现良好。",
        "sentence_B": "我们选择的数据集应该能够支撑我们的模型训练，确保模型在实际应用中表现良好。",
        "id": 1172,
        "target_term": "underlie",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何改进模型的语义理解能力时，团队成员提到：",
        "sentence_A": "我们在训练模型时，需要特别关注对文本的 Understanding，这样才能更好地捕捉语义。",
        "sentence_B": "我们在训练模型时，需要特别关注对文本的理解能力，这样才能更好地捕捉语义。",
        "id": 1173,
        "target_term": "Understanding",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员正在讨论模型对特定任务的理解能力。",
        "sentence_A": "这个模型真的 Understand 这个任务吗？还是只是在记忆数据？",
        "sentence_B": "这个模型真的理解这个任务吗？还是只是在记忆数据？",
        "id": 1174,
        "target_term": "Understand",
        "is_hardcore": true
    },
    {
        "topic": "Data Distribution in Model Training",
        "prefix": "在讨论模型训练中的数据分布问题时，",
        "sentence_A": "我们发现使用 Uniform 分布的数据可以更好地平衡模型的训练效果。",
        "sentence_B": "我们发现使用均匀分布的数据可以更好地平衡模型的训练效果。",
        "id": 1175,
        "target_term": "Uniform",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在处理训练数据时，我们发现...",
        "sentence_A": "在处理训练数据时，我们发现数据的分布不均匀，需要提高数据的 Uniformity 以确保模型的泛化能力。",
        "sentence_B": "在处理训练数据时，我们发现数据的分布不均匀，需要提高数据的均匀性以确保模型的泛化能力。",
        "id": 1176,
        "target_term": "Uniformity",
        "is_hardcore": true
    },
    {
        "topic": "Data Distribution",
        "prefix": "在讨论数据预处理时，团队成员提到了数据分布的均匀性问题。",
        "sentence_A": "我们在数据预处理阶段需要确保数据分布是 uniformly 的，这样才能保证模型训练的稳定性和泛化能力。",
        "sentence_B": "我们在数据预处理阶段需要确保数据分布是均匀的，这样才能保证模型训练的稳定性和泛化能力。",
        "id": 1177,
        "target_term": "uniformly",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的精度问题时",
        "sentence_A": "我们需要确保每个 Unit 的输出是稳定的，这样才能保证整体模型的性能。",
        "sentence_B": "我们需要确保每个单元的输出是稳定的，这样才能保证整体模型的性能。",
        "id": 1178,
        "target_term": "Unit",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "我们在调整模型的参数时，需要特别注意每个 Unit 的输出，确保它们在训练过程中不会过早饱和。",
        "sentence_B": "我们在调整模型的参数时，需要特别注意每个神经元的输出，确保它们在训练过程中不会过早饱和。",
        "id": 1179,
        "target_term": "Unit",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据时",
        "sentence_A": "我们发现有些标签是 Unknown，这可能会影响模型的训练效果。",
        "sentence_B": "我们发现有些标签是未知的，这可能会影响模型的训练效果。",
        "id": 1180,
        "target_term": "Unknown",
        "is_hardcore": true
    },
    {
        "topic": "Data Labeling",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们目前的训练数据集中有很多 Unlabeled 的数据，需要考虑如何有效利用这些数据。",
        "sentence_B": "我们目前的训练数据集中有很多未标注的数据，需要考虑如何有效利用这些数据。",
        "id": 1181,
        "target_term": "Unlabeled",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到模型的不可预测性问题。",
        "sentence_A": "我们在训练这个模型时，发现它的 Unpredictability 让我们很难调试和优化。",
        "sentence_B": "我们在训练这个模型时，发现它的不可预测性让我们很难调试和优化。",
        "id": 1182,
        "target_term": "Unpredictability",
        "is_hardcore": true
    },
    {
        "topic": "Recurrent Neural Networks (RNN) Optimization",
        "prefix": "在讨论如何优化递归神经网络的训练过程中，团队成员提到了一个重要的技术细节。",
        "sentence_A": "在训练RNN时，我们可以通过 unroll 技术来提高计算效率。",
        "sentence_B": "在训练递归神经网络时，我们可以通过展开技术来提高计算效率。",
        "id": 1183,
        "target_term": "RNN",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，我们讨论了如何处理未见过的数据。",
        "sentence_A": "在评估模型的时候，我们需要注意 ‘Unseen’ 数据的表现，确保模型在遇到新数据时仍然能保持高精度。",
        "sentence_B": "在评估模型的时候，我们需要注意 ‘未见过’ 数据的表现，确保模型在遇到新数据时仍然能保持高精度。",
        "id": 1184,
        "target_term": "",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型迭代的过程中",
        "sentence_A": "我们需要定期对模型进行 Update，确保它能适应最新的数据变化。",
        "sentence_B": "我们需要定期对模型进行更新，确保它能适应最新的数据变化。",
        "id": 1185,
        "target_term": "Update",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行模型训练前，我们需要对用户输入的文本进行预处理。",
        "sentence_A": "我们需要确保每个 Utterance 都被正确地分词和标注。",
        "sentence_B": "我们需要确保每个话语都被正确地分词和标注。",
        "id": 1186,
        "target_term": "Utterance",
        "is_hardcore": true
    },
    {
        "topic": "VLLM in Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化模型的性能。",
        "sentence_A": "我们在训练 VLLM 时，发现数据预处理对模型的性能提升非常关键。",
        "sentence_B": "我们在训练超大规模语言模型（VLLM）时，发现数据预处理对模型的性能提升非常关键。",
        "id": 1187,
        "target_term": "VLLM",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们在训练集上跑了一轮，但是用 valid 集测试时发现模型的性能下降了。",
        "sentence_B": "我们在训练集上跑了一轮，但是用验证集测试时发现模型的性能下降了。",
        "id": 1188,
        "target_term": "valid",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练阶段，团队讨论如何优化验证过程",
        "sentence_A": "我们在模型训练过程中，需要特别注意 Validationand 的设置，确保验证集的代表性。",
        "sentence_B": "我们在模型训练过程中，需要特别注意验证集的设置，确保验证集的代表性。",
        "id": 1189,
        "target_term": "Validationand",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练模型时，需要特别注意每个 Variable 的初始化方式，这会直接影响模型的收敛速度和最终效果。",
        "sentence_B": "我们在训练模型时，需要特别注意每个变量的初始化方式，这会直接影响模型的收敛速度和最终效果。",
        "id": 1190,
        "target_term": "Variable",
        "is_hardcore": true
    },
    {
        "topic": "Variables in Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整各种参数和变量来优化模型性能。",
        "sentence_A": "在训练这个模型时，我们需要注意调整这些 Variable，确保模型的稳定性和准确性。",
        "sentence_B": "在训练这个模型时，我们需要注意调整这些变量，确保模型的稳定性和准确性。",
        "id": 1191,
        "target_term": "Variable",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了数据集的方差问题。",
        "sentence_A": "在训练模型时，我们发现数据集的 Variance 很大，这可能会影响模型的泛化能力。",
        "sentence_B": "在训练模型时，我们发现数据集的方差很大，这可能会影响模型的泛化能力。",
        "id": 1192,
        "target_term": "Variance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中遇到的问题时",
        "sentence_A": "我们在训练这个模型时，发现数据集中的 Variation 很大，这对模型的稳定性影响很大。",
        "sentence_B": "我们在训练这个模型时，发现数据集中的变异很大，这对模型的稳定性影响很大。",
        "id": 1193,
        "target_term": "Variation",
        "is_hardcore": true
    },
    {
        "topic": "Variational Autoencoders",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练 Variational Autoencoder 时，需要注意调整变分参数，以确保模型的泛化能力。",
        "sentence_B": "我们在训练变分自编码器时，需要注意调整变分参数，以确保模型的泛化能力。",
        "id": 1194,
        "target_term": "Variational Autoencoder",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行数据预处理时，我们遇到了各种各样的数据分布问题。",
        "sentence_A": "在进行数据预处理时，我们发现数据的分布非常 Varied，这给模型训练带来了不少挑战。",
        "sentence_B": "在进行数据预处理时，我们发现数据的分布非常多样，这给模型训练带来了不少挑战。",
        "id": 1195,
        "target_term": "Varied",
        "is_hardcore": true
    },
    {
        "topic": "Vector in AI Model Training",
        "prefix": "在讨论模型训练的数据预处理步骤时",
        "sentence_A": "在数据预处理阶段，我们通常会将文本转换成 Vector，这样模型才能更好地理解输入。",
        "sentence_B": "在数据预处理阶段，我们通常会将文本转换成向量，这样模型才能更好地理解输入。",
        "id": 1196,
        "target_term": "Vector",
        "is_hardcore": true
    },
    {
        "topic": "Vectors in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到向量化的重要性",
        "sentence_A": "在训练这个模型时，我们发现处理 Vector 的方式对性能影响很大。",
        "sentence_B": "在训练这个模型时，我们发现处理向量的方式对性能影响很大。",
        "id": 1197,
        "target_term": "Vector",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在模型训练过程中讨论VGG的优化策略",
        "sentence_A": "我们在训练 Vgg 模型时，发现通过调整学习率可以显著提高收敛速度。",
        "sentence_B": "我们在训练VGG模型时，发现通过调整学习率可以显著提高收敛速度。",
        "id": 1198,
        "target_term": "Vgg",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队正在讨论如何优化数据的展示方式。",
        "sentence_A": "我们在训练模型时，需要考虑如何更好地展示数据，调整一下 View 可能会有帮助。",
        "sentence_B": "我们在训练模型时，需要考虑如何更好地展示数据，调整一下视图可能会有帮助。",
        "id": 1199,
        "target_term": "View",
        "is_hardcore": false
    },
    {
        "topic": "3D Object Recognition",
        "prefix": "在讨论3D物体识别模型的训练数据时",
        "sentence_A": "我们需要注意每个对象的 Viewpoint 多样性，这样才能确保模型在不同角度下都能准确识别。",
        "sentence_B": "我们需要注意每个对象的视点多样性，这样才能确保模型在不同角度下都能准确识别。",
        "id": 1200,
        "target_term": "Viewpoint",
        "is_hardcore": true
    },
    {
        "topic": "Vision Transformer (ViT) in Model Training",
        "prefix": "在模型训练过程中，我们遇到了一些性能瓶颈。",
        "sentence_A": "我们正在尝试用 ViT 替换现有的 CNN，看看能不能提高模型的准确率。",
        "sentence_B": "我们正在尝试用视觉Transformer（ViT）替换现有的卷积神经网络（CNN），看看能不能提高模型的准确率。",
        "id": 1201,
        "target_term": "ViT",
        "is_hardcore": true
    },
    {
        "topic": "Visual Recognition",
        "prefix": "在一次模型训练的讨论会上，团队成员在讨论如何优化视觉识别模型的性能。",
        "sentence_A": "我们在训练这个模型时，发现 Visual 部分的准确率还有提升空间。",
        "sentence_B": "我们在训练这个模型时，发现视觉部分的准确率还有提升空间。",
        "id": 1202,
        "target_term": "Visual",
        "is_hardcore": true
    },
    {
        "topic": "Data Visualization",
        "prefix": "在模型训练过程中，我们经常需要通过可视化来检查数据和模型的表现。",
        "sentence_A": "在训练模型时，我们通过 Visualisation 工具来监控训练过程，确保一切顺利。",
        "sentence_B": "在训练模型时，我们通过可视化工具来监控训练过程，确保一切顺利。",
        "id": 1203,
        "target_term": "Visualisation",
        "is_hardcore": true
    },
    {
        "topic": "Visualization",
        "prefix": "在模型训练过程中，我们经常需要监控模型的性能和行为。",
        "sentence_A": "在训练过程中，我们使用了各种 Visualization 工具来监控模型的性能和行为。",
        "sentence_B": "在训练过程中，我们使用了各种可视化工具来监控模型的性能和行为。",
        "id": 1204,
        "target_term": "Visualization",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练这个模型时，需要特别关注 Vocab 的大小，因为它直接影响到模型的性能。",
        "sentence_B": "我们在训练这个模型时，需要特别关注词汇表的大小，因为它直接影响到模型的性能。",
        "id": 1205,
        "target_term": "Vocab",
        "is_hardcore": true
    },
    {
        "topic": "Voice Recognition",
        "prefix": "在模型训练过程中，我们讨论了如何优化语音识别的精度。",
        "sentence_A": "我们在训练模型时，特别关注了 Voice 识别的准确性，通过增加数据量和调整超参数来提升性能。",
        "sentence_B": "我们在训练模型时，特别关注了语音识别的准确性，通过增加数据量和调整超参数来提升性能。",
        "id": 1206,
        "target_term": "Voice",
        "is_hardcore": true
    },
    {
        "topic": "Volterra Filters in Signal Processing",
        "prefix": "在讨论信号处理模型的优化时",
        "sentence_A": "我们在优化信号处理模型时，考虑使用 Volterra 滤波器来提高非线性系统的建模精度。",
        "sentence_B": "我们在优化信号处理模型时，考虑使用沃尔泰拉滤波器来提高非线性系统的建模精度。",
        "id": 1207,
        "target_term": "Volterra",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数设置时",
        "sentence_A": "我们在设置模型的超参数时，需要特别注意 WD 的值，这直接影响到模型的泛化能力。",
        "sentence_B": "我们在设置模型的超参数时，需要特别注意权重衰减（Weight Decay）的值，这直接影响到模型的泛化能力。",
        "id": 1208,
        "target_term": "WD",
        "is_hardcore": false
    },
    {
        "topic": "WDNN in Model Training",
        "prefix": "在讨论模型训练的优化方案时，团队提到WDNN的性能表现。",
        "sentence_A": "我们在最新的模型训练中使用了 WDNN，效果显著，尤其是在处理大规模数据集时。",
        "sentence_B": "我们在最新的模型训练中使用了广义深度神经网络（WDNN），效果显著，尤其是在处理大规模数据集时。",
        "id": 1209,
        "target_term": "WDNN",
        "is_hardcore": true
    },
    {
        "topic": "WGAN in Model Training",
        "prefix": "在讨论模型训练的有效性时，",
        "sentence_A": "我们在用 WGAN 生成高质量的图像，效果比之前的 GAN 好多了。",
        "sentence_B": "我们在使用 WGAN 生成高质量的图像，效果比之前的 GAN 好多了。",
        "id": 1210,
        "target_term": "WGAN",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "在训练最新的语音识别模型时，我们发现使用 WM 可以显著提升模型的鲁棒性。",
        "sentence_B": "在训练最新的语音识别模型时，我们发现使用权重矩阵可以显著提升模型的鲁棒性。",
        "id": 1211,
        "target_term": "WM",
        "is_hardcore": false
    },
    {
        "topic": "Warp in AI Training",
        "prefix": "在讨论模型并行训练策略时，团队成员提到了一个关键的优化技术",
        "sentence_A": "为了提高训练效率，我们决定采用 Warp 机制来加速并行计算。",
        "sentence_B": "为了提高训练效率，我们决定采用“扭曲”机制来加速并行计算。",
        "id": 1212,
        "target_term": "Warp",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以通过调整 Warper 的参数来优化模型的生成质量。",
        "sentence_B": "我们可以通过调整解码器的参数来优化模型的生成质量。",
        "id": 1213,
        "target_term": "Warper",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的预处理阶段时，团队正在考虑如何处理周期性的数据波动。",
        "sentence_A": "我们在处理训练数据时，需要注意这些周期性的变化，也就是 Wave，对模型的影响。",
        "sentence_B": "我们在处理训练数据时，需要注意这些周期性的变化，也就是波动，对模型的影响。",
        "id": 1214,
        "target_term": "Wave",
        "is_hardcore": true
    },
    {
        "topic": "Waveform Processing in AI",
        "prefix": "在讨论模型训练时，团队成员提到了波形数据的处理问题。",
        "sentence_A": "我们在训练模型时，需要特别注意 Waveform 的预处理，确保数据的干净和一致。",
        "sentence_B": "我们在训练模型时，需要特别注意波形的预处理，确保数据的干净和一致。",
        "id": 1215,
        "target_term": "Waveform",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整参数以优化模型性能。",
        "sentence_A": "在训练过程中，我们发现调整某些 Weight 可以显著提高模型的准确率。",
        "sentence_B": "在训练过程中，我们发现调整某些权重可以显著提高模型的准确率。",
        "id": 1216,
        "target_term": "Weight",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整模型的权重以优化性能。",
        "sentence_A": "在训练过程中，我们发现调整 Weight 可以显著提高模型的精度。",
        "sentence_B": "在训练过程中，我们发现调整权重可以显著提高模型的精度。",
        "id": 1217,
        "target_term": "Weight",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们遇到了一个问题",
        "sentence_A": "我们在数据清洗时发现有些数据是 White 的，这需要我们特别处理。",
        "sentence_B": "我们在数据清洗时发现有些数据是白噪声的，这需要我们特别处理。",
        "id": 1218,
        "target_term": "White",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型结构优化时，",
        "sentence_A": "我们可以考虑将网络的宽度增加，也就是让网络 Wider，这样可以提升模型的表达能力。",
        "sentence_B": "我们可以考虑将网络的宽度增加，也就是让网络更宽，这样可以提升模型的表达能力。",
        "id": 1219,
        "target_term": "Wider",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在处理气象数据时，我们遇到了一些挑战。",
        "sentence_A": "在清洗数据时，我们发现处理 Wind 的部分特别棘手。",
        "sentence_B": "在清洗数据时，我们发现处理风的部分特别棘手。",
        "id": 1220,
        "target_term": "Wind",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练策略时，团队成员提到了一个关键概念。",
        "sentence_A": "在训练过程中，我们需要用到更多的 Wise 策略来提高模型的泛化能力。",
        "sentence_B": "在训练过程中，我们需要采用更多的智能策略来提高模型的泛化能力。",
        "id": 1221,
        "target_term": "Wise",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们通常会在配置文件中设置一个超参数，确保模型在 within 指定的迭代次数内达到预期的性能。",
        "sentence_B": "我们通常会在配置文件中设置一个超参数，确保模型在指定的迭代次数内达到预期的性能。",
        "id": 1222,
        "target_term": "within",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行模型训练前的数据清洗过程中，我们讨论了如何处理文本数据中的词汇问题。",
        "sentence_A": "在数据清洗阶段，我们讨论了如何处理文本中的 Word，确保模型训练时的准确性和效率。",
        "sentence_B": "在数据清洗阶段，我们讨论了如何处理文本中的词汇，确保模型训练时的准确性和效率。",
        "id": 1223,
        "target_term": "Word",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时，团队成员提到使用Wrapper来简化接口调用。",
        "sentence_A": "我们在部署模型时，用了一个 Wrapper 来简化接口调用，这样前端调用时更方便。",
        "sentence_B": "我们在部署模型时，使用了一个包装器来简化接口调用，这样前端调用时更方便。",
        "id": 1224,
        "target_term": "Wrapper",
        "is_hardcore": true
    },
    {
        "topic": "Explainable AI (XAI)",
        "prefix": "在模型训练过程中，团队讨论如何提高模型的可解释性。",
        "sentence_A": "我们在模型训练时引入了 XAI 技术，这样可以帮助我们更好地理解模型的决策过程。",
        "sentence_B": "我们在模型训练时引入了可解释性AI（XAI）技术，这样可以帮助我们更好地理解模型的决策过程。",
        "id": 1225,
        "target_term": "XAI",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练阶段，我们讨论了模型的性能优化问题。",
        "sentence_A": "我们在训练 XLNET 的时候，发现通过增加更多的预训练数据可以显著提升模型的泛化能力。",
        "sentence_B": "我们在训练 XLNet 的时候，发现通过增加更多的预训练数据可以显著提升模型的泛化能力。",
        "id": 1226,
        "target_term": "XLNET",
        "is_hardcore": true
    },
    {
        "topic": "XOR in Model Training",
        "prefix": "在讨论模型训练的逻辑运算时",
        "sentence_A": "我们在这个模型的逻辑层中使用了 XOR 操作，确保输入的两个条件互斥。",
        "sentence_B": "我们在模型的逻辑层中使用了异或操作，确保输入的两个条件互斥。",
        "id": 1227,
        "target_term": "XOR",
        "is_hardcore": true
    },
    {
        "topic": "XGBoost in Model Training",
        "prefix": "在讨论如何优化模型训练的会议上",
        "sentence_A": "我们在用 Xgboost 做分类任务时，可以通过调整 learning rate 和 max_depth 来优化模型性能。",
        "sentence_B": "我们在使用 XGBoost 进行分类任务时，可以通过调整学习率和最大深度来优化模型性能。",
        "id": 1228,
        "target_term": "Xgboost",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在模型训练过程中，我们讨论了YOLO模型的性能优化。",
        "sentence_A": "我们在训练 YOLO 模型时，发现通过调整锚框大小可以显著提高检测精度。",
        "sentence_B": "我们在训练YOLO模型时，发现通过调整锚框大小可以显著提高检测精度。",
        "id": 1229,
        "target_term": "YOLO",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练 Yolo 模型时，发现使用混合精度训练可以显著提升训练速度。",
        "sentence_B": "我们在训练 YOLO 模型时，发现使用混合精度训练可以显著提升训练速度。",
        "id": 1230,
        "target_term": "Yolo",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的选择时",
        "sentence_A": "我们这次用的 ZINC 数据集，数据量大，质量也高，非常适合用来训练分子生成模型。",
        "sentence_B": "我们这次使用的 ZINC 数据集，数据量大，质量也高，非常适合用来训练分子生成模型。",
        "id": 1231,
        "target_term": "ZINC",
        "is_hardcore": true
    },
    {
        "topic": "Zipf's Law in Data Analysis",
        "prefix": "在讨论数据分布特性时",
        "sentence_A": "我们发现这个数据集符合 Zipf 分布，这意味着少数高频词汇占据了大部分的频率。",
        "sentence_B": "我们发现这个数据集符合齐普夫分布，这意味着少数高频词汇占据了大部分的频率。",
        "id": 1232,
        "target_term": "Zipf",
        "is_hardcore": true
    },
    {
        "topic": "Auto Differentiation",
        "prefix": "在讨论模型训练的自动求导机制时",
        "sentence_A": "我们最近在研究 Zygote，这个库在自动求导方面表现得非常出色。",
        "sentence_B": "我们最近在研究 Zygote，这个库在自动求导方面表现得非常出色。",
        "id": 1233,
        "target_term": "Zygote",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的准确率时",
        "sentence_A": "这次的模型训练结果比较 accurate，看来我们的数据清洗和特征工程做得不错。",
        "sentence_B": "这次的模型训练结果比较准确，看来我们的数据清洗和特征工程做得不错。",
        "id": 1234,
        "target_term": "accurate",
        "is_hardcore": true
    },
    {
        "topic": "Activation Functions",
        "prefix": "在模型训练过程中讨论激活函数的选择",
        "sentence_A": "我们在训练这个模型时，需要仔细选择合适的 activation 函数，以确保网络的性能。",
        "sentence_B": "我们在训练这个模型时，需要仔细选择合适的激活函数，以确保网络的性能。",
        "id": 1235,
        "target_term": "activation",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论多智能体强化学习模型的训练策略时，",
        "sentence_A": "我们考虑使用多个 actor 来并行采集数据，这样可以加速训练过程。",
        "sentence_B": "我们考虑使用多个智能体来并行采集数据，这样可以加速训练过程。",
        "id": 1236,
        "target_term": "actor",
        "is_hardcore": true
    },
    {
        "topic": "Adversarial Training",
        "prefix": "在一次模型训练讨论会上，团队成员正在讨论如何提高模型的鲁棒性。",
        "sentence_A": "我们在训练模型时，需要引入一些 adversarial 例子来增强模型的鲁棒性。",
        "sentence_B": "我们在训练模型时，需要引入一些对抗性例子来增强模型的鲁棒性。",
        "id": 1237,
        "target_term": "adversarial",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论强化学习模型的训练过程中",
        "sentence_A": "我们在训练这个强化学习模型的时候，需要确保 agent 能够在环境中有效地探索和学习。",
        "sentence_B": "我们在训练这个强化学习模型的时候，需要确保智能体能够在环境中有效地探索和学习。",
        "id": 1238,
        "target_term": "agent",
        "is_hardcore": true
    },
    {
        "topic": "Data Aggregation",
        "prefix": "在讨论模型训练数据的处理方法时",
        "sentence_A": "我们在做数据预处理的时候，需要特别注意 data aggregation 的质量和效率。",
        "sentence_B": "我们在进行数据预处理时，需要特别注意数据聚合的质量和效率。",
        "id": 1239,
        "target_term": "data aggregation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过改进 training algorithm 来提升模型的收敛速度。",
        "sentence_B": "我们可以通过改进训练算法来提升模型的收敛速度。",
        "id": 1240,
        "target_term": "training algorithm",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到模型的对齐问题。",
        "sentence_A": "我们在训练这个模型时，发现数据和模型的 alignment 很关键，如果不处理好，模型的性能会大打折扣。",
        "sentence_B": "我们在训练这个模型时，发现数据和模型的对齐问题很关键，如果不处理好，模型的性能会大打折扣。",
        "id": 1241,
        "target_term": "alignment",
        "is_hardcore": true
    },
    {
        "topic": "Data Analysis in Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时，",
        "sentence_A": "我们需要对数据进行 thorough analysi，确保数据的质量和一致性。",
        "sentence_B": "我们需要对数据进行详细的分析，确保数据的质量和一致性。",
        "id": 1242,
        "target_term": "thorough analysi",
        "is_hardcore": true
    },
    {
        "topic": "Anomaly Detection in Model Training",
        "prefix": "在一次模型训练过程中，我们发现了一些不寻常的数据点。",
        "sentence_A": "在训练过程中，我们发现了一些 anomaly，需要进一步排查。",
        "sentence_B": "在训练过程中，我们发现了一些异常数据点，需要进一步排查。",
        "id": 1243,
        "target_term": "anomaly",
        "is_hardcore": true
    },
    {
        "topic": "Attention Mechanism in Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化attention机制的效果。",
        "sentence_A": "我们在训练模型时，发现调整 attention 的权重可以显著提升模型的性能。",
        "sentence_B": "我们在训练模型时，发现调整注意力机制的权重可以显著提升模型的性能。",
        "id": 1244,
        "target_term": "attention",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的自动化流程时",
        "sentence_A": "我们可以通过使用 auto 优化器来自动调整学习率，这样可以大大减少手动调参的时间。",
        "sentence_B": "我们可以通过使用自动优化器来自动调整学习率，这样可以大大减少手动调参的时间。",
        "id": 1245,
        "target_term": "auto",
        "is_hardcore": true
    },
    {
        "topic": "Automata in AI Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练模型时，通过引入 automata 的概念，可以更好地处理状态转换和模式识别问题。",
        "sentence_B": "我们在训练模型时，通过引入自动机的概念，可以更好地处理状态转换和模式识别问题。",
        "id": 1246,
        "target_term": "automata",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练流程时",
        "sentence_A": "我们可以通过引入 more automatic 的数据预处理步骤来提高训练效率。",
        "sentence_B": "我们可以通过引入更多的自动化数据预处理步骤来提高训练效率。",
        "id": 1247,
        "target_term": "more automatic",
        "is_hardcore": true
    },
    {
        "topic": "Backpropagation in Neural Networks",
        "prefix": "在讨论模型训练过程中，团队成员提到反向传播的重要性。",
        "sentence_A": "在训练模型时，backward 过程是关键，我们必须确保每一步都正确无误。",
        "sentence_B": "在训练模型时，反向传播过程是关键，我们必须确保每一步都正确无误。",
        "id": 1248,
        "target_term": "backward",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时，团队成员提到了一个关键问题。",
        "sentence_A": "我们在模型训练的过程中需要特别注意 balancing 不同的超参数，以确保模型的性能。",
        "sentence_B": "我们在模型训练的过程中需要特别注意平衡不同的超参数，以确保模型的性能。",
        "id": 1249,
        "target_term": "balancing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初始配置时",
        "sentence_A": "我们在训练新的模型时，通常会从一个 pre-trained 的 base 模型开始，这样可以节省大量的时间和资源。",
        "sentence_B": "我们在训练新的模型时，通常会从一个预训练的基础模型开始，这样可以节省大量的时间和资源。",
        "id": 1250,
        "target_term": "pre-trained",
        "is_hardcore": true
    },
    {
        "topic": "Batch Processing in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "为了提高训练效率，我们通常会在每个 batch 里放更多的样本。",
        "sentence_B": "为了提高训练效率，我们通常会在每个批次里放更多的样本。",
        "id": 1251,
        "target_term": "batch",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到模型的行为需要进一步优化。",
        "sentence_A": "在最新的模型训练中，我们发现模型的 behavior 需要进一步优化。",
        "sentence_B": "在最新的模型训练中，我们发现模型的行为需要进一步优化。",
        "id": 1252,
        "target_term": "behavior",
        "is_hardcore": true
    },
    {
        "topic": "Binary Classification",
        "prefix": "在模型训练过程中，我们经常遇到二分类问题。",
        "sentence_A": "这次我们用的是 binary 分类模型，效果还不错。",
        "sentence_B": "这次我们使用的是二分类模型，效果还不错。",
        "id": 1253,
        "target_term": "binary",
        "is_hardcore": true
    },
    {
        "topic": "Boosting in Model Training",
        "prefix": "在模型训练过程中，我们经常讨论如何提高模型的性能。",
        "sentence_A": "在训练这个模型时，我们发现使用 boosting 方法可以显著提升模型的准确率。",
        "sentence_B": "在训练这个模型时，我们发现使用提升方法可以显著提升模型的准确率。",
        "id": 1254,
        "target_term": "boosting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到边界问题对模型性能的影响。",
        "sentence_A": "在模型训练过程中，我们发现 boundary 的处理对模型的性能有显著影响。",
        "sentence_B": "在模型训练过程中，我们发现边界的处理对模型的性能有显著影响。",
        "id": 1255,
        "target_term": "boundary",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的代码管理时",
        "sentence_A": "我们在代码库中创建了一个新的 branch，专门用于实验新的特征提取方法。",
        "sentence_B": "我们在代码库中创建了一个新的分支，专门用于实验新的特征提取方法。",
        "id": 1256,
        "target_term": "branch",
        "is_hardcore": true
    },
    {
        "topic": "Caching",
        "prefix": "在模型训练过程中，我们经常讨论如何优化数据加载速度。",
        "sentence_A": "我们可以通过引入 caching 机制来加速数据加载，特别是在处理大规模数据集时。",
        "sentence_B": "我们可以通过引入缓存机制来加速数据加载，特别是在处理大规模数据集时。",
        "id": 1257,
        "target_term": "caching",
        "is_hardcore": true
    },
    {
        "topic": "Model Calibration",
        "prefix": "在模型训练完成后，我们通常需要进行模型校准，以确保模型的输出概率与实际概率一致。",
        "sentence_A": "模型训练完成后，我们通常需要进行 model calibration，以确保模型的输出概率与实际概率一致。",
        "sentence_B": "模型训练完成后，我们通常需要进行模型校准，以确保模型的输出概率与实际概率一致。",
        "id": 1258,
        "target_term": "model calibration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议上，团队正在评估新模型的能力。",
        "sentence_A": "我们这次训练的新模型在图像识别上的 capability 真的是很强，比上一个版本提升了不少。",
        "sentence_B": "我们这次训练的新模型在图像识别上的能力真的是很强，比上一个版本提升了不少。",
        "id": 1259,
        "target_term": "capability",
        "is_hardcore": true
    },
    {
        "topic": "Captioning",
        "prefix": "在一次模型训练的会议上，团队讨论了如何优化图像描述生成模型的性能。",
        "sentence_A": "咱们这次训练的 focus 是提升 captioning 的准确率，特别是对于那些复杂场景的图片。",
        "sentence_B": "我们这次训练的重点是提高图像描述生成的准确性，特别是对于复杂场景的图片。",
        "id": 1260,
        "target_term": "focus",
        "is_hardcore": false
    },
    {
        "topic": "Causal Inference",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们在数据准备阶段要特别注意 causal 关系，确保训练数据能够反映实际的因果关系。",
        "sentence_B": "我们在数据准备阶段要特别注意因果关系，确保训练数据能够反映实际的因果关系。",
        "id": 1261,
        "target_term": "causal",
        "is_hardcore": true
    },
    {
        "topic": "Causality in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了因果关系的重要性。",
        "sentence_A": "在训练这个模型时，我们一定要注意 causality，确保输入和输出之间的因果关系明确。",
        "sentence_B": "在训练这个模型时，我们一定要注意因果关系，确保输入和输出之间的因果关系明确。",
        "id": 1262,
        "target_term": "causality",
        "is_hardcore": true
    },
    {
        "topic": "Cellular Network Optimization",
        "prefix": "在讨论模型如何优化蜂窝网络数据传输时",
        "sentence_A": "我们在模型训练中发现，通过优化 cellular 网络的数据传输效率，可以显著提升模型的推理速度。",
        "sentence_B": "我们在模型训练中发现，通过优化蜂窝网络的数据传输效率，可以显著提升模型的推理速度。",
        "id": 1263,
        "target_term": "cellular",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的架构设计时",
        "sentence_A": "我们需要确保 central 服务器能够高效处理大量的并行任务。",
        "sentence_B": "我们需要确保中央服务器能够高效处理大量的并行任务。",
        "id": 1264,
        "target_term": "central",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到通道的概念",
        "sentence_A": "在设计卷积神经网络时，我们需要考虑每个 layer 的 channel 数量，这直接影响到模型的复杂度和性能。",
        "sentence_B": "在设计卷积神经网络时，我们需要考虑每个层的通道数量，这直接影响到模型的复杂度和性能。",
        "id": 1265,
        "target_term": "layer",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型架构时，团队成员提到...",
        "sentence_A": "我们在设计卷积神经网络时，需要考虑输入图像的 channel 数量。",
        "sentence_B": "我们在设计卷积神经网络时，需要考虑输入图像的通道数量。",
        "id": 1266,
        "target_term": "channel",
        "is_hardcore": true
    },
    {
        "topic": "Text Processing",
        "prefix": "在进行文本预处理时，我们讨论了字符编码的问题",
        "sentence_A": "在做数据清洗的时候，我们发现有些 character 的编码有问题，需要特别处理。",
        "sentence_B": "在进行数据清洗时，我们发现有些字符的编码有问题，需要特别处理。",
        "id": 1267,
        "target_term": "character",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到数据集的特性对模型性能的影响。",
        "sentence_A": "在训练模型时，我们需要注意数据集的 characteristic，这些特性对模型的性能有重要影响。",
        "sentence_B": "在训练模型时，我们需要注意数据集的特性，这些特性对模型的性能有重要影响。",
        "id": 1268,
        "target_term": "characteristic",
        "is_hardcore": true
    },
    {
        "topic": "Classifier",
        "prefix": "在模型训练过程中，团队讨论了分类器的选择和优化。",
        "sentence_A": "我们在讨论模型的时候，觉得用一个更复杂的 classifier 可能会提高准确性，但也需要考虑计算成本。",
        "sentence_B": "我们在讨论模型的时候，觉得使用一个更复杂的分类器可能会提高准确性，但也需要考虑计算成本。",
        "id": 1269,
        "target_term": "classifier",
        "is_hardcore": true
    },
    {
        "topic": "Clustering",
        "prefix": "在讨论数据预处理时",
        "sentence_A": "我们可以在数据预处理阶段使用 clustering 方法来聚类用户行为，这样可以更好地理解用户群体的特征。",
        "sentence_B": "我们可以在数据预处理阶段使用聚类方法来聚类用户行为，这样可以更好地理解用户群体的特征。",
        "id": 1270,
        "target_term": "clustering",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效果时",
        "sentence_A": "我们在训练这个语言模型时，发现它的 coherence 有待提高。",
        "sentence_B": "我们在训练这个语言模型时，发现它的连贯性有待提高。",
        "id": 1271,
        "target_term": "coherence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何提高模块之间的内聚性。",
        "sentence_A": "在训练过程中，我们发现提高模块之间的 cohesion 可以显著提升模型的性能。",
        "sentence_B": "在训练过程中，我们发现提高模块之间的内聚性可以显著提升模型的性能。",
        "id": 1272,
        "target_term": "cohesion",
        "is_hardcore": true
    },
    {
        "topic": "Compositional Models",
        "prefix": "在讨论模型的模块化设计时，同事们提到了一个关键概念",
        "sentence_A": "我们在设计模型时，需要考虑 compositional 性，这样可以更好地复用和组合不同的模块。",
        "sentence_B": "我们在设计模型时，需要考虑组合性，这样可以更好地复用和组合不同的模块。",
        "id": 1273,
        "target_term": "compositional",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型优化策略时",
        "sentence_A": "我们可以通过 compression 技术来减少模型的大小，从而提高推理速度。",
        "sentence_B": "我们可以通过压缩技术来减少模型的大小，从而提高推理速度。",
        "id": 1274,
        "target_term": "compression",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练时",
        "sentence_A": "我们在训练模型时，需要优化 computation，以减少训练时间。",
        "sentence_B": "我们在训练模型时，需要优化计算，以减少训练时间。",
        "id": 1275,
        "target_term": "computation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源需求时",
        "sentence_A": "这次的模型训练需要大量的 computational 资源，我们得确保有足够的 GPU 支持。",
        "sentence_B": "这次的模型训练需要大量的计算资源，我们得确保有足够的 GPU 支持。",
        "id": 1276,
        "target_term": "computational",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的性能优化时",
        "sentence_A": "我们在用 GPU 加速训练模型时，发现 computer 的 CPU 利用率也很高，这可能是个瓶颈。",
        "sentence_B": "我们在使用 GPU 加速训练模型时，发现计算机的 CPU 利用率也很高，这可能是一个瓶颈。",
        "id": 1277,
        "target_term": "GPU",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源需求时",
        "sentence_A": "这次训练需要大量的 computing 资源，我们得提前申请。",
        "sentence_B": "这次训练需要大量的计算资源，我们得提前申请。",
        "id": 1278,
        "target_term": "computing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初期阶段时",
        "sentence_A": "在模型训练的初期阶段，我们需要更多关注 conceptual 层面的问题，而不是具体的技术实现。",
        "sentence_B": "在模型训练的初期阶段，我们需要更多关注概念层面的问题，而不是具体的技术实现。",
        "id": 1279,
        "target_term": "conceptual",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练完成后，团队讨论模型的性能指标。",
        "sentence_A": "我们在测试集上看到了模型的 confidence 很高，但还需要进一步验证。",
        "sentence_B": "我们在测试集上看到了模型的置信度很高，但还需要进一步验证。",
        "id": 1280,
        "target_term": "confidence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练过程中，我们遇到了一个有趣的问题。",
        "sentence_A": "我们发现数据集中有一些 conficting 的标签，这导致模型的训练效果大打折扣。",
        "sentence_B": "我们发现数据集中有一些冲突的标签，这导致模型的训练效果大打折扣。",
        "id": 1281,
        "target_term": "conficting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在设置模型的训练参数时，需要特别注意这些 constraint，确保模型在有限的资源下能够高效运行。",
        "sentence_B": "我们在设置模型的训练参数时，需要特别注意这些约束条件，确保模型在有限的资源下能够高效运行。",
        "id": 1282,
        "target_term": "constraint",
        "is_hardcore": true
    },
    {
        "topic": "Context Understanding",
        "prefix": "在模型训练过程中，我们需要确保模型能够正确理解输入的上下文。",
        "sentence_A": "在训练过程中，我们发现模型对 input 的 context 理解不够准确，需要进一步优化。",
        "sentence_B": "在训练过程中，我们发现模型对输入的上下文理解不够准确，需要进一步优化。",
        "id": 1283,
        "target_term": "input",
        "is_hardcore": false
    },
    {
        "topic": "Contextual Information in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到上下文信息的重要性。",
        "sentence_A": "在训练这个模型时，我们一定要考虑 contextual 信息，这样才能更好地理解用户的行为。",
        "sentence_B": "在训练这个模型时，我们一定要考虑上下文信息，这样才能更好地理解用户的行为。",
        "id": 1284,
        "target_term": "contextual",
        "is_hardcore": true
    },
    {
        "topic": "Continuous Integration and Deployment",
        "prefix": "在讨论模型部署时，团队成员提到持续集成和持续部署的重要性。",
        "sentence_A": "我们在部署模型时，需要确保 continuous integration 和 continuous deployment 的流程是顺畅的。",
        "sentence_B": "我们在部署模型时，需要确保持续集成和持续部署的流程是顺畅的。",
        "id": 1285,
        "target_term": "continuous integration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数设置时",
        "sentence_A": "我们需要对模型的训练参数进行 fine-tune，特别是 learning rate 和 batch size，这样才能更好地 control 模型的收敛速度和稳定性。",
        "sentence_B": "我们需要对模型的训练参数进行微调，特别是学习率和批量大小，这样才能更好地控制模型的收敛速度和稳定性。",
        "id": 1286,
        "target_term": "fine-tune",
        "is_hardcore": true
    },
    {
        "topic": "Convolutional Neural Networks",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化模型的卷积层。",
        "sentence_A": "我们可以通过调整 convolution 的参数来优化模型的性能。",
        "sentence_B": "我们可以通过调整卷积层的参数来优化模型的性能。",
        "id": 1287,
        "target_term": "convolution",
        "is_hardcore": true
    },
    {
        "topic": "Convolutional Neural Networks",
        "prefix": "在讨论模型优化的会议上，团队成员提到卷积层的重要性。",
        "sentence_A": "在优化模型的时候，我们发现 convolutional 层的参数对性能提升特别关键。",
        "sentence_B": "在优化模型的时候，我们发现卷积层的参数对性能提升特别关键。",
        "id": 1288,
        "target_term": "convolutional",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论多GPU训练时",
        "sentence_A": "我们需要确保各个GPU之间的 coordination 是高效的，这样才能最大化训练速度。",
        "sentence_B": "我们需要确保各个GPU之间的协调是高效的，这样才能最大化训练速度。",
        "id": 1289,
        "target_term": "GPU",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论数据集的选择和处理",
        "sentence_A": "我们在训练模型时，需要从多个 corpora 中选择合适的数据集。",
        "sentence_B": "我们在训练模型时，需要从多个语料库中选择合适的数据集。",
        "id": 1290,
        "target_term": "corpora",
        "is_hardcore": true
    },
    {
        "topic": "Data Preparation",
        "prefix": "在进行模型训练前，团队讨论数据集的准备情况。",
        "sentence_A": "我们在准备训练模型的 corpus 时，需要确保数据的多样性和质量。",
        "sentence_B": "我们在准备训练模型的语料库时，需要确保数据的多样性和质量。",
        "id": 1291,
        "target_term": "corpus",
        "is_hardcore": true
    },
    {
        "topic": "Data Analysis and Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段，团队成员提到了特征之间的关系。",
        "sentence_A": "在数据预处理阶段，我们需要检查特征之间的 correlation，确保没有高度相关的特征导致模型过拟合。",
        "sentence_B": "在数据预处理阶段，我们需要检查特征之间的相关性，确保没有高度相关的特征导致模型过拟合。",
        "id": 1292,
        "target_term": "correlation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源消耗时",
        "sentence_A": "这次的模型训练真的太 costly 了，计算资源的开销简直让人头疼。",
        "sentence_B": "这次的模型训练真的太昂贵了，计算资源的开销简直让人头疼。",
        "id": 1293,
        "target_term": "costly",
        "is_hardcore": true
    },
    {
        "topic": "Counterfactual Reasoning in AI",
        "prefix": "在讨论模型的解释性时，团队成员提出了一个关于反事实推理的问题。",
        "sentence_A": "我们在讨论模型的解释性时，提到了 counterfactual 例子，这有助于我们理解模型的决策过程。",
        "sentence_B": "我们在讨论模型的解释性时，提到了反事实例子，这有助于我们理解模型的决策过程。",
        "id": 1294,
        "target_term": "counterfactual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化时，团队成员提到模型组件之间的耦合问题。",
        "sentence_A": "在模型训练过程中，我们发现模块之间的 coupling 太高，导致优化难度增加。",
        "sentence_B": "在模型训练过程中，我们发现模块之间的耦合度过高，导致优化难度增加。",
        "id": 1295,
        "target_term": "coupling",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，我们讨论了模型的覆盖范围和性能。",
        "sentence_A": "我们在评估模型时，不仅要关注 accuracy，还要看 model 的 coverage，确保它在各种场景下都能有好的表现。",
        "sentence_B": "我们在评估模型时，不仅要关注准确率，还要看模型的覆盖率，确保它在各种场景下都能有好的表现。",
        "id": 1296,
        "target_term": "accuracy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了一个关键问题。",
        "sentence_A": "在训练过程中，我们发现数据预处理的这一步是 critical 的，必须确保没有错误。",
        "sentence_B": "在训练过程中，我们发现数据预处理的这一步是关键的，必须确保没有错误。",
        "id": 1297,
        "target_term": "critical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，工程师们经常提到特征交叉的问题。",
        "sentence_A": "我们在模型训练中使用了 cross 特征，这样可以更好地捕捉不同特征之间的交互效应。",
        "sentence_B": "我们在模型训练中使用了交叉特征，这样可以更好地捕捉不同特征之间的交互效应。",
        "id": 1298,
        "target_term": "cross",
        "is_hardcore": true
    },
    {
        "topic": "Genetic Algorithm in Model Training",
        "prefix": "在讨论遗传算法优化模型训练时，团队成员提到交叉操作的重要性。",
        "sentence_A": "在训练模型时，我们可以通过引入 crossover 来增加遗传算法的多样性。",
        "sentence_B": "在训练模型时，我们可以通过引入交叉操作来增加遗传算法的多样性。",
        "id": 1299,
        "target_term": "crossover",
        "is_hardcore": true
    },
    {
        "topic": "CUDA in Model Training",
        "prefix": "在讨论模型训练的优化时",
        "sentence_A": "我们可以通过使用 cuda 来加速模型的训练过程，这样可以大大减少训练时间。",
        "sentence_B": "我们可以通过使用 CUDA 来加速模型的训练过程，这样可以大大减少训练时间。",
        "id": 1300,
        "target_term": "cuda",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过调整每个 training cycle 的参数来提高模型的收敛速度。",
        "sentence_B": "我们可以通过调整每个训练周期的参数来提高模型的收敛速度。",
        "id": 1301,
        "target_term": "training cycle",
        "is_hardcore": true
    },
    {
        "topic": "Matrix Decomposition in Model Training",
        "prefix": "在讨论模型训练的优化方法时，团队成员提到了矩阵分解技术。",
        "sentence_A": "我们可以利用 matrix decomposition 技术来优化模型的训练速度和精度。",
        "sentence_B": "我们可以利用矩阵分解技术来优化模型的训练速度和精度。",
        "id": 1302,
        "target_term": "matrix decomposition",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化时",
        "sentence_A": "在设计系统的架构时，我们通过 decoupling 不同的模块来提高系统的可维护性和扩展性。",
        "sentence_B": "在设计系统的架构时，我们通过解耦不同的模块来提高系统的可维护性和扩展性。",
        "id": 1303,
        "target_term": "decoupling",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一些问题。",
        "sentence_A": "在模型训练过程中，我们发现了一些 defect，需要进一步排查。",
        "sentence_B": "在模型训练过程中，我们发现了一些缺陷，需要进一步排查。",
        "id": 1304,
        "target_term": "defect",
        "is_hardcore": true
    },
    {
        "topic": "Object Detection",
        "prefix": "在模型训练过程中，我们遇到了一个常见的问题。",
        "sentence_A": "我们在训练模型时，发现目标检测的精度提升遇到了瓶颈。",
        "sentence_B": "我们在训练模型时，发现目标检测的精度提升遇到了瓶颈。",
        "id": 1305,
        "term_cleaned": "N/A",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性和可重复性时",
        "sentence_A": "我们在训练模型时需要注意 determinism，确保每次运行的结果都是一致的。",
        "sentence_B": "我们在训练模型时需要注意确定性，确保每次运行的结果都是一致的。",
        "id": 1306,
        "target_term": "determinism",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在调整模型的 hidden dimension 时，要注意不要设置得太大，否则会导致过拟合。",
        "sentence_B": "我们在调整模型的隐藏层维度时，要注意不要设置得太大，否则会导致过拟合。",
        "id": 1307,
        "target_term": "hidden dimension",
        "is_hardcore": true
    },
    {
        "topic": "Dimensionality Reduction",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在处理高 dimensionality 的数据时，经常会遇到过拟合的问题，所以需要进行降维处理。",
        "sentence_B": "我们在处理高维度的数据时，经常会遇到过拟合的问题，所以需要进行降维处理。",
        "id": 1308,
        "target_term": "dimensionality",
        "is_hardcore": true
    },
    {
        "topic": "Discrete Variables in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了离散变量的处理方法。",
        "sentence_A": "在训练这个模型时，我们需要特别关注那些 discrete 变量的处理，因为它们可能会影响模型的性能。",
        "sentence_B": "在训练这个模型时，我们需要特别关注那些离散变量的处理，因为它们可能会影响模型的性能。",
        "id": 1309,
        "target_term": "discrete",
        "is_hardcore": true
    },
    {
        "topic": "GAN Training",
        "prefix": "在讨论生成对抗网络（GAN）训练时，同事们提到判别器的重要性。",
        "sentence_A": "在训练 GAN 的时候，discriminator 的性能对整个模型的影响非常大，所以我们需要特别关注它的优化。",
        "sentence_B": "在训练生成对抗网络（GAN）时，判别器的性能对整个模型的影响非常大，所以我们需要特别关注它的优化。",
        "id": 1310,
        "target_term": "GAN",
        "is_hardcore": true
    },
    {
        "topic": "Distance Calculation in Machine Learning",
        "prefix": "在模型训练过程中，我们经常需要计算不同数据点之间的距离。",
        "sentence_A": "在训练这个模型时，我们发现计算数据点之间的 distance 对性能影响很大。",
        "sentence_B": "在训练这个模型时，我们发现计算数据点之间的距离对性能影响很大。",
        "id": 1311,
        "target_term": "distance",
        "is_hardcore": true
    },
    {
        "topic": "Data Distribution",
        "prefix": "在讨论模型训练数据集的分布问题时",
        "sentence_A": "我们需要确保训练数据的 distribution 能够反映真实场景中的数据分布，否则模型在实际应用中可能会出现性能下降。",
        "sentence_B": "我们需要确保训练数据的分布能够反映真实场景中的数据分布，否则模型在实际应用中可能会出现性能下降。",
        "id": 1312,
        "target_term": "distribution",
        "is_hardcore": true
    },
    {
        "topic": "Data Distributions in Model Training",
        "prefix": "在讨论模型训练数据的分布时",
        "sentence_A": "我们在训练模型时，需要特别关注数据的 distribution，确保它们在不同批次之间保持一致。",
        "sentence_B": "我们在训练模型时，需要特别关注数据的分布，确保它们在不同批次之间保持一致。",
        "id": 1313,
        "target_term": "distribution",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的构建时，团队成员提到数据的多样性问题。",
        "sentence_A": "我们在构建训练数据集时，必须确保数据的 diversity，这样才能提高模型的泛化能力。",
        "sentence_B": "我们在构建训练数据集时，必须确保数据的多样性，这样才能提高模型的泛化能力。",
        "id": 1314,
        "target_term": "diversity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在选择训练数据时，需要确保数据覆盖了不同的 domain，这样才能让模型更加通用。",
        "sentence_B": "我们在选择训练数据时，需要确保数据覆盖了不同的领域，这样才能让模型更加通用。",
        "id": 1315,
        "target_term": "domain",
        "is_hardcore": true
    },
    {
        "topic": "Dropout in Neural Networks",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练这个模型时，使用了 dropout 技术来防止过拟合。",
        "sentence_B": "我们在训练这个模型时，使用了丢弃法来防止过拟合。",
        "id": 1316,
        "target_term": "dropout",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在训练过程中引入了 dual 模型，这样可以更好地处理数据的多模态特性。",
        "sentence_B": "我们在训练过程中引入了双模型，这样可以更好地处理数据的多模态特性。",
        "id": 1317,
        "target_term": "dual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练这个模型时，需要考虑使用 dynamic batch size 来优化性能。",
        "sentence_B": "我们在训练这个模型时，需要考虑使用动态批次大小来优化性能。",
        "id": 1318,
        "target_term": "dynamic batch size",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练效率的会议上",
        "sentence_A": "我们在模型训练过程中需要注意利用好 economie，这样才能在资源有限的情况下提高训练效率。",
        "sentence_B": "我们在模型训练过程中需要注意利用好经济效应，这样才能在资源有限的情况下提高训练效率。",
        "id": 1319,
        "target_term": "economie",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在进行数据清洗时，团队讨论如何处理数据中的异常值。",
        "sentence_A": "我们在讨论如何处理数据集中的异常 element，特别是那些明显偏离正常范围的值。",
        "sentence_B": "我们在讨论如何处理数据集中的异常元素，特别是那些明显偏离正常范围的值。",
        "id": 1320,
        "target_term": "element",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行模型训练前的数据清洗过程中，我们讨论了如何处理数据集中的各个部分。",
        "sentence_A": "在数据清洗过程中，我们需要特别注意处理这些 data element，确保每个 element 都是干净且一致的。",
        "sentence_B": "在数据清洗过程中，我们需要特别注意处理这些数据元素，确保每个数据元素都是干净且一致的。",
        "id": 1321,
        "target_term": "data element",
        "is_hardcore": true
    },
    {
        "topic": "Embedding in Model Training",
        "prefix": "在模型训练过程中，我们需要处理大量的文本数据。",
        "sentence_A": "为了提高模型的性能，我们通常会先将文本数据转换为 embedding，再输入到神经网络中。",
        "sentence_B": "为了提高模型的性能，我们通常会先将文本数据转换为嵌入向量，再输入到神经网络中。",
        "id": 1322,
        "target_term": "embedding",
        "is_hardcore": true
    },
    {
        "topic": "Embeddings in Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们这次在训练模型时，发现使用更高质量的 embedding 可以显著提升模型的性能。",
        "sentence_B": "我们在训练模型时发现，使用更高质量的嵌入可以显著提升模型的性能。",
        "id": 1323,
        "target_term": "embedding",
        "is_hardcore": true
    },
    {
        "topic": "Encoder in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了encoder的作用。",
        "sentence_A": "我们在训练这个模型时，发现 encoder 的表现对整体性能影响很大。",
        "sentence_B": "我们在训练这个模型时，发现编码器的表现对整体性能影响很大。",
        "id": 1324,
        "target_term": "encoder",
        "is_hardcore": true
    },
    {
        "topic": "Data Security",
        "prefix": "在讨论数据安全时，团队成员提到数据传输的安全性。",
        "sentence_A": "在训练模型时，我们使用了 SSL 进行数据传输的 encryption，确保数据在传输过程中的安全。",
        "sentence_B": "在训练模型时，我们使用了 SSL 进行数据传输的加密，确保数据在传输过程中的安全。",
        "id": 1325,
        "target_term": "SSL",
        "is_hardcore": true
    },
    {
        "topic": "Ensemble Learning",
        "prefix": "在模型训练过程中，团队讨论如何提高模型的鲁棒性和准确性。",
        "sentence_A": "我们在训练模型时，考虑使用 ensemble 方法来提高模型的鲁棒性和准确性。",
        "sentence_B": "我们在训练模型时，考虑使用集成方法来提高模型的鲁棒性和准确性。",
        "id": 1326,
        "target_term": "ensemble",
        "is_hardcore": true
    },
    {
        "topic": "Entropy in Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员提到熵的概念。",
        "sentence_A": "在训练分类模型时，我们需要关注 entropy，它能帮助我们评估模型的不确定性。",
        "sentence_B": "在训练分类模型时，我们需要关注熵，它能帮助我们评估模型的不确定性。",
        "id": 1327,
        "target_term": "entropy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training Environment",
        "prefix": "在讨论模型训练的配置时",
        "sentence_A": "我们需要确保在不同的 environment 下模型的性能一致。",
        "sentence_B": "我们需要确保在不同的环境中模型的性能一致。",
        "id": 1328,
        "target_term": "environment",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的公平性问题时，团队成员提到",
        "sentence_A": "我们在设计模型时需要确保训练数据是 equitable 的，这样才能避免偏见。",
        "sentence_B": "我们在设计模型时需要确保训练数据是公平的，这样才能避免偏见。",
        "id": 1329,
        "target_term": "equitable",
        "is_hardcore": true
    },
    {
        "topic": "Equivariant Properties in Neural Networks",
        "prefix": "在讨论模型的对称性时",
        "sentence_A": "我们在模型训练中发现，使用 equivariant 层可以显著提高模型对输入变换的鲁棒性。",
        "sentence_B": "我们在模型训练中发现，使用等变层可以显著提高模型对输入变换的鲁棒性。",
        "id": 1330,
        "target_term": "equivariant",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们遇到了一些问题。",
        "sentence_A": "在训练最新的模型时，我们发现了一些 error，需要进一步排查。",
        "sentence_B": "在训练最新的模型时，我们发现了一些错误，需要进一步排查。",
        "id": 1331,
        "target_term": "error",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的性能优化时",
        "sentence_A": "我们这次的模型训练中，estimation 的精度提升了不少，但还需要进一步优化。",
        "sentence_B": "我们这次的模型训练中，估计的精度提升了不少，但还需要进一步优化。",
        "id": 1332,
        "target_term": "estimation",
        "is_hardcore": true
    },
    {
        "topic": "Estimator in Model Training",
        "prefix": "在模型训练过程中，团队正在讨论如何选择合适的评估器来优化模型性能。",
        "sentence_A": "我们在模型训练中使用了不同的 estimator，发现某些 estimator 在处理大规模数据时表现更好。",
        "sentence_B": "我们在模型训练中使用了不同的评估器，发现某些评估器在处理大规模数据时表现更好。",
        "id": 1333,
        "target_term": "estimator",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练的最后阶段，我们通常会进行一系列的评估来确保模型的性能。",
        "sentence_A": "在模型训练的最后阶段，我们通常会进行一系列的 evaluation 来确保模型的性能。",
        "sentence_B": "在模型训练的最后阶段，我们通常会进行一系列的评估来确保模型的性能。",
        "id": 1334,
        "target_term": "evaluation",
        "is_hardcore": true
    },
    {
        "topic": "Model Evolution",
        "prefix": "在讨论模型优化的过程中，团队成员提到了模型的演化过程。",
        "sentence_A": "在模型训练的过程中，我们注意到模型的 evolution 非常重要，它可以帮助我们更好地适应新的数据和任务。",
        "sentence_B": "在模型训练的过程中，我们注意到模型的演化过程非常重要，它可以帮助我们更好地适应新的数据和任务。",
        "id": 1335,
        "target_term": "evolution",
        "is_hardcore": true
    },
    {
        "topic": "Evolutionary Algorithms in Model Training",
        "prefix": "在讨论如何优化模型训练过程时，团队成员提出了一个基于进化算法的新方案。",
        "sentence_A": "我们可以通过引入 evolutionary 算法来优化模型的训练过程，这样可以在更短的时间内找到更优的模型参数。",
        "sentence_B": "我们可以通过引入进化算法来优化模型的训练过程，这样可以在更短的时间内找到更优的模型参数。",
        "id": 1336,
        "target_term": "evolutionary",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练流程时",
        "sentence_A": "我们这次的训练 pipeline 需要优化 execution 的效率，特别是在大规模数据集上。",
        "sentence_B": "我们这次的训练流程需要优化执行的效率，特别是在大规模数据集上。",
        "id": 1337,
        "target_term": "pipeline",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Evaluation",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们在进行模型训练时，需要更多的 experimentation 来找到最佳的超参数组合。",
        "sentence_B": "我们在进行模型训练时，需要更多的实验来找到最佳的超参数组合。",
        "id": 1338,
        "target_term": "experimentation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们可能需要找一个 expert 来优化这个参数，现在的效果还不够理想。",
        "sentence_B": "我们可能需要找一个专家来优化这个参数，现在的效果还不够理想。",
        "id": 1339,
        "target_term": "expert",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretability",
        "prefix": "在模型训练过程中，团队讨论如何提高模型的可解释性。",
        "sentence_A": "我们在模型训练中需要更多地关注 explanation，这样才能更好地理解模型的决策过程。",
        "sentence_B": "我们在模型训练中需要更多地关注可解释性，这样才能更好地理解模型的决策过程。",
        "id": 1340,
        "target_term": "explanation",
        "is_hardcore": true
    },
    {
        "topic": "Exploration in Reinforcement Learning",
        "prefix": "在讨论如何优化强化学习算法的探索策略时",
        "sentence_A": "我们在训练模型时，需要平衡好 exploitation 和 exploration，这样才能更好地找到最优策略。",
        "sentence_B": "我们在训练模型时，需要平衡好利用（exploitation）和探索（exploration），这样才能更好地找到最优策略。",
        "id": 1341,
        "target_term": "exploitation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理各种表达式。",
        "sentence_A": "在训练模型时，我们需要注意处理各种 expression，特别是那些复杂的数学表达式。",
        "sentence_B": "在训练模型时，我们需要注意处理各种表达式，特别是那些复杂的数学表达式。",
        "id": 1342,
        "target_term": "expression",
        "is_hardcore": true
    },
    {
        "topic": "Data Extraction",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "我们需要确保数据的 extraction 过程是高效且准确的，这样才能保证模型训练的质量。",
        "sentence_B": "我们需要确保数据的提取过程是高效且准确的，这样才能保证模型训练的质量。",
        "id": 1343,
        "target_term": "extraction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员讨论了特征选择的重要性。",
        "sentence_A": "我们在训练模型时，一定要注意挑选合适的 feature，这样才能提高模型的准确率。",
        "sentence_B": "我们在训练模型时，一定要注意挑选合适的特征，这样才能提高模型的准确率。",
        "id": 1344,
        "target_term": "feature",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到了用户反馈的重要性。",
        "sentence_A": "在模型训练阶段，我们特别重视用户的 feedback，它能帮助我们及时调整模型参数，提高模型的准确性和用户满意度。",
        "sentence_B": "在模型训练阶段，我们特别重视用户的反馈，它能帮助我们及时调整模型参数，提高模型的准确性和用户满意度。",
        "id": 1345,
        "target_term": "feedback",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在模型训练数据准备阶段，我们讨论如何处理噪声数据。",
        "sentence_A": "在数据预处理阶段，我们使用了 filtering 技术来去除噪声数据，确保模型训练的准确性。",
        "sentence_B": "在数据预处理阶段，我们使用了过滤技术来去除噪声数据，确保模型训练的准确性。",
        "id": 1346,
        "target_term": "filtering",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论卷积神经网络的架构设计时",
        "sentence_A": "我们需要在卷积层中使用不同的 filter 来提取特征。",
        "sentence_B": "我们需要在卷积层中使用不同的滤波器来提取特征。",
        "id": 1347,
        "target_term": "filter",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们讨论了如何处理金融数据中的异常值。",
        "sentence_A": "在数据清洗阶段，我们讨论了如何处理 financial 数据中的异常值，确保模型训练的准确性。",
        "sentence_B": "在数据清洗阶段，我们讨论了如何处理金融数据中的异常值，确保模型训练的准确性。",
        "id": 1348,
        "target_term": "financial",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的策略时，团队成员提到了模型的灵活性。",
        "sentence_A": "在设计模型的时候，我们一定要考虑到 model 的 flexibility，这样才能更好地应对不同的数据集和应用场景。",
        "sentence_B": "在设计模型的时候，我们一定要考虑到模型的灵活性，这样才能更好地应对不同的数据集和应用场景。",
        "id": 1349,
        "target_term": "model",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型优化时",
        "sentence_A": "我们在优化模型的时候，需要特别关注计算资源的使用，比如 flop 和内存占用。",
        "sentence_B": "在优化模型时，我们需要注意计算资源的使用，例如浮点运算次数（FLOPS）和内存占用。",
        "id": 1350,
        "target_term": "flop",
        "is_hardcore": true
    },
    {
        "topic": "Data Flow Optimization",
        "prefix": "在讨论模型训练数据流优化的过程中",
        "sentence_A": "我们需要优化 data flow，确保数据传输的高效性和稳定性。",
        "sentence_B": "我们需要优化数据流，确保数据传输的高效性和稳定性。",
        "id": 1351,
        "target_term": "data flow",
        "is_hardcore": true
    },
    {
        "topic": "Time Series Analysis",
        "prefix": "在一次模型训练的会议中，讨论如何优化时间序列预测模型的性能。",
        "sentence_A": "我们在最新的模型训练中，采用了更先进的方法进行 forecasting，效果提升很明显。",
        "sentence_B": "我们在最新的模型训练中，采用了更先进的方法进行时间序列预测，效果提升很明显。",
        "id": 1352,
        "target_term": "forecasting",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数选择时",
        "sentence_A": "我们这次用的 loss function 是比较 formal 的交叉熵损失，这样模型的收敛会更稳定。",
        "sentence_B": "我们这次使用的损失函数是比较正式的交叉熵损失，这样模型的收敛会更稳定。",
        "id": 1353,
        "target_term": "loss function",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的基础架构时",
        "sentence_A": "我们在设计模型的 foundation 时，要确保它能够支持大规模的并行训练和高效的资源管理。",
        "sentence_B": "我们在设计模型的基础架构时，要确保它能够支持大规模的并行训练和高效的资源管理。",
        "id": 1354,
        "target_term": "foundation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在设置参数的时候，需要特别注意 learning rate 的 frequency，这直接影响到模型的收敛速度。",
        "sentence_B": "我们在设置参数的时候，需要特别注意学习率的频率，这直接影响到模型的收敛速度。",
        "id": 1355,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到函数的重要性。",
        "sentence_A": "在训练模型时，我们需要确保每个 function 都能高效运行，这样才能保证整体的性能。",
        "sentence_B": "在训练模型时，我们需要确保每个函数都能高效运行，这样才能保证整体的性能。",
        "id": 1356,
        "target_term": "function",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练优化的会议上，团队正在探讨如何提高模型的性能。",
        "sentence_A": "我们在训练模型时，可以考虑使用 fusion 技术来整合多模态信息，这样可以显著提升模型的鲁棒性和准确性。",
        "sentence_B": "我们在训练模型时，可以考虑使用融合技术来整合多模态信息，这样可以显著提升模型的鲁棒性和准确性。",
        "id": 1357,
        "target_term": "fusion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在调整超参数时，发现通过增加学习率可以显著提高模型的 gain。",
        "sentence_B": "我们在调整超参数时，发现通过增加学习率可以显著提高模型的增益。",
        "id": 1358,
        "target_term": "gain",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型训练的效率时",
        "sentence_A": "我们在训练模型时，发现使用不同的 game 策略可以显著提高训练速度。",
        "sentence_B": "我们在训练模型时，发现使用不同的博弈策略可以显著提高训练速度。",
        "id": 1359,
        "target_term": "game",
        "is_hardcore": false
    },
    {
        "topic": "Gaze Estimation",
        "prefix": "在模型训练的讨论中",
        "sentence_A": "我们在训练 gaze 估计模型时，发现数据集中的标注有些不一致。",
        "sentence_B": "我们在训练注视点估计模型时，发现数据集中的标注有些不一致。",
        "id": 1360,
        "target_term": "gaze",
        "is_hardcore": true
    },
    {
        "topic": "Model Generalization",
        "prefix": "在模型训练过程中，我们经常讨论模型的泛化能力。",
        "sentence_A": "我们在训练模型时，不仅要关注训练集上的表现，还要确保模型有好的 generalization 能力，这样才能在实际应用中表现稳定。",
        "sentence_B": "我们在训练模型时，不仅要关注训练集上的表现，还要确保模型有好的泛化能力，这样才能在实际应用中表现稳定。",
        "id": 1361,
        "target_term": "generalization",
        "is_hardcore": true
    },
    {
        "topic": "Text Generation",
        "prefix": "在讨论模型训练时，团队成员提到生成模型的性能问题。",
        "sentence_A": "我们在最新的模型训练中，发现 generation 的效果比预期的要好，尤其是在处理长文本时。",
        "sentence_B": "我们在最新的模型训练中，发现生成效果比预期的要好，尤其是在处理长文本时。",
        "id": 1362,
        "target_term": "generation",
        "is_hardcore": true
    },
    {
        "topic": "Generative Models",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练这个模型时，使用了最新的 generative 技术，效果非常不错。",
        "sentence_B": "我们在训练这个模型时，使用了最新的生成技术，效果非常不错。",
        "id": 1363,
        "target_term": "generative",
        "is_hardcore": true
    },
    {
        "topic": "Genetic Algorithms in Model Training",
        "prefix": "在讨论模型训练方法时",
        "sentence_A": "我们这次可以试试用 genetic 算法来优化模型的超参数，看看效果如何。",
        "sentence_B": "我们可以尝试使用遗传算法来优化模型的超参数，看看效果如何。",
        "id": 1364,
        "target_term": "genetic",
        "is_hardcore": true
    },
    {
        "topic": "Geometry in AI Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化模型的输入数据。",
        "sentence_A": "我们在处理 3D 模型时，需要特别注意 geometry 的精度，这直接影响到模型的训练效果。",
        "sentence_B": "我们在处理 3D 模型时，需要特别注意几何精度，这直接影响到模型的训练效果。",
        "id": 1365,
        "target_term": "3D",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在设置参数的时候，需要考虑 global 参数的优化，这样才能确保模型在不同环境下的表现一致性。",
        "sentence_B": "我们在设置参数的时候，需要考虑全局参数的优化，这样才能确保模型在不同环境下的表现一致性。",
        "id": 1366,
        "target_term": "global",
        "is_hardcore": true
    },
    {
        "topic": "Gradient Descent",
        "prefix": "在模型训练过程中，我们经常需要讨论梯度的计算和更新。",
        "sentence_A": "在训练这个模型时，我们发现计算 gradient 的效率很低，需要优化一下。",
        "sentence_B": "在训练这个模型时，我们发现计算梯度的效率很低，需要优化一下。",
        "id": 1367,
        "target_term": "gradient",
        "is_hardcore": true
    },
    {
        "topic": "Gradient Descent",
        "prefix": "在模型训练过程中，我们经常需要调整学习率以优化梯度下降过程。",
        "sentence_A": "在训练过程中，我们需要密切关注 gradient，确保它们不会导致模型过拟合或欠拟合。",
        "sentence_B": "在训练过程中，我们需要密切关注梯度，确保它们不会导致模型过拟合或欠拟合。",
        "id": 1368,
        "target_term": "gradient",
        "is_hardcore": true
    },
    {
        "topic": "NLP Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何处理输入文本的语法问题。",
        "sentence_A": "在处理输入文本时，我们发现模型对 complex grammar 的处理效果不佳，需要进一步优化。",
        "sentence_B": "在处理输入文本时，我们发现模型对复杂语法的处理效果不佳，需要进一步优化。",
        "id": 1369,
        "target_term": "complex grammar",
        "is_hardcore": true
    },
    {
        "topic": "NLP Model Training",
        "prefix": "在模型训练过程中，我们遇到了一些文本数据的问题。",
        "sentence_A": "我们在处理数据时发现有些句子的 grammatical 结构有问题，需要进一步清洗。",
        "sentence_B": "我们在处理数据时发现有些句子的语法结构有问题，需要进一步清洗。",
        "id": 1370,
        "target_term": "grammatical",
        "is_hardcore": true
    },
    {
        "topic": "Graph Representation",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们可以通过优化 graph 的结构来提高模型的训练效率。",
        "sentence_B": "我们可以通过优化图的结构来提高模型的训练效率。",
        "id": 1371,
        "target_term": "graph",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论如何提高模型的鲁棒性。",
        "sentence_A": "为了提高模型的鲁棒性，我们需要更好地处理 grounding 问题，确保模型在不同场景下的表现一致。",
        "sentence_B": "为了提高模型的鲁棒性，我们需要更好地处理对齐问题，确保模型在不同场景下的表现一致。",
        "id": 1372,
        "target_term": "grounding",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化时，团队成员提到硬件配置的重要性。",
        "sentence_A": "我们这次的模型训练对 hardware 要求比较高，得确保 GPU 和内存都足够。",
        "sentence_B": "我们这次的模型训练对硬件要求比较高，得确保 GPU 和内存都足够。",
        "id": 1373,
        "target_term": "hardware",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型架构设计时",
        "sentence_A": "我们在设计模型的时候需要考虑到数据的 hierarchy，这样才能更好地捕捉到深层次的特征。",
        "sentence_B": "在设计模型时，我们需要考虑到数据的层次结构，这样才能更好地捕捉到深层次的特征。",
        "id": 1374,
        "target_term": "hierarchy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到数据的历史记录对模型性能的影响。",
        "sentence_A": "在训练这个模型时，我们发现 old data 的 history 对结果影响很大，需要特别注意。",
        "sentence_B": "在训练这个模型时，我们发现旧数据的历史记录对结果影响很大，需要特别注意。",
        "id": 1375,
        "target_term": "old data",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们讨论了数据集的一致性问题。",
        "sentence_A": "在数据清洗的时候，我们发现数据集的 homogeneity 很重要，不一致的数据会严重影响模型的训练效果。",
        "sentence_B": "在数据清洗的时候，我们发现数据集的一致性很重要，不一致的数据会严重影响模型的训练效果。",
        "id": 1376,
        "target_term": "homogeneity",
        "is_hardcore": true
    },
    {
        "topic": "Hyperparameter Optimization",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们可以通过调整 hyper 参数来优化模型的性能。",
        "sentence_B": "我们可以通过调整超参数来优化模型的性能。",
        "id": 1377,
        "target_term": "hyper",
        "is_hardcore": true
    },
    {
        "topic": "Hyperparameter Tuning",
        "prefix": "在模型训练过程中，团队正在讨论如何优化模型性能。",
        "sentence_A": "我们在调整 hyperparameter 的时候，一定要小心，因为这直接影响到模型的性能。",
        "sentence_B": "我们在调整超参数的时候，一定要小心，因为这直接影响到模型的性能。",
        "id": 1378,
        "target_term": "hyperparameter",
        "is_hardcore": true
    },
    {
        "topic": "Hyperparameter Tuning",
        "prefix": "在模型训练过程中，团队讨论如何优化模型性能。",
        "sentence_A": "我们这次模型训练的 hyperparameter 需要再调整一下，可能会影响最终的准确性。",
        "sentence_B": "我们这次模型训练的超参数需要再调整一下，可能会影响最终的准确性。",
        "id": 1379,
        "target_term": "hyperparameter",
        "is_hardcore": true
    },
    {
        "topic": "Image Processing in AI",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们在预处理阶段需要确保每张 image 都经过了标准化处理，这样才能提高模型的泛化能力。",
        "sentence_B": "我们在预处理阶段需要确保每张图像都经过了标准化处理，这样才能提高模型的泛化能力。",
        "id": 1380,
        "target_term": "image",
        "is_hardcore": false
    },
    {
        "topic": "Imaging in AI Model Training",
        "prefix": "在讨论如何优化医学影像数据的处理流程时",
        "sentence_A": "我们在处理 medical imaging 数据时，需要特别注意数据的预处理和标注质量。",
        "sentence_B": "我们在处理医学影像数据时，需要特别注意数据的预处理和标注质量。",
        "id": 1381,
        "target_term": "medical imaging",
        "is_hardcore": true
    },
    {
        "topic": "Data Imbalance in Model Training",
        "prefix": "在讨论模型训练数据集的问题时，团队成员提到了数据不平衡的问题。",
        "sentence_A": "我们在处理这个数据集的时候，发现了一个明显的 class imbalance 问题，需要调整样本权重。",
        "sentence_B": "我们在处理这个数据集的时候，发现了一个明显的数据不平衡问题，需要调整样本权重。",
        "id": 1382,
        "target_term": "class imbalance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到了一个重要的概念。",
        "sentence_A": "在训练这个模型时，我们需要注意数据的分布变化对模型性能的 implication。",
        "sentence_B": "在训练这个模型时，我们需要注意数据的分布变化对模型性能的影响。",
        "id": 1383,
        "target_term": "implication",
        "is_hardcore": true
    },
    {
        "topic": "Feature Selection",
        "prefix": "在模型训练过程中，我们常常需要评估特征的重要性。",
        "sentence_A": "在训练模型时，我们通常会计算每个特征的 importance，以确定哪些特征对模型的预测效果影响最大。",
        "sentence_B": "在训练模型时，我们通常会计算每个特征的重要度，以确定哪些特征对模型的预测效果影响最大。",
        "id": 1384,
        "target_term": "importance",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在讨论数据清洗的过程中，团队成员提到一个常见的问题。",
        "sentence_A": "我们最近在处理数据时，发现很多缺失值，用 imputation 方法填补这些空值是很关键的。",
        "sentence_B": "我们最近在处理数据时，发现很多缺失值，使用插补方法填补这些空值是很关键的。",
        "id": 1385,
        "target_term": "imputation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的激励机制时",
        "sentence_A": "我们在设计模型训练的激励机制时，需要确保每个参与者的 incentive 都能最大化，这样才能提高整体的训练效率。",
        "sentence_B": "我们在设计模型训练的激励机制时，需要确保每个参与者的激励都能最大化，这样才能提高整体的训练效率。",
        "id": 1386,
        "target_term": "incentive",
        "is_hardcore": true
    },
    {
        "topic": "Feature Engineering",
        "prefix": "在讨论特征工程时，团队成员提到特征之间的独立性问题。",
        "sentence_A": "我们在处理特征时，要确保每个特征之间的 independence，这样才能避免模型的性能受到冗余特征的影响。",
        "sentence_B": "我们在处理特征时，要确保每个特征之间的独立性，这样才能避免模型的性能受到冗余特征的影响。",
        "id": 1387,
        "target_term": "independence",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型部署时，团队成员提到了推理优化的问题。",
        "sentence_A": "我们在优化模型的 inference 时间时，发现了一些瓶颈。",
        "sentence_B": "我们在优化模型的推理时间时，发现了一些瓶颈。",
        "id": 1388,
        "target_term": "inference",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到了一个关键参数对模型性能的影响。",
        "sentence_A": "这个参数的调整对模型的 performance 有显著的 influence，我们需要仔细评估。",
        "sentence_B": "这个参数的调整对模型的性能有显著的影响，我们需要仔细评估。",
        "id": 1389,
        "target_term": "performance",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们发现了一个重要的问题",
        "sentence_A": "在数据清洗阶段，我们发现了一个重要的问题，很多记录的 information 字段是缺失的。",
        "sentence_B": "在数据清洗阶段，我们发现了一个重要的问题，很多记录的信息字段是缺失的。",
        "id": 1390,
        "target_term": "information",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的初期阶段时",
        "sentence_A": "我们在模型训练的初期阶段，需要特别关注参数的 initialization，这一步对模型的收敛速度和最终性能影响很大。",
        "sentence_B": "我们在模型训练的初期阶段，需要特别关注参数的初始化，这一步对模型的收敛速度和最终性能影响很大。",
        "id": 1391,
        "target_term": "initialization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据处理阶段时",
        "sentence_A": "我们这次的模型训练，需要特别注意 input 的预处理，确保数据的干净和一致性。",
        "sentence_B": "我们这次的模型训练，需要特别注意输入的预处理，确保数据的干净和一致性。",
        "id": 1392,
        "target_term": "input",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化时",
        "sentence_A": "我们可以通过优化 instruction 的格式来提高模型的响应速度。",
        "sentence_B": "我们可以通过优化指令的格式来提高模型的响应速度。",
        "id": 1393,
        "target_term": "instruction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们需要确保模型能够正确理解输入的指令。",
        "sentence_A": "为了确保模型能正确理解输入的 instruction，我们需要对数据进行预处理，确保每条指令的格式和内容都符合要求。",
        "sentence_B": "为了确保模型能正确理解输入的指令，我们需要对数据进行预处理，确保每条指令的格式和内容都符合要求。",
        "id": 1394,
        "target_term": "instruction",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论如何将新训练的模型集成到现有系统中时",
        "sentence_A": "我们在讨论如何将新训练的模型的 integration 做好，确保线上服务的稳定性。",
        "sentence_B": "我们在讨论如何将新训练的模型的集成做好，确保线上服务的稳定性。",
        "id": 1395,
        "target_term": "integration",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练模型时，需要确保模型的 intelligence 能够有效处理各种复杂场景。",
        "sentence_B": "我们在训练模型时，需要确保模型的智能能够有效处理各种复杂场景。",
        "id": 1396,
        "target_term": "intelligence",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论如何优化模型的智能水平",
        "sentence_A": "我们在模型训练中使用了一些 intelligent 的技术，比如自适应学习率和动态调整权重。",
        "sentence_B": "我们在模型训练中使用了一些智能的技术，比如自适应学习率和动态调整权重。",
        "id": 1397,
        "target_term": "intelligent",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到用户交互数据的重要性。",
        "sentence_A": "在训练推荐系统时，我们发现用户的 interaction 数据对模型性能影响很大。",
        "sentence_B": "在训练推荐系统时，我们发现用户的交互数据对模型性能影响很大。",
        "id": 1398,
        "target_term": "interaction",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretability",
        "prefix": "在模型训练阶段，团队讨论模型的可解释性问题。",
        "sentence_A": "我们在模型训练时，不仅要关注准确性，还要考虑模型的 interpretability，这样才能更好地理解模型的行为。",
        "sentence_B": "我们在模型训练时，不仅要关注准确性，还要考虑模型的可解释性，这样才能更好地理解模型的行为。",
        "id": 1399,
        "target_term": "interpretability",
        "is_hardcore": true
    },
    {
        "topic": "Model Interpretation",
        "prefix": "在讨论模型的可解释性时，同事们提到了一个关键点",
        "sentence_A": "这个模型的 interpretation 非常重要，我们需要确保每个特征的权重都能被清晰地解释。",
        "sentence_B": "这个模型的解释性非常重要，我们需要确保每个特征的权重都能被清晰地解释。",
        "id": 1400,
        "target_term": "interpretation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中的人工干预策略时",
        "sentence_A": "在训练过程中，我们需要考虑适当的 intervention 来避免模型过拟合。",
        "sentence_B": "在训练过程中，我们需要考虑适当的人工干预来避免模型过拟合。",
        "id": 1401,
        "target_term": "intervention",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数设置时",
        "sentence_A": "我们在设置学习率的 decay interval 时，需要确保模型在训练过程中能够稳定收敛。",
        "sentence_B": "我们在设置学习率的衰减间隔时，需要确保模型在训练过程中能够稳定收敛。",
        "id": 1402,
        "target_term": "decay interval",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常讨论模型的直觉能力。",
        "sentence_A": "这个模型的训练过程中，我们发现它的 intuition 非常强，能够很好地处理边缘情况。",
        "sentence_B": "在模型训练过程中，我们发现它的直觉能力非常强，能够很好地处理边缘情况。",
        "id": 1403,
        "target_term": "intuition",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到需要计算逆矩阵来优化损失函数。",
        "sentence_A": "在训练模型时，我们发现计算 inverse 矩阵可以有效优化损失函数。",
        "sentence_B": "在训练模型时，我们发现计算逆矩阵可以有效优化损失函数。",
        "id": 1404,
        "target_term": "inverse",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中团队成员的角色分配时",
        "sentence_A": "这次的模型训练，我们需要更多人的 involvement，确保每个环节都能得到充分的优化。",
        "sentence_B": "这次的模型训练，我们需要更多人的参与，确保每个环节都能得到充分的优化。",
        "id": 1405,
        "target_term": "involvement",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在数据预处理阶段，我们讨论了如何处理数据集中的每个条目。",
        "sentence_A": "在数据预处理阶段，我们需要确保每个 item 的格式正确，这样才能顺利进行后续的模型训练。",
        "sentence_B": "在数据预处理阶段，我们需要确保每个条目的格式正确，这样才能顺利进行后续的模型训练。",
        "id": 1406,
        "target_term": "item",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要进行多次迭代来优化模型性能。",
        "sentence_A": "在训练过程中，我们需要不断进行 iterative 优化，以提高模型的准确性和稳定性。",
        "sentence_B": "在训练过程中，我们需要不断进行迭代优化，以提高模型的准确性和稳定性。",
        "id": 1407,
        "target_term": "iterative",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化时",
        "sentence_A": "我们在优化模型训练的时候，发现调整 kernel 的参数可以显著提高训练效率。",
        "sentence_B": "我们在优化模型训练的时候，发现调整卷积核的参数可以显著提高训练效率。",
        "id": 1408,
        "target_term": "kernel",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何改进模型的训练过程中，团队成员提到",
        "sentence_A": "我们在训练模型时，需要更好地利用 knowledge，以提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要更好地利用知识，以提高模型的泛化能力。",
        "id": 1409,
        "target_term": "knowledge",
        "is_hardcore": true
    },
    {
        "topic": "Laplacian Smoothing",
        "prefix": "在模型训练过程中，我们讨论了如何处理数据中的噪声问题。",
        "sentence_A": "我们在模型训练时用到了 laplacian 平滑技术，效果很不错。",
        "sentence_B": "我们在模型训练时使用了拉普拉斯平滑技术，效果非常好。",
        "id": 1410,
        "target_term": "laplacian",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们这次优化的重点是降低模型的 latency，确保在生产环境中能够快速响应用户请求。",
        "sentence_B": "我们这次优化的重点是降低模型的延迟，确保在生产环境中能够快速响应用户请求。",
        "id": 1411,
        "target_term": "latency",
        "is_hardcore": true
    },
    {
        "topic": "Latent Variables in Model Training",
        "prefix": "在讨论模型训练的会议上，团队成员在讨论如何优化模型的隐变量表示。",
        "sentence_A": "我们可以通过优化这些 latent 变量来提升模型的泛化能力。",
        "sentence_B": "我们可以通过优化这些隐变量来提升模型的泛化能力。",
        "id": 1412,
        "target_term": "latent",
        "is_hardcore": true
    },
    {
        "topic": "Lattice in AI Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到使用了lattice结构来优化模型性能。",
        "sentence_A": "在训练这个模型的时候，我们引入了一个 lattice 结构，有效地提高了模型的精度和效率。",
        "sentence_B": "在训练这个模型的时候，我们引入了一个格子结构，有效地提高了模型的精度和效率。",
        "id": 1413,
        "target_term": "lattice",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Architecture",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们可以在模型的 hidden layer 之间加一个 dropout layer 来提高模型的泛化能力。",
        "sentence_B": "我们可以在模型的隐藏层之间加一个 dropout 层来提高模型的泛化能力。",
        "id": 1414,
        "target_term": "hidden layer",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们在调整模型的 layer 时，需要确保每个 layer 的参数都经过充分的优化。",
        "sentence_B": "我们在调整模型的层时，需要确保每一层的参数都经过充分的优化。",
        "id": 1415,
        "target_term": "layer",
        "is_hardcore": true
    },
    {
        "topic": "Data Leakage in Model Training",
        "prefix": "在讨论模型训练中的常见问题时",
        "sentence_A": "我们在处理训练数据时要注意避免数据集之间的 leakage，这会导致模型在验证集上的表现失真。",
        "sentence_B": "我们在处理训练数据时要注意避免数据集之间的数据泄漏，这会导致模型在验证集上的表现失真。",
        "id": 1416,
        "target_term": "leakage",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们在数据清洗的时候，需要特别注意对每个单词的 lemma 进行标准化处理。",
        "sentence_B": "我们在数据清洗的时候，需要特别注意对每个单词的词元进行标准化处理。",
        "id": 1417,
        "target_term": "lemma",
        "is_hardcore": true
    },
    {
        "topic": "Lexical Analysis in NLP",
        "prefix": "在模型训练过程中，我们遇到了一些关于词汇分析的问题。",
        "sentence_A": "在处理这个任务时，我们需要特别关注 lexical 层面的特征提取。",
        "sentence_B": "在处理这个任务时，我们需要特别关注词汇层面的特征提取。",
        "id": 1418,
        "target_term": "lexical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练模型时，用到了很多流行的 machine learning library，比如 TensorFlow 和 PyTorch。",
        "sentence_B": "我们在训练模型时，用到了很多流行的机器学习库，比如 TensorFlow 和 PyTorch。",
        "id": 1419,
        "target_term": "machine learning library",
        "is_hardcore": true
    },
    {
        "topic": "Model Licensing",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们需要确保模型的 licensing 问题已经解决，这样才能顺利上线。",
        "sentence_B": "我们需要确保模型的许可问题已经解决，这样才能顺利上线。",
        "id": 1420,
        "target_term": "licensing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在设置 batch size 的时候，需要注意不要超过 GPU 的 memory limit，否则会出问题。",
        "sentence_B": "我们在设置批量大小时，需要注意不要超过 GPU 的内存限制，否则会出问题。",
        "id": 1421,
        "target_term": "batch size",
        "is_hardcore": true
    },
    {
        "topic": "Linear Regression",
        "prefix": "在一次模型训练的过程中，我们讨论了线性回归模型的性能。",
        "sentence_A": "在训练这个模型的时候，我们发现使用 linear 回归的效果比其他方法更好。",
        "sentence_B": "在训练这个模型的时候，我们发现使用线性回归的效果比其他方法更好。",
        "id": 1422,
        "target_term": "linear",
        "is_hardcore": true
    },
    {
        "topic": "NLP Model Training",
        "prefix": "在模型训练过程中，我们讨论了语言学特征的重要性。",
        "sentence_A": "在训练模型时，我们发现 linguistic 特征对性能提升非常关键。",
        "sentence_B": "在训练模型时，我们发现语言学特征对性能提升非常关键。",
        "id": 1423,
        "target_term": "linguistic",
        "is_hardcore": true
    },
    {
        "topic": "Linguistics in NLP",
        "prefix": "在讨论模型训练时，团队成员提到语言学的重要性。",
        "sentence_A": "在训练这个模型时，我们得特别注意 linguistic 的应用，这样才能更好地理解文本的深层含义。",
        "sentence_B": "在训练这个模型时，我们得特别注意语言学的应用，这样才能更好地理解文本的深层含义。",
        "id": 1424,
        "target_term": "linguistic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时，团队成员提到数据集中的链接问题。",
        "sentence_A": "我们在准备训练数据时，发现有些数据的 link 是断的，这会影响模型的准确性。",
        "sentence_B": "我们在准备训练数据时，发现有些数据的链接是断的，这会影响模型的准确性。",
        "id": 1425,
        "target_term": "link",
        "is_hardcore": false
    },
    {
        "topic": "Entity Linking",
        "prefix": "在讨论模型训练的数据准备阶段时，",
        "sentence_A": "我们在数据预处理阶段需要特别注意实体的 linking，确保每个实体都能正确地关联到知识图谱中的对应节点。",
        "sentence_B": "我们在数据预处理阶段需要特别注意实体的链接，确保每个实体都能正确地关联到知识图谱中的对应节点。",
        "id": 1426,
        "target_term": "linking",
        "is_hardcore": true
    },
    {
        "topic": "Data Structures in AI Development",
        "prefix": "在讨论模型训练数据的预处理时",
        "sentence_A": "我们在处理训练数据时，通常会用一个 list 来存储每个样本的特征值。",
        "sentence_B": "我们在处理训练数据时，通常会用一个列表来存储每个样本的特征值。",
        "id": 1427,
        "target_term": "list",
        "is_hardcore": false
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型上线的会议上",
        "sentence_A": "我们在讨论如何确保模型在 live 环境中稳定运行。",
        "sentence_B": "我们在讨论如何确保模型在生产环境中稳定运行。",
        "id": 1428,
        "target_term": "live",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的分布式策略时",
        "sentence_A": "我们在讨论模型训练时，用的是 local 模式还是 distributed 模式呢？",
        "sentence_B": "我们在讨论模型训练时，使用的是本地模式还是分布式模式呢？",
        "id": 1429,
        "target_term": "local",
        "is_hardcore": true
    },
    {
        "topic": "Data Locality",
        "prefix": "在模型训练过程中，我们经常需要考虑数据的本地化问题。",
        "sentence_A": "在训练大规模模型时，我们需要注意数据的 locality，确保数据能够高效地加载到内存中。",
        "sentence_B": "在训练大规模模型时，我们需要注意数据的局部性，确保数据能够高效地加载到内存中。",
        "id": 1430,
        "target_term": "locality",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何优化模型在不同语言环境下的表现。",
        "sentence_A": "我们在模型训练中引入了 localization 技术，以提高模型在不同语言环境下的适应性。",
        "sentence_B": "我们在模型训练中引入了本地化技术，以提高模型在不同语言环境下的适应性。",
        "id": 1431,
        "target_term": "localization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员讨论如何优化模型的推理过程。",
        "sentence_A": "我们需要优化模型的 inference logic，以提高推理速度。",
        "sentence_B": "我们需要优化模型的推理逻辑，以提高推理速度。",
        "id": 1432,
        "target_term": "inference logic",
        "is_hardcore": true
    },
    {
        "topic": "Data Analysis",
        "prefix": "在讨论用户行为分析的数据处理方案时",
        "sentence_A": "我们在处理用户行为数据时，需要关注 longitudinal 数据的连续性，这样才能更好地理解用户的行为模式。",
        "sentence_B": "我们在处理用户行为数据时，需要关注纵向数据的连续性，这样才能更好地理解用户的行为模式。",
        "id": 1433,
        "target_term": "longitudinal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队正在讨论如何优化损失函数。",
        "sentence_A": "我们得看看这个 loss 是不是还有优化的空间，可能需要调整学习率。",
        "sentence_B": "我们需要检查这个损失函数是否还有优化的空间，可能需要调整学习率。",
        "id": 1434,
        "target_term": "loss",
        "is_hardcore": true
    },
    {
        "topic": "Manifold Learning",
        "prefix": "在讨论模型训练的数据预处理阶段",
        "sentence_A": "我们在处理高维数据时，利用 manifold 技术可以有效降低维度，同时保留数据的关键特征。",
        "sentence_B": "我们在处理高维数据时，利用流形技术可以有效降低维度，同时保留数据的关键特征。",
        "id": 1435,
        "target_term": "manifold",
        "is_hardcore": true
    },
    {
        "topic": "Data Mapping",
        "prefix": "在模型训练过程中，我们需要将原始数据转换为模型可以理解的格式。",
        "sentence_A": "我们需要创建一个 mapping，将原始数据字段与模型输入字段对齐。",
        "sentence_B": "我们需要创建一个映射，将原始数据字段与模型输入字段对齐。",
        "id": 1436,
        "target_term": "mapping",
        "is_hardcore": true
    },
    {
        "topic": "Masking in NLP",
        "prefix": "在讨论模型训练时，团队成员提到如何处理输入数据中的某些部分。",
        "sentence_A": "我们在训练模型时，需要使用 mask 来处理输入中的某些部分，这样可以避免模型关注到不重要的信息。",
        "sentence_B": "我们在训练模型时，需要使用掩码来处理输入中的某些部分，这样可以避免模型关注到不重要的信息。",
        "id": 1437,
        "target_term": "mask",
        "is_hardcore": true
    },
    {
        "topic": "Masking",
        "prefix": "在模型训练过程中，我们经常需要处理输入数据中的某些部分，例如在自然语言处理中屏蔽某些词汇。",
        "sentence_A": "在训练这个 NLP 模型的时候，我们需要用到 masking 技术来处理输入序列中的某些部分。",
        "sentence_B": "在训练这个自然语言处理模型时，我们需要使用遮蔽技术来处理输入序列中的某些部分。",
        "id": 1438,
        "target_term": "NLP",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在探讨如何优化模型的数学基础。",
        "sentence_A": "我们在优化模型时，需要更关注 mathematical 基础，这样才能确保模型的稳定性和准确性。",
        "sentence_B": "我们在优化模型时，需要更关注数学基础，这样才能确保模型的稳定性和准确性。",
        "id": 1439,
        "target_term": "mathematical",
        "is_hardcore": true
    },
    {
        "topic": "Matrix Operations in Model Training",
        "prefix": "在讨论模型训练的优化过程中，",
        "sentence_A": "我们需要优化 matrix 的乘法运算，以提高模型训练的效率。",
        "sentence_B": "我们需要优化矩阵的乘法运算，以提高模型训练的效率。",
        "id": 1440,
        "target_term": "matrix",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时，团队成员提到一个关键的优化目标。",
        "sentence_A": "在调整超参数时，我们需要确保模型的 accuracy 达到 maximum，这样才能保证模型在测试集上的表现。",
        "sentence_B": "在调整超参数时，我们需要确保模型的准确率达到最大值，这样才能保证模型在测试集上的表现。",
        "id": 1441,
        "target_term": "accuracy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，同事提到了一个关键概念",
        "sentence_A": "我们这次训练的模型需要更好地理解句子的 meaning，这样才能在推理时更准确。",
        "sentence_B": "我们这次训练的模型需要更好地理解句子的意义，这样才能在推理时更准确。",
        "id": 1442,
        "target_term": "meaning",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型评估阶段，团队正在讨论如何量化模型的性能。",
        "sentence_A": "我们在评估模型时，需要考虑多个 measure，比如精度、召回率和F1分数。",
        "sentence_B": "我们在评估模型时，需要考虑多个指标，比如精度、召回率和F1分数。",
        "id": 1443,
        "target_term": "measure",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，我们需要不断评估模型的性能。",
        "sentence_A": "在训练过程中，我们需要定期检查模型的 performance，确保每个阶段的 measurement 都符合预期。",
        "sentence_B": "在训练过程中，我们需要定期检查模型的性能，确保每个阶段的度量都符合预期。",
        "id": 1444,
        "target_term": "performance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方法时",
        "sentence_A": "我们在优化模型训练时，发现机械式的参数调整方法效果并不理想，需要更智能的策略来提升模型性能。",
        "sentence_B": "我们在优化模型训练时，发现机械式的参数调整方法效果并不理想，需要更智能的策略来提升模型性能。",
        "id": 1445,
        "term_cleaned": "N/A",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中的优化策略时",
        "sentence_A": "我们可以通过调整学习率和批量大小来优化训练机制 mechanism，从而提高模型的收敛速度。",
        "sentence_B": "我们可以通过调整学习率和批量大小来优化训练机制，从而提高模型的收敛速度。",
        "id": 1446,
        "target_term": "mechanism",
        "is_hardcore": true
    },
    {
        "topic": "Memory Management",
        "prefix": "在模型训练过程中，我们经常需要关注内存使用情况。",
        "sentence_A": "这次训练过程中，我们的模型在 batch size 为 32 时，memory 使用量已经接近上限了。",
        "sentence_B": "在这次训练过程中，我们的模型在批大小为 32 时，内存使用量已经接近上限了。",
        "id": 1447,
        "target_term": "batch size",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数时",
        "sentence_A": "我们在训练这个模型时，需要特别注意 meta 数据的处理，这会直接影响到模型的泛化能力。",
        "sentence_B": "我们在训练这个模型时，需要特别注意元数据的处理，这会直接影响到模型的泛化能力。",
        "id": 1448,
        "target_term": "meta",
        "is_hardcore": true
    },
    {
        "topic": "Metamodel in Model Training",
        "prefix": "在讨论模型训练策略时，团队成员提到使用元模型来优化训练过程。",
        "sentence_A": "我们在训练过程中引入了 metamodel，这样可以显著提高模型的泛化能力。",
        "sentence_B": "我们在训练过程中引入了元模型，这样可以显著提高模型的泛化能力。",
        "id": 1449,
        "target_term": "metamodel",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，团队正在讨论如何评估模型的性能。",
        "sentence_A": "我们这次训练的模型在验证集上的 accuracy 这个 metric 表现不错，但 precision 和 recall 还需要进一步优化。",
        "sentence_B": "我们这次训练的模型在验证集上的准确率这个指标表现不错，但精确率和召回率还需要进一步优化。",
        "id": 1450,
        "target_term": "accuracy",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练阶段，团队正在讨论如何评估模型的性能。",
        "sentence_A": "我们这次训练的模型，最重要的就是看这些 metric，比如 precision 和 recall，它们能帮助我们更好地理解模型的表现。",
        "sentence_B": "我们这次训练的模型，最重要的就是看这些评估指标，比如精确率和召回率，它们能帮助我们更好地理解模型的表现。",
        "id": 1451,
        "target_term": "metric",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的性能优化时",
        "sentence_A": "我们在训练过程中发现，使用 micro-batch 可以显著提高模型的训练速度。",
        "sentence_B": "我们在训练过程中发现，使用小批量可以显著提高模型的训练速度。",
        "id": 1452,
        "target_term": "micro-batch",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型从开发环境迁移到生产环境的过程中",
        "sentence_A": "我们在进行模型的 migration 时，要注意确保数据的一致性和系统的稳定性。",
        "sentence_B": "我们在进行模型的迁移时，要注意确保数据的一致性和系统的稳定性。",
        "id": 1453,
        "target_term": "migration",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "为了减少推理时间，我们需要对模型进行 minimal 的裁剪。",
        "sentence_B": "为了减少推理时间，我们需要对模型进行最小的裁剪。",
        "id": 1454,
        "target_term": "minimal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化模型的训练过程中，团队成员提到了一种简约的设计理念。",
        "sentence_A": "在模型训练中，我们可以采用更 minimalist 的方法，减少不必要的参数，提高模型的效率。",
        "sentence_B": "在模型训练中，我们可以采用更简约的方法，减少不必要的参数，提高模型的效率。",
        "id": 1455,
        "target_term": "minimalist",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的超参数设置时",
        "sentence_A": "我们需要设置 learning rate 的 minimum 值，以确保模型在训练初期不会因学习率过低而停滞不前。",
        "sentence_B": "我们需要设置学习率的最小值，以确保模型在训练初期不会因学习率过低而停滞不前。",
        "id": 1456,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练方案时",
        "sentence_A": "我们可以在训练过程中使用 mix 策略来提高模型的泛化能力。",
        "sentence_B": "我们可以在训练过程中使用混合策略来提高模型的泛化能力。",
        "id": 1457,
        "target_term": "mix",
        "is_hardcore": true
    },
    {
        "topic": "Mixture Models",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们这次的训练数据集是一个 mixture，包含了多种不同的数据分布。",
        "sentence_B": "我们这次的训练数据集是一个混合体，包含了多种不同的数据分布。",
        "id": 1458,
        "target_term": "mixture",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "在训练这个模型时，我们需要特别注意每个 moment 的梯度变化，以确保模型的稳定性和收敛性。",
        "sentence_B": "在训练这个模型时，我们需要特别注意每个时刻的梯度变化，以确保模型的稳定性和收敛性。",
        "id": 1459,
        "target_term": "moment",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何处理数据的统计特性。",
        "sentence_A": "在训练过程中，我们需要特别注意数据的 moment，因为这些统计特性对模型的性能有很大影响。",
        "sentence_B": "在训练过程中，我们需要特别注意数据的矩，因为这些统计特性对模型的性能有很大影响。",
        "id": 1460,
        "target_term": "moment",
        "is_hardcore": true
    },
    {
        "topic": "Monotonic Functions in Model Training",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在优化这个模型的时候，发现使用 monotonic 函数可以显著提升模型的稳定性和预测准确性。",
        "sentence_B": "我们在优化这个模型的时候，发现使用单调函数可以显著提升模型的稳定性和预测准确性。",
        "id": 1461,
        "target_term": "monotonic",
        "is_hardcore": true
    },
    {
        "topic": "Morphological Analysis in NLP",
        "prefix": "在讨论自然语言处理中的文本预处理技术时，",
        "sentence_A": "我们在做文本预处理的时候，需要处理各种 morphological 变化，比如词形还原和词干提取。",
        "sentence_B": "我们在进行文本预处理时，需要处理各种形态变化，比如词形还原和词干提取。",
        "id": 1462,
        "target_term": "morphological",
        "is_hardcore": true
    },
    {
        "topic": "Motion Estimation in Video Compression",
        "prefix": "在讨论视频压缩算法的优化时",
        "sentence_A": "我们在做视频压缩的时候，需要特别关注 motion 估计的精度，这直接影响到压缩效率和视频质量。",
        "sentence_B": "在进行视频压缩时，需要特别关注运动估计的精度，这直接影响到压缩效率和视频质量。",
        "id": 1463,
        "target_term": "motion",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化多任务学习模型时",
        "sentence_A": "我们在训练 multi-task 模型时，需要特别注意数据的分布和任务之间的权重平衡。",
        "sentence_B": "我们在训练多任务模型时，需要特别注意数据的分布和任务之间的权重平衡。",
        "id": 1464,
        "target_term": "multi-task",
        "is_hardcore": true
    },
    {
        "topic": "Multichannel Data Integration",
        "prefix": "在讨论模型训练的数据源时",
        "sentence_A": "我们在训练模型时，需要从 multichannel 来源获取数据，以确保模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要从多渠道来源获取数据，以确保模型的泛化能力。",
        "id": 1465,
        "target_term": "multichannel",
        "is_hardcore": true
    },
    {
        "topic": "Multiclass Classification",
        "prefix": "在模型训练过程中，我们讨论了如何处理多分类问题。",
        "sentence_A": "我们在训练这个模型时，需要特别注意 multiclas 的处理方式，确保每个类别的预测都足够准确。",
        "sentence_B": "我们在训练这个模型时，需要特别注意多分类的处理方式，确保每个类别的预测都足够准确。",
        "id": 1466,
        "target_term": "multiclas",
        "is_hardcore": true
    },
    {
        "topic": "Multidimensional Data Processing",
        "prefix": "在模型训练中讨论数据处理方式时",
        "sentence_A": "我们在处理 multidimensional 数据时，需要确保每个维度的数据都经过了适当的归一化。",
        "sentence_B": "我们在处理多维数据时，需要确保每个维度的数据都经过了适当的归一化。",
        "id": 1467,
        "target_term": "multidimensional",
        "is_hardcore": true
    },
    {
        "topic": "Multifidelity Optimization",
        "prefix": "在模型训练过程中讨论优化策略",
        "sentence_A": "我们在模型训练中采用了 multifidelity 优化，这样可以显著提高效率。",
        "sentence_B": "我们在模型训练中采用了多保真度优化，这样可以显著提高效率。",
        "id": 1468,
        "target_term": "multifidelity",
        "is_hardcore": true
    },
    {
        "topic": "Graph Theory in AI",
        "prefix": "在讨论模型训练的数据结构时",
        "sentence_A": "我们在处理图数据时，经常会遇到 multigraph 的情况，这时候需要特别注意节点之间的多重边。",
        "sentence_B": "我们在处理图数据时，经常会遇到多重图的情况，这时候需要特别注意节点之间的多重边。",
        "id": 1469,
        "target_term": "multigraph",
        "is_hardcore": true
    },
    {
        "topic": "Multilabel Classification",
        "prefix": "在一次模型训练的讨论中，团队正在优化一个多标签分类模型。",
        "sentence_A": "我们在处理 multilabel 问题时，需要特别注意特征工程和损失函数的选择。",
        "sentence_B": "我们在处理多标签问题时，需要特别注意特征工程和损失函数的选择。",
        "id": 1470,
        "target_term": "multilabel",
        "is_hardcore": true
    },
    {
        "topic": "Multilingual Model Training",
        "prefix": "在一次模型训练的讨论中，团队正在探讨如何优化多语言模型的性能。",
        "sentence_A": "我们在训练 multilingual 模型时，需要确保数据集的质量，这样才能保证模型的泛化能力。",
        "sentence_B": "我们在训练多语言模型时，需要确保数据集的质量，这样才能保证模型的泛化能力。",
        "id": 1471,
        "target_term": "multilingual",
        "is_hardcore": true
    },
    {
        "topic": "Multimodal Data Fusion",
        "prefix": "在讨论模型训练时，团队成员提到多模态数据的重要性。",
        "sentence_A": "我们在训练模型时，multimodal 数据的融合是关键，需要确保各个模态之间的信息能够有效对齐。",
        "sentence_B": "我们在训练模型时，多模态数据的融合是关键，需要确保各个模态之间的信息能够有效对齐。",
        "id": 1472,
        "target_term": "multimodal",
        "is_hardcore": true
    },
    {
        "topic": "Multi-objective Optimization",
        "prefix": "在讨论模型训练时，团队成员提到多目标优化的问题。",
        "sentence_A": "我们在训练这个模型时，需要考虑 multiobjec 优化，确保多个目标都能达到最优。",
        "sentence_B": "我们在训练这个模型时，需要考虑多目标优化，确保多个目标都能达到最优。",
        "id": 1473,
        "target_term": "multiobjec",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们需要设置 multiple learning rate 来优化不同层的训练效果。",
        "sentence_B": "我们需要设置多个学习率来优化不同层的训练效果。",
        "id": 1474,
        "target_term": "multiple learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Multiscale Techniques in Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们可以通过引入 multiscale 技术来提升模型的鲁棒性和泛化能力。",
        "sentence_B": "我们可以通过引入多尺度技术来提升模型的鲁棒性和泛化能力。",
        "id": 1475,
        "target_term": "multiscale",
        "is_hardcore": true
    },
    {
        "topic": "Data Structures in Algorithm Design",
        "prefix": "在讨论数据结构优化时，团队成员提到了一个术语",
        "sentence_A": "我们在数据清洗阶段用到了 multiset，这样可以高效地处理重复数据。",
        "sentence_B": "我们在数据清洗阶段用到了多重集，这样可以高效地处理重复数据。",
        "id": 1476,
        "target_term": "multiset",
        "is_hardcore": true
    },
    {
        "topic": "Multistage Model Training",
        "prefix": "在讨论如何优化模型训练流程时，团队成员提出了一个多阶段训练方案。",
        "sentence_A": "我们可以通过 multistage 训练方法来逐步提升模型的性能，每个阶段专注于解决不同的问题。",
        "sentence_B": "我们可以通过多阶段训练方法来逐步提升模型的性能，每个阶段专注于解决不同的问题。",
        "id": 1477,
        "target_term": "multistage",
        "is_hardcore": true
    },
    {
        "topic": "Multitask Learning",
        "prefix": "在讨论模型训练策略时，团队成员提到：",
        "sentence_A": "我们在训练这个模型时，可以采用 multitask 的方法，这样可以提高模型的泛化能力。",
        "sentence_B": "我们在训练这个模型时，可以采用多任务学习的方法，这样可以提高模型的泛化能力。",
        "id": 1478,
        "target_term": "multitask",
        "is_hardcore": true
    },
    {
        "topic": "Multiview Learning",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练这个模型时，使用了 multiview 技术，从多个视角获取数据，效果提升很明显。",
        "sentence_B": "我们在训练这个模型时，使用了多视图技术，从多个视角获取数据，效果提升非常明显。",
        "id": 1479,
        "target_term": "multiview",
        "is_hardcore": true
    },
    {
        "topic": "Multivariate Analysis",
        "prefix": "在进行模型训练时，团队遇到了多变量数据处理的问题。",
        "sentence_A": "我们在处理 multivariate 数据时，发现模型的预测准确性有所下降。",
        "sentence_B": "我们在处理多变量数据时，发现模型的预测准确性有所下降。",
        "id": 1480,
        "target_term": "multivariate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论音乐推荐系统的模型训练时",
        "sentence_A": "我们在训练模型时，发现 music 数据的质量对推荐效果影响很大。",
        "sentence_B": "我们在训练模型时，发现音乐数据的质量对推荐效果影响很大。",
        "id": 1481,
        "target_term": "music",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们需要确保训练集和测试集之间有 mutual 信息，这样才能确保模型的泛化能力。",
        "sentence_B": "我们需要确保训练集和测试集之间有共同信息，这样才能确保模型的泛化能力。",
        "id": 1482,
        "target_term": "mutual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何更好地处理文本数据中的叙事结构。",
        "sentence_A": "在训练这个模型时，我们发现处理文本的 narrative 非常重要，需要更精细的预处理。",
        "sentence_B": "在训练这个模型时，我们发现处理文本的叙事结构非常重要，需要更精细的预处理。",
        "id": 1483,
        "target_term": "narrative",
        "is_hardcore": true
    },
    {
        "topic": "Navigation in Autonomous Vehicles",
        "prefix": "在讨论自动驾驶汽车的路径规划时",
        "sentence_A": "我们在模型训练中发现，navigation 模块的精度对整体性能影响很大。",
        "sentence_B": "我们在模型训练中发现，导航模块的精度对整体性能影响很大。",
        "id": 1484,
        "target_term": "navigation",
        "is_hardcore": true
    },
    {
        "topic": "Graph Neural Networks",
        "prefix": "在讨论图神经网络的节点聚合方法时",
        "sentence_A": "我们可以通过聚合每个节点的 neighbor 信息来提高模型的表示能力。",
        "sentence_B": "我们可以通过聚合每个节点的邻居信息来提高模型的表示能力。",
        "id": 1485,
        "target_term": "neighbor",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据结构时",
        "sentence_A": "我们这次的数据集里有好多 nested 的结构，处理起来挺麻烦的。",
        "sentence_B": "我们这次的数据集中有很多嵌套的结构，处理起来相当麻烦。",
        "id": 1486,
        "target_term": "nested",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Training",
        "prefix": "在讨论模型训练的过程中",
        "sentence_A": "我们这次的模型训练中，使用了更复杂的 neural 网络结构，效果提升明显。",
        "sentence_B": "我们这次的模型训练中，使用了更复杂的神经网络结构，效果提升明显。",
        "id": 1487,
        "target_term": "neural",
        "is_hardcore": true
    },
    {
        "topic": "Neural Network Architecture",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们在优化模型的时候，发现调整每个 neuron 的激活函数可以显著提升模型的性能。",
        "sentence_B": "我们在优化模型的时候，发现调整每个神经元的激活函数可以显著提升模型的性能。",
        "id": 1488,
        "target_term": "neuron",
        "is_hardcore": true
    },
    {
        "topic": "Neural Networks",
        "prefix": "在讨论模型结构优化时",
        "sentence_A": "我们在优化模型时，需要特别注意每个 layer 里的 neurons 数量，这直接影响到模型的复杂度和性能。",
        "sentence_B": "我们在优化模型时，需要特别注意每个层中的神经元数量，这直接影响到模型的复杂度和性能。",
        "id": 1489,
        "target_term": "layer",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们发现了一批异常数据。",
        "sentence_A": "在数据清洗过程中，我们发现了一批包含大量 noise 的异常数据。",
        "sentence_B": "在数据清洗过程中，我们发现了一批包含大量噪声的异常数据。",
        "id": 1490,
        "target_term": "noise",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在进行数据预处理时，我们遇到了一些问题。",
        "sentence_A": "这些数据集里有很多 noisy 的数据，我们需要进一步清洗。",
        "sentence_B": "这些数据集中有很多噪声数据，我们需要进一步清洗。",
        "id": 1491,
        "target_term": "noisy",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们发现了一些异常值。",
        "sentence_A": "在数据清洗阶段，我们发现了一些异常值，但大多数值还是 nominal 的。",
        "sentence_B": "在数据清洗阶段，我们发现了一些异常值，但大多数值还是名义值的。",
        "id": 1492,
        "target_term": "nominal",
        "is_hardcore": true
    },
    {
        "topic": "Nonlinearity in Neural Networks",
        "prefix": "在讨论模型训练时，团队成员提到模型的非线性特性对性能的影响。",
        "sentence_A": "我们在训练这个模型时，发现引入 nonlinearity 后，性能提升很明显。",
        "sentence_B": "我们在训练这个模型时，发现引入非线性特性后，性能提升非常明显。",
        "id": 1493,
        "target_term": "nonlinearity",
        "is_hardcore": true
    },
    {
        "topic": "Nonmonotonic Reasoning in AI Models",
        "prefix": "在讨论模型推理时，团队成员提到非单调逻辑的重要性。",
        "sentence_A": "在处理复杂推理问题时，我们发现 nonmonotonic 逻辑对于提高模型的鲁棒性非常关键。",
        "sentence_B": "在处理复杂推理问题时，我们发现非单调逻辑对于提高模型的鲁棒性非常关键。",
        "id": 1494,
        "target_term": "nonmonotonic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "在训练过程中，我们发现数据的 normal 分布对模型性能影响很大。",
        "sentence_B": "在训练过程中，我们发现数据的正态分布对模型性能影响很大。",
        "id": 1495,
        "target_term": "normal",
        "is_hardcore": true
    },
    {
        "topic": "Normalization in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到数据预处理的重要性。",
        "sentence_A": "在训练模型之前，我们通常会对数据进行 normalization，这样可以提高模型的收敛速度和稳定性。",
        "sentence_B": "在训练模型之前，我们通常会对数据进行归一化，这样可以提高模型的收敛速度和稳定性。",
        "id": 1496,
        "target_term": "normalization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数表示时",
        "sentence_A": "我们在模型训练中使用的 notation 需要统一，这样才能确保代码的可读性和维护性。",
        "sentence_B": "我们在模型训练中使用的符号表示需要统一，这样才能确保代码的可读性和维护性。",
        "id": 1497,
        "target_term": "notation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论最新模型的训练策略时，团队成员提到了一个新方法。",
        "sentence_A": "这个新的训练方法确实很 novel，值得我们深入研究。",
        "sentence_B": "这个新的训练方法确实很有创新性，值得我们深入研究。",
        "id": 1498,
        "target_term": "novel",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗阶段，我们遇到了一些问题",
        "sentence_A": "我们需要确保所有的 numeric 字段都转换为浮点数，以避免在模型训练时出现类型错误。",
        "sentence_B": "我们需要确保所有的数值字段都转换为浮点数，以避免在模型训练时出现类型错误。",
        "id": 1499,
        "target_term": "numeric",
        "is_hardcore": true
    },
    {
        "topic": "Numerical Stability in Model Training",
        "prefix": "在讨论模型训练的数值稳定性时",
        "sentence_A": "我们在模型训练时要注意 numerical 稳定性，特别是在处理大规模数据集时。",
        "sentence_B": "我们在模型训练时要注意数值稳定性，特别是在处理大规模数据集时。",
        "id": 1500,
        "target_term": "numerical",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在模型训练的数据预处理阶段，团队讨论了如何处理异常值的问题。",
        "sentence_A": "在数据清洗过程中，我们需要特别注意每个 observation，确保它们的准确性和一致性。",
        "sentence_B": "在数据清洗过程中，我们需要特别注意每个观测值，确保它们的准确性和一致性。",
        "id": 1501,
        "target_term": "observation",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署的会议上",
        "sentence_A": "我们在部署模型时，需要确保模型在 online 环境中的性能稳定。",
        "sentence_B": "我们在部署模型时，需要确保模型在在线环境中的性能稳定。",
        "id": 1502,
        "target_term": "online",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到需要对训练过程进行优化。",
        "sentence_A": "我们在训练模型时，需要特别关注训练效率的 optimization，这样才能确保模型在有限的资源下达到最佳性能。",
        "sentence_B": "我们在训练模型时，需要特别关注训练效率的优化，这样才能确保模型在有限的资源下达到最佳性能。",
        "id": 1503,
        "target_term": "optimization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员正在讨论模型的输出结果。",
        "sentence_A": "我们在训练模型的时候，需要特别关注 model 的 output，确保它能准确反映输入数据的特征。",
        "sentence_B": "我们在训练模型的时候，需要特别关注模型的输出结果，确保它能准确反映输入数据的特征。",
        "id": 1504,
        "target_term": "model",
        "is_hardcore": true
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在进行数据清洗时，我们发现了一些问题",
        "sentence_A": "在数据清洗过程中，我们发现有些数据段有明显的 overlap，需要进一步处理。",
        "sentence_B": "在数据清洗过程中，我们发现有些数据段有明显的重叠，需要进一步处理。",
        "id": 1505,
        "target_term": "overlap",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现模型在训练集上的表现非常好，但在验证集上的表现却大打折扣。",
        "sentence_A": "看来我们的模型出现了 overfitting 的问题，需要调整一些超参数来解决。",
        "sentence_B": "看来我们的模型出现了过拟合的问题，需要调整一些超参数来解决。",
        "id": 1506,
        "target_term": "overfitting",
        "is_hardcore": true
    },
    {
        "topic": "Parallel Computing in Model Training",
        "prefix": "在讨论如何优化模型训练速度时",
        "sentence_A": "我们可以通过使用 parallel 计算来大幅提高训练效率。",
        "sentence_B": "我们可以通过使用并行计算来大幅提高训练效率。",
        "id": 1507,
        "target_term": "parallel",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练参数的设置时",
        "sentence_A": "我们在调整 model 的 parameter 时，需要特别关注 learning rate 和 batch size，这两个 parameter 对模型的收敛速度和最终性能影响很大。",
        "sentence_B": "我们在调整模型的参数时，需要特别关注学习率和批量大小，这两个参数对模型的收敛速度和最终性能影响很大。",
        "id": 1508,
        "target_term": "model",
        "is_hardcore": true
    },
    {
        "topic": "Text Parsing",
        "prefix": "在模型训练过程中，我们讨论如何处理输入数据的解析问题。",
        "sentence_A": "在模型训练时，我们需要先进行 parsing，把原始数据转换成模型可以理解的格式。",
        "sentence_B": "在模型训练时，我们需要先进行解析，把原始数据转换成模型可以理解的格式。",
        "id": 1509,
        "target_term": "parsing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据路径时",
        "sentence_A": "我们需要确保 data path 是正确的，这样才能顺利加载数据。",
        "sentence_B": "我们需要确保数据路径是正确的，这样才能顺利加载数据。",
        "id": 1510,
        "target_term": "data path",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现了一些有趣的数据模式。",
        "sentence_A": "在模型训练过程中，我们发现了一些有趣的 data pattern。",
        "sentence_B": "在模型训练过程中，我们发现了一些有趣的数据模式。",
        "id": 1511,
        "target_term": "data pattern",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到需要调整某些参数以优化模型性能。",
        "sentence_A": "我们可能需要调整一下 learning rate，同时看看 penalty 的设置是否合理，以防止过拟合。",
        "sentence_B": "我们可能需要调整一下学习率，同时看看正则化项的设置是否合理，以防止过拟合。",
        "id": 1512,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Perceptron in Model Training",
        "prefix": "在模型训练的过程中，团队讨论如何优化感知器的性能。",
        "sentence_A": "在训练模型时，我们发现调整 perceptron 的参数可以显著提升准确率。",
        "sentence_B": "在训练模型时，我们发现调整感知器的参数可以显著提升准确率。",
        "id": 1513,
        "target_term": "perceptron",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们发现模型的性能出现了波动。",
        "sentence_A": "在模型训练过程中，我们发现模型的 performance 出现了波动。",
        "sentence_B": "在模型训练过程中，我们发现模型的性能出现了波动。",
        "id": 1514,
        "target_term": "performance",
        "is_hardcore": true
    },
    {
        "topic": "Model Robustness",
        "prefix": "在讨论模型鲁棒性时，团队提到了一个关键概念",
        "sentence_A": "我们在测试模型的鲁棒性时，发现通过对输入数据加入 small perturbation，可以有效检测模型的抗干扰能力。",
        "sentence_B": "我们在测试模型的鲁棒性时，发现通过对输入数据加入小扰动，可以有效检测模型的抗干扰能力。",
        "id": 1515,
        "target_term": "small perturbation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "我们在讨论模型训练的不同阶段",
        "sentence_A": "在每个 training phase，我们都需要监控模型的性能，确保没有过拟合。",
        "sentence_B": "在每个训练阶段，我们都需要监控模型的性能，确保没有过拟合。",
        "id": 1516,
        "target_term": "training phase",
        "is_hardcore": true
    },
    {
        "topic": "Speech Recognition",
        "prefix": "在模型训练过程中，我们讨论了如何优化语音识别模型的准确性。",
        "sentence_A": "我们要确保模型在处理不同 phoneme 时的准确性，这样才能提高整体的识别率。",
        "sentence_B": "我们要确保模型在处理不同音素时的准确性，这样才能提高整体的识别率。",
        "id": 1517,
        "target_term": "phoneme",
        "is_hardcore": true
    },
    {
        "topic": "Speech Recognition",
        "prefix": "在模型训练过程中，我们讨论了如何优化语音识别的准确率。",
        "sentence_A": "我们发现，如果能更准确地处理 phoneme，模型的性能会显著提升。",
        "sentence_B": "我们发现，如果能更准确地处理音素，模型的性能会显著提升。",
        "id": 1518,
        "target_term": "phoneme",
        "is_hardcore": true
    },
    {
        "topic": "NLP Model Training",
        "prefix": "在讨论模型训练中的数据预处理时",
        "sentence_A": "我们在数据清洗阶段需要特别注意每个 phrase 的处理，确保它们的上下文信息不被破坏。",
        "sentence_B": "我们在数据清洗阶段需要特别注意每个短语的处理，确保它们的上下文信息不被破坏。",
        "id": 1519,
        "target_term": "phrase",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在模型训练过程中，我们讨论了如何处理文本数据中的短语问题。",
        "sentence_A": "我们在训练模型时，特别关注了如何有效地处理这些 phrase，确保模型能够准确地理解语义。",
        "sentence_B": "我们在训练模型时，特别关注了如何有效地处理这些短语，确保模型能够准确地理解语义。",
        "id": 1520,
        "target_term": "phrase",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的物理资源需求时",
        "sentence_A": "我们需要确保有足够的 physical 资源来支持大规模的模型训练。",
        "sentence_B": "我们需要确保有足够的物理资源来支持大规模的模型训练。",
        "id": 1521,
        "target_term": "physical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们在训练模型时，发现数据集中有关于 physic 的部分需要特别处理。",
        "sentence_B": "我们在训练模型时，发现数据集中有关于物理的部分需要特别处理。",
        "id": 1522,
        "target_term": "physic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次团队会议中，讨论如何优化模型训练流程。",
        "sentence_A": "我们在模型训练的 planning 阶段，需要更加细致地考虑数据预处理和模型选择。",
        "sentence_B": "在模型训练的规划阶段，我们需要更加细致地考虑数据预处理和模型选择。",
        "id": 1523,
        "target_term": "planning",
        "is_hardcore": true
    },
    {
        "topic": "Model Training Platform",
        "prefix": "在讨论模型训练平台的选择时",
        "sentence_A": "我们在选择 model training platform 时，要考虑它的扩展性和易用性。",
        "sentence_B": "我们在选择模型训练平台时，要考虑它的扩展性和易用性。",
        "id": 1524,
        "target_term": "model training platform",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning Policy",
        "prefix": "在讨论强化学习模型的训练策略时",
        "sentence_A": "我们这次的训练方案需要明确每个阶段的 policy，这样才能确保模型在不同环境下的表现一致性。",
        "sentence_B": "我们这次的训练方案需要明确每个阶段的策略，这样才能确保模型在不同环境下的表现一致性。",
        "id": 1525,
        "target_term": "policy",
        "is_hardcore": true
    },
    {
        "topic": "Pooling in Neural Networks",
        "prefix": "在讨论模型优化时",
        "sentence_A": "我们在模型训练中使用了不同的 pool 方法来减少计算量。",
        "sentence_B": "我们在模型训练中使用了不同的池化方法来减少计算量。",
        "id": 1526,
        "target_term": "pool",
        "is_hardcore": true
    },
    {
        "topic": "Pooling in Convolutional Neural Networks",
        "prefix": "在讨论模型优化时",
        "sentence_A": "我们可以通过在卷积层后面加上 pooling 层来减少参数量，提高模型的鲁棒性。",
        "sentence_B": "我们可以通过在卷积层后面加上池化层来减少参数量，提高模型的鲁棒性。",
        "id": 1527,
        "target_term": "pooling",
        "is_hardcore": true
    },
    {
        "topic": "Data Sampling",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们这次的训练数据集是从整个 population 中随机抽取的，确保了样本的多样性和代表性。",
        "sentence_B": "我们这次的训练数据集是从整个总体中随机抽取的，确保了样本的多样性和代表性。",
        "id": 1528,
        "target_term": "population",
        "is_hardcore": true
    },
    {
        "topic": "Data Sampling",
        "prefix": "在讨论模型训练数据的采样方法时",
        "sentence_A": "我们在训练模型时需要从不同的 population 中抽取样本，以确保模型的泛化能力。",
        "sentence_B": "我们在训练模型时需要从不同的群体中抽取样本，以确保模型的泛化能力。",
        "id": 1529,
        "target_term": "population",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型的优化策略时",
        "sentence_A": "我们在训练模型时，要充分利用数据的 potential，以提高模型的泛化能力。",
        "sentence_B": "我们在训练模型时，要充分利用数据的潜力，以提高模型的泛化能力。",
        "id": 1530,
        "target_term": "potential",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的资源需求时",
        "sentence_A": "这次训练的模型参数量太大了，我们需要更多的 computational power 才能完成训练。",
        "sentence_B": "这次训练的模型参数量太大了，我们需要更多的计算能力才能完成训练。",
        "id": 1531,
        "target_term": "computational power",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，团队正在讨论模型的性能指标。",
        "sentence_A": "我们在测试集上跑了模型，发现 precision 挺高的，但 recall 还需要优化。",
        "sentence_B": "我们在测试集上运行了模型，发现精确率很高，但召回率还需要优化。",
        "id": 1532,
        "target_term": "precision",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常讨论预测的准确性。",
        "sentence_A": "在训练过程中，我们需要不断优化模型的 prediction 准确率。",
        "sentence_B": "在训练过程中，我们需要不断优化模型的预测准确率。",
        "id": 1533,
        "target_term": "prediction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队提到了用户偏好对模型性能的影响。",
        "sentence_A": "在训练模型时，我们发现用户的 preference 对模型的推荐效果影响很大。",
        "sentence_B": "在训练模型时，我们发现用户的偏好对模型的推荐效果影响很大。",
        "id": 1534,
        "target_term": "preference",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的过程中，团队成员提到预训练模型的重要性。",
        "sentence_A": "在我们的项目中，pretraining 阶段对模型的最终性能影响很大，所以我们需要花更多时间在这上面。",
        "sentence_B": "在我们的项目中，预训练阶段对模型的最终性能影响很大，所以我们需要花更多时间在这上面。",
        "id": 1535,
        "target_term": "pretraining",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在选择数据集的时候，要考虑到 principal 组件的重要性，确保模型在关键特征上表现良好。",
        "sentence_B": "我们在选择数据集的时候，要考虑到主成分的重要性，确保模型在关键特征上表现良好。",
        "id": 1536,
        "target_term": "principal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "在设置模型参数时，我们通常会用到 prior 来初始化权重，这样可以提高模型的收敛速度。",
        "sentence_B": "在设置模型参数时，我们通常会用到先验来初始化权重，这样可以提高模型的收敛速度。",
        "id": 1537,
        "target_term": "prior",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练任务的优先级时",
        "sentence_A": "我们需要根据任务的 priority 来安排模型训练的顺序。",
        "sentence_B": "我们需要根据任务的优先级来安排模型训练的顺序。",
        "id": 1538,
        "target_term": "priority",
        "is_hardcore": true
    },
    {
        "topic": "Data Privacy in Model Training",
        "prefix": "在讨论模型训练数据的处理时",
        "sentence_A": "我们在处理训练数据时，一定要确保用户的 privacy 不被泄露。",
        "sentence_B": "我们在处理训练数据时，一定要确保用户的隐私不被泄露。",
        "id": 1539,
        "target_term": "privacy",
        "is_hardcore": true
    },
    {
        "topic": "Probabilistic Modeling",
        "prefix": "在讨论模型训练的策略时",
        "sentence_A": "我们在模型训练中使用了 probabilistic 方法，这样可以更好地处理不确定性和噪声。",
        "sentence_B": "我们在模型训练中使用了概率方法，这样可以更好地处理不确定性和噪声。",
        "id": 1540,
        "target_term": "probabilistic",
        "is_hardcore": true
    },
    {
        "topic": "Probability in Model Training",
        "prefix": "在讨论模型训练的准确性和稳定性时",
        "sentence_A": "我们在调整超参数时，需要考虑 probability 的分布，以确保模型在不同数据集上的表现更加稳定。",
        "sentence_B": "我们在调整超参数时，需要考虑概率的分布，以确保模型在不同数据集上的表现更加稳定。",
        "id": 1541,
        "target_term": "probability",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练流程时",
        "sentence_A": "我们在训练模型的时候，需要优化整个 training proces，确保每个步骤都高效运行。",
        "sentence_B": "我们在训练模型的时候，需要优化整个训练过程，确保每个步骤都高效运行。",
        "id": 1542,
        "target_term": "training proces",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们在准备模型上线时，需要确保在 production 环境中不会出现性能问题。",
        "sentence_B": "我们在准备模型上线时，需要确保在生产环境中不会出现性能问题。",
        "id": 1543,
        "target_term": "production",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员讨论如何优化训练流程。",
        "sentence_A": "我们在训练模型时，需要写一个 program 来自动化数据预处理和模型调参。",
        "sentence_B": "我们在训练模型时，需要编写一个程序来自动化数据预处理和模型调参。",
        "id": 1544,
        "target_term": "program",
        "is_hardcore": true
    },
    {
        "topic": "Code Optimization",
        "prefix": "在讨论模型训练时的代码优化问题",
        "sentence_A": "我们在进行模型训练时，发现有些编程技巧可以显著提升效率，比如使用多线程和异步 I/O。",
        "sentence_B": "我们在进行模型训练时，发现有些编程技巧可以显著提升效率，比如使用多线程和异步 I/O。",
        "id": 1545,
        "target_term": "I",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化策略时，",
        "sentence_A": "我们可以通过 projection 将高维数据映射到低维空间，这样可以提高模型的训练效率。",
        "sentence_B": "我们可以通过投影将高维数据映射到低维空间，这样可以提高模型的训练效率。",
        "id": 1546,
        "target_term": "projection",
        "is_hardcore": true
    },
    {
        "topic": "Error Propagation",
        "prefix": "在讨论模型训练时，团队成员提到了误差传播的问题。",
        "sentence_A": "在训练过程中，我们需要注意 error propagation，确保误差能够有效传递，从而优化模型性能。",
        "sentence_B": "在训练过程中，我们需要注意误差传播，确保误差能够有效传递，从而优化模型性能。",
        "id": 1547,
        "target_term": "error propagation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时，团队成员提出了一个新的建议。",
        "sentence_A": "我们在模型训练的优化方案中提出了一个新的 proposal，希望能提高模型的收敛速度。",
        "sentence_B": "我们在模型训练的优化方案中提出了一个新的提案，希望能提高模型的收敛速度。",
        "id": 1548,
        "target_term": "proposal",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference",
        "prefix": "在讨论模型训练和推理优化的过程中，团队成员提到了数据传输的标准。",
        "sentence_A": "我们在训练模型时，需要确保数据传输的 protocol 是安全且高效的。",
        "sentence_B": "我们在训练模型时，需要确保数据传输的协议是安全且高效的。",
        "id": 1549,
        "target_term": "protocol",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论新模型的初步设计时，团队成员提到需要先开发一个原型来验证想法。",
        "sentence_A": "在讨论新模型的初步设计时，我们决定先开发一个 prototype 来验证想法。",
        "sentence_B": "在讨论新模型的初步设计时，我们决定先开发一个原型来验证想法。",
        "id": 1550,
        "target_term": "prototype",
        "is_hardcore": true
    },
    {
        "topic": "Proximal Gradient Methods",
        "prefix": "在讨论模型优化方法时，团队成员提到一个重要的技术点。",
        "sentence_A": "在训练这个模型时，我们发现使用 proximal 算法可以显著提高收敛速度。",
        "sentence_B": "在训练这个模型时，我们发现使用近端算法可以显著提高收敛速度。",
        "id": 1551,
        "target_term": "proximal",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在一次团队会议中，讨论模型优化方案时。",
        "sentence_A": "我们可以在模型训练后期进行一些 pruning，这样可以减少模型的大小，提高推理速度。",
        "sentence_B": "我们可以在模型训练后期进行一些剪枝，这样可以减少模型的大小，提高推理速度。",
        "id": 1552,
        "target_term": "pruning",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署策略时",
        "sentence_A": "我们在部署这个模型时，需要考虑将 API 设计为 public，这样外部系统才能调用。",
        "sentence_B": "我们在部署这个模型时，需要考虑将 API 设计为公共的，这样外部系统才能调用。",
        "id": 1553,
        "target_term": "API",
        "is_hardcore": true
    },
    {
        "topic": "Data Cleaning",
        "prefix": "在数据清洗过程中，我们讨论如何处理文本中的标点符号。",
        "sentence_A": "在处理这段文本时，我们需要注意 punctuation 的处理，确保不会影响模型的性能。",
        "sentence_B": "在处理这段文本时，我们需要注意标点符号的处理，确保不会影响模型的性能。",
        "id": 1554,
        "target_term": "punctuation",
        "is_hardcore": true
    },
    {
        "topic": "Model Quantization",
        "prefix": "在讨论模型优化时，",
        "sentence_A": "我们在模型训练过程中引入了 quantification 技术，大大提高了模型的推理速度和部署效率。",
        "sentence_B": "我们在模型训练过程中引入了量化技术，大大提高了模型的推理速度和部署效率。",
        "id": 1555,
        "target_term": "quantification",
        "is_hardcore": true
    },
    {
        "topic": "Model Optimization",
        "prefix": "在模型训练完成后，我们通常会对模型进行一系列的优化操作，以提高其在实际部署中的性能。",
        "sentence_A": "训练完模型后，我们通常会用 quantization 来减少模型的存储和计算开销。",
        "sentence_B": "训练完模型后，我们通常会用量化来减少模型的存储和计算开销。",
        "id": 1556,
        "target_term": "quantization",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的多样性时",
        "sentence_A": "我们还需要增加一些复杂的 query 来提高模型的泛化能力。",
        "sentence_B": "我们还需要增加一些复杂的查询来提高模型的泛化能力。",
        "id": 1557,
        "target_term": "query",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了一个重要的问题。",
        "sentence_A": "在训练这个模型的时候，我们遇到了一个关于 data imbalance 的 question，需要大家一起讨论解决。",
        "sentence_B": "在训练这个模型的时候，我们遇到了一个关于数据不平衡的问题，需要大家一起讨论解决。",
        "id": 1558,
        "target_term": "data imbalance",
        "is_hardcore": true
    },
    {
        "topic": "Ranking Algorithm Optimization",
        "prefix": "在模型训练过程中，我们讨论了如何优化推荐系统的排名算法。",
        "sentence_A": "在训练模型时，我们发现通过调整特征权重可以显著提升 ranking 的准确性。",
        "sentence_B": "在训练模型时，我们发现通过调整特征权重可以显著提升排名的准确性。",
        "id": 1559,
        "target_term": "ranking",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率时",
        "sentence_A": "我们需要关注训练集和验证集的 ratio，以确保模型不会过拟合。",
        "sentence_B": "我们需要关注训练集和验证集的比例，以确保模型不会过拟合。",
        "id": 1560,
        "target_term": "ratio",
        "is_hardcore": false
    },
    {
        "topic": "Data Preprocessing",
        "prefix": "在数据清洗过程中，我们讨论了不同特征的分布情况。",
        "sentence_A": "我们在数据清洗时，需要特别注意各个特征的 ratio，这样才能确保模型的训练数据是平衡的。",
        "sentence_B": "我们在数据清洗时，需要特别注意各个特征的比例，这样才能确保模型的训练数据是平衡的。",
        "id": 1561,
        "target_term": "ratio",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论如何优化超参数以提高模型的泛化能力。",
        "sentence_A": "我们在讨论如何设置更 rational 的超参数，以确保模型在新数据上的表现。",
        "sentence_B": "我们在讨论如何设置更合理的超参数，以确保模型在新数据上的表现。",
        "id": 1562,
        "target_term": "rational",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的真实性时，团队成员提到",
        "sentence_A": "我们需要确保训练数据是 real 的，这样模型才能在实际场景中表现良好。",
        "sentence_B": "我们需要确保训练数据是真实的，这样模型才能在实际场景中表现良好。",
        "id": 1563,
        "target_term": "real",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到一个常见的问题。",
        "sentence_A": "我们在训练模型时遇到的一个常见问题是数据不平衡，这可能是因为数据采集的 reason 不够多样化。",
        "sentence_B": "我们在训练模型时遇到的一个常见问题是数据不平衡，这可能是因为数据采集的原因不够多样化。",
        "id": 1564,
        "target_term": "reason",
        "is_hardcore": true
    },
    {
        "topic": "Speech Recognition",
        "prefix": "在一次团队会议中，讨论如何优化语音识别模型的准确率。",
        "sentence_A": "我们在训练模型时，发现 speech recognition 的准确率在噪声环境下的表现不佳。",
        "sentence_B": "我们在训练模型时，发现语音识别的准确率在噪声环境下的表现不佳。",
        "id": 1565,
        "target_term": "speech recognition",
        "is_hardcore": true
    },
    {
        "topic": "Recurrent Neural Networks",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练这个模型时，需要特别注意处理 recurrent 部分的优化，确保长序列数据的处理效果。",
        "sentence_B": "我们在训练这个模型时，需要特别注意处理循环部分的优化，确保长序列数据的处理效果。",
        "id": 1566,
        "target_term": "recurrent",
        "is_hardcore": true
    },
    {
        "topic": "Recursion in Algorithm Design",
        "prefix": "在讨论模型优化的过程中",
        "sentence_A": "我们在设计算法时，经常会用到 recursion，特别是在处理树状结构的数据时。",
        "sentence_B": "我们在设计算法时，经常会用到递归，特别是在处理树状结构的数据时。",
        "id": 1567,
        "target_term": "recursion",
        "is_hardcore": true
    },
    {
        "topic": "Recursive Algorithms",
        "prefix": "在模型训练过程中，我们遇到了一个递归算法的优化问题。",
        "sentence_A": "在模型训练过程中，我们发现这个 recursive 算法的性能瓶颈，需要优化。",
        "sentence_B": "在模型训练过程中，我们发现这个递归算法的性能瓶颈，需要优化。",
        "id": 1568,
        "target_term": "recursive",
        "is_hardcore": true
    },
    {
        "topic": "Dimensionality Reduction",
        "prefix": "在模型训练过程中，我们经常需要处理高维数据，这时候降维技术就显得尤为重要。",
        "sentence_A": "我们在处理高维数据时，需要考虑 dimensionality reduction，这样才能提高模型的效率和可解释性。",
        "sentence_B": "我们在处理高维数据时，需要考虑降维，这样才能提高模型的效率和可解释性。",
        "id": 1569,
        "target_term": "dimensionality reduction",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型过拟合问题时",
        "sentence_A": "我们在训练模型时，为了防止过拟合，通常会用到 regularization 技术。",
        "sentence_B": "我们在训练模型时，为了防止过拟合，通常会用到正则化技术。",
        "id": 1570,
        "target_term": "regularization",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning in Model Training",
        "prefix": "在讨论如何优化模型训练时，团队成员提到了强化学习的重要性。",
        "sentence_A": "我们在训练模型时，可以考虑用 reinforcement 来优化策略，这样能更好地模拟真实环境中的决策过程。",
        "sentence_B": "我们在训练模型时，可以考虑用强化学习来优化策略，这样能更好地模拟真实环境中的决策过程。",
        "id": 1571,
        "target_term": "reinforcement",
        "is_hardcore": true
    },
    {
        "topic": "Data Relationship in Model Training",
        "prefix": "在讨论模型训练数据集时",
        "sentence_A": "我们需要确保每个数据点的 relation 都是准确的，这样才能保证模型的训练效果。",
        "sentence_B": "我们需要确保每个数据点的关系都是准确的，这样才能保证模型的训练效果。",
        "id": 1572,
        "target_term": "relation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的数据准备阶段时",
        "sentence_A": "在处理用户行为数据时，我们需要特别关注 user 和 item 之间的 relationship，这样才能更好地训练推荐模型。",
        "sentence_B": "在处理用户行为数据时，我们需要特别关注用户和项目之间的关系，这样才能更好地训练推荐模型。",
        "id": 1573,
        "target_term": "user",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了特征选择的重要性。",
        "sentence_A": "我们在讨论特征选择时，特别强调了特征与目标变量的 relevance。",
        "sentence_B": "我们在讨论特征选择时，特别强调了特征与目标变量的相关性。",
        "id": 1574,
        "target_term": "relevance",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性和性能时",
        "sentence_A": "我们在训练这个模型时，不仅要关注精度，还要确保它的 reliability，这样才能保证在实际应用中的稳定性。",
        "sentence_B": "我们在训练这个模型时，不仅要关注精度，还要确保它的可靠性，这样才能保证在实际应用中的稳定性。",
        "id": 1575,
        "target_term": "reliability",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中遇到的问题讨论",
        "sentence_A": "我们发现模型在某些数据上表现不佳，需要对这些数据进行 repair，以提高模型的鲁棒性。",
        "sentence_B": "我们发现模型在某些数据上表现不佳，需要对这些数据进行修复，以提高模型的鲁棒性。",
        "id": 1576,
        "target_term": "repair",
        "is_hardcore": false
    },
    {
        "topic": "Feature Representation",
        "prefix": "在模型训练过程中，我们讨论了如何优化特征表示的问题。",
        "sentence_A": "我们在训练模型时，发现通过优化 feature representation 可以显著提升模型性能。",
        "sentence_B": "我们在训练模型时，发现通过优化特征表示可以显著提升模型性能。",
        "id": 1577,
        "target_term": "feature representation",
        "is_hardcore": true
    },
    {
        "topic": "Residual Networks",
        "prefix": "在模型训练过程中，我们讨论了如何处理残差块的优化问题。",
        "sentence_A": "我们在训练过程中发现，使用 residual 块可以显著提高模型的性能。",
        "sentence_B": "我们在训练过程中发现，使用残差块可以显著提高模型的性能。",
        "id": 1578,
        "target_term": "residual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的图像输入参数时",
        "sentence_A": "我们这次的模型训练，输入图像的 resolution 要设置为 1080p，以确保细节的清晰度。",
        "sentence_B": "我们这次的模型训练，输入图像的分辨率要设置为 1080p，以确保细节的清晰度。",
        "id": 1579,
        "target_term": "resolution",
        "is_hardcore": true
    },
    {
        "topic": "Resource Management in Model Training",
        "prefix": "在讨论模型训练资源分配时",
        "sentence_A": "我们这次训练需要更多的 compute resource，不然模型收敛速度会慢很多。",
        "sentence_B": "我们这次训练需要更多的计算资源，不然模型收敛速度会慢很多。",
        "id": 1580,
        "target_term": "compute resource",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练资源分配时",
        "sentence_A": "我们这次的模型训练需要大量的 computing resource，特别是 GPU 和存储空间。",
        "sentence_B": "我们这次的模型训练需要大量的计算资源，特别是 GPU 和存储空间。",
        "id": 1581,
        "target_term": "computing resource",
        "is_hardcore": true
    },
    {
        "topic": "Information Retrieval",
        "prefix": "我们在讨论如何优化搜索模型的检索效率时，提到了retrieval的重要性。",
        "sentence_A": "在训练模型时，我们发现提高 retrieval 的效率对整体性能提升非常关键。",
        "sentence_B": "在训练模型时，我们发现提高检索效率对整体性能提升非常关键。",
        "id": 1582,
        "target_term": "retrieval",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论如何优化强化学习模型的训练过程时，团队成员提到了奖励机制的重要性。",
        "sentence_A": "在训练这个模型的时候，我们发现调整 reward 的设置对最终性能影响很大。",
        "sentence_B": "在训练这个模型的时候，我们发现调整奖励的设置对最终性能影响很大。",
        "id": 1583,
        "target_term": "reward",
        "is_hardcore": true
    },
    {
        "topic": "Reinforcement Learning",
        "prefix": "在讨论如何优化强化学习模型的奖励机制时",
        "sentence_A": "我们在设计 reward 函数时，需要确保它能够准确反映我们希望模型优化的目标。",
        "sentence_B": "我们在设计奖励函数时，需要确保它能够准确反映我们希望模型优化的目标。",
        "id": 1584,
        "target_term": "reward",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论如何优化机器人的行为模型时",
        "sentence_A": "我们今天主要讨论如何通过强化学习来优化这个 robot 的行为模型。",
        "sentence_B": "我们今天主要讨论如何通过强化学习来优化这个机器人的行为模型。",
        "id": 1585,
        "target_term": "robot",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次会议中，团队讨论如何改进机器人的自然语言处理能力。",
        "sentence_A": "我们需要在模型中加入更多的 robotic 语音数据，以提高机器人的自然语言处理能力。",
        "sentence_B": "我们需要在模型中加入更多的机器人语音数据，以提高机器人的自然语言处理能力。",
        "id": 1586,
        "target_term": "robotic",
        "is_hardcore": true
    },
    {
        "topic": "Robotics in Model Training",
        "prefix": "在讨论模型训练的数据集时",
        "sentence_A": "我们在训练模型时，需要确保数据集中包含足够多的 robotic 相关的场景，这样才能更好地优化算法。",
        "sentence_B": "我们在训练模型时，需要确保数据集中包含足够多的机器人技术相关的场景，这样才能更好地优化算法。",
        "id": 1587,
        "target_term": "robotic",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时",
        "sentence_A": "我们需要确保模型在不同数据集上表现得足够 robust，这样才能在实际应用中保持高可靠性。",
        "sentence_B": "我们需要确保模型在不同数据集上表现得足够稳健，这样才能在实际应用中保持高可靠性。",
        "id": 1588,
        "target_term": "robust",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们讨论了如何提高模型的鲁棒性。",
        "sentence_A": "我们在训练模型时，特别关注了模型的 robustnes，确保它在各种数据分布下都能表现良好。",
        "sentence_B": "我们在训练模型时，特别关注了模型的鲁棒性，确保它在各种数据分布下都能表现良好。",
        "id": 1589,
        "target_term": "robustnes",
        "is_hardcore": true
    },
    {
        "topic": "Rule-Based Systems in AI",
        "prefix": "在模型训练中，我们需要确保数据符合特定的规则。",
        "sentence_A": "在训练模型时，我们通常会用一些 rule 来确保数据的正确性和一致性。",
        "sentence_B": "在训练模型时，我们通常会用一些规则来确保数据的正确性和一致性。",
        "id": 1590,
        "target_term": "rule",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论会上，团队成员正在讨论如何确保模型在不同环境下的安全性。",
        "sentence_A": "我们这次训练模型时，一定要特别注意 model 的 safety，确保它在各种环境下的表现都稳定可靠。",
        "sentence_B": "我们这次训练模型时，一定要特别注意模型的安全性，确保它在各种环境下的表现都稳定可靠。",
        "id": 1591,
        "target_term": "model",
        "is_hardcore": true
    },
    {
        "topic": "Data Sampling in Model Training",
        "prefix": "在讨论如何优化模型训练数据集时",
        "sentence_A": "我们在进行模型训练时，需要通过对数据集进行 sampling 来确保训练的效率和效果。",
        "sentence_B": "在进行模型训练时，需要通过对数据集进行采样来确保训练的效率和效果。",
        "id": 1592,
        "target_term": "sampling",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中的参数设置时",
        "sentence_A": "在训练模型时，我们需要调整 learning rate 这个 scalar，以确保模型能够稳定收敛。",
        "sentence_B": "在训练模型时，我们需要调整学习率这个标量，以确保模型能够稳定收敛。",
        "id": 1593,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到扩展性问题。",
        "sentence_A": "我们在训练这个模型时，需要考虑如何在更大的数据集上进行 scale，确保性能不会下降。",
        "sentence_B": "我们在训练这个模型时，需要考虑如何在更大的数据集上进行扩展，确保性能不会下降。",
        "id": 1594,
        "target_term": "scale",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化的过程中",
        "sentence_A": "我们在进行模型训练时，经常需要考虑 scaling 的问题，特别是在处理大数据集时。",
        "sentence_B": "我们在进行模型训练时，经常需要考虑扩展的问题，特别是在处理大数据集时。",
        "id": 1595,
        "target_term": "scaling",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论如何优化模型训练和推理过程的会议中",
        "sentence_A": "我们在讨论如何优化模型训练和推理的 scheduling，确保资源利用最大化。",
        "sentence_B": "我们在讨论如何优化模型训练和推理的调度，确保资源利用最大化。",
        "id": 1596,
        "target_term": "scheduling",
        "is_hardcore": true
    },
    {
        "topic": "Data Schema Design",
        "prefix": "在讨论模型训练数据结构时",
        "sentence_A": "我们在设计数据 schema 时，需要确保每个字段的类型和格式都符合要求。",
        "sentence_B": "我们在设计数据模式时，需要确保每个字段的类型和格式都符合要求。",
        "id": 1597,
        "target_term": "schema",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练过程中，团队正在讨论如何评估模型的性能。",
        "sentence_A": "我们在模型训练的最后阶段，需要对不同模型的性能进行 scoring，确保选择最优模型。",
        "sentence_B": "我们在模型训练的最后阶段，需要对不同模型的性能进行评分，确保选择最优模型。",
        "id": 1598,
        "target_term": "scoring",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练中的超参数优化时",
        "sentence_A": "我们这次可以尝试用不同的 search 策略来优化超参数，看看能不能找到更好的模型配置。",
        "sentence_B": "我们可以尝试使用不同的搜索策略来优化超参数，看看是否能找到更好的模型配置。",
        "id": 1599,
        "target_term": "search",
        "is_hardcore": false
    },
    {
        "topic": "Search Algorithm Optimization",
        "prefix": "在讨论模型训练过程中，团队成员提到搜索算法的优化问题。",
        "sentence_A": "在模型训练中，我们发现通过改进 searching 算法可以显著提高模型的性能。",
        "sentence_B": "在模型训练中，我们发现通过改进搜索算法可以显著提高模型的性能。",
        "id": 1600,
        "target_term": "searching",
        "is_hardcore": true
    },
    {
        "topic": "Time Series Analysis",
        "prefix": "在讨论时间序列模型的特征工程时",
        "sentence_A": "我们在这次的模型训练中，需要特别关注 seasonal 特征的处理，因为这对预测结果的准确性有很大影响。",
        "sentence_B": "我们在这次的模型训练中，需要特别关注季节性特征的处理，因为这对预测结果的准确性有很大影响。",
        "id": 1601,
        "target_term": "seasonal",
        "is_hardcore": true
    },
    {
        "topic": "Image Segmentation",
        "prefix": "在模型训练过程中，团队讨论如何优化图像分割的精度。",
        "sentence_A": "我们在训练模型时，发现 segmentation 的精度还有提升空间，需要进一步优化数据预处理和模型结构。",
        "sentence_B": "我们在训练模型时，发现图像分割的精度还有提升空间，需要进一步优化数据预处理和模型结构。",
        "id": 1602,
        "target_term": "segmentation",
        "is_hardcore": true
    },
    {
        "topic": "Feature Selection in Model Training",
        "prefix": "在讨论特征选择对模型性能的影响时，团队成员提到：",
        "sentence_A": "在模型训练中，正确的 feature selection 对性能提升至关重要。",
        "sentence_B": "在模型训练中，正确的特征选择对性能提升至关重要。",
        "id": 1603,
        "target_term": "feature selection",
        "is_hardcore": true
    },
    {
        "topic": "Object-Oriented Programming in AI Models",
        "prefix": "在讨论模型类的定义时",
        "sentence_A": "在定义模型类的时候，我们通常会用到 self 这个关键字，它代表类的实例对象。",
        "sentence_B": "在定义模型类的时候，我们通常会用到“self”这个关键字，它代表类的实例对象。",
        "id": 1604,
        "target_term": "self",
        "is_hardcore": true
    },
    {
        "topic": "Semantic Understanding",
        "prefix": "在一次模型训练的讨论中，团队成员正在探讨如何优化模型的语义理解能力。",
        "sentence_A": "我们在训练模型的时候，需要特别关注模型的 semantic 理解能力，这直接影响到最终的推理效果。",
        "sentence_B": "我们在训练模型的时候，需要特别关注模型的语义理解能力，这直接影响到最终的推理效果。",
        "id": 1605,
        "target_term": "semantic",
        "is_hardcore": true
    },
    {
        "topic": "Natural Language Processing",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练这个模型时，特别关注了 sematic 的准确性和上下文的一致性。",
        "sentence_B": "我们在训练这个模型时，特别关注了语义的准确性和上下文的一致性。",
        "id": 1606,
        "target_term": "sematic",
        "is_hardcore": true
    },
    {
        "topic": "Sequence Processing in NLP",
        "prefix": "在讨论模型训练的过程中，团队成员提到了数据预处理的重要性。",
        "sentence_A": "在处理这个任务时，我们发现对 sequence 的预处理非常关键，尤其是 padding 和 truncation 的方式。",
        "sentence_B": "在处理这个任务时，我们发现对序列的预处理非常关键，尤其是填充和截断的方式。",
        "id": 1607,
        "target_term": "sequence",
        "is_hardcore": true
    },
    {
        "topic": "Sequence Processing in Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理各种序列数据。",
        "sentence_A": "在处理这些 sequence 的时候，我们需要确保数据的时序性不被破坏。",
        "sentence_B": "在处理这些序列的时候，我们需要确保数据的时序性不被破坏。",
        "id": 1608,
        "target_term": "sequence",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在讨论模型部署时",
        "sentence_A": "我们今天主要讨论的是如何优化模型在 server 上的推理速度。",
        "sentence_B": "我们今天主要讨论的是如何优化模型在服务器上的推理速度。",
        "id": 1609,
        "target_term": "server",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在部署模型时，我们讨论了服务器的配置问题。",
        "sentence_A": "我们需要确保这些 server 的配置足够高，以支持模型的高效运行。",
        "sentence_B": "我们需要确保这些服务器的配置足够高，以支持模型的高效运行。",
        "id": 1610,
        "target_term": "server",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的维度时，团队成员提到",
        "sentence_A": "这次的数据集的 shape 是 (10000, 256)，我们应该检查一下是否有问题。",
        "sentence_B": "这次的数据集的形状是 (10000, 256)，我们应该检查一下是否有问题。",
        "id": 1611,
        "target_term": "shape",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在训练模型时，需要特别注意输入数据的 shape，因为不同的 shape 可能会影响模型的性能。",
        "sentence_B": "在训练模型时，需要特别注意输入数据的形状，因为不同的形状可能会影响模型的性能。",
        "id": 1612,
        "target_term": "shape",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员正在讨论如何优化数据分发策略。",
        "sentence_A": "我们在讨论如何通过更好的 data sharing 机制来提高模型训练的效率。",
        "sentence_B": "我们在讨论如何通过更好的数据共享机制来提高模型训练的效率。",
        "id": 1613,
        "target_term": "data sharing",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中数据分布变化的问题时",
        "sentence_A": "我们在训练过程中发现数据分布的 shift 非常明显，需要及时调整模型以适应新的数据。",
        "sentence_B": "我们在训练过程中发现数据分布的变化非常明显，需要及时调整模型以适应新的数据。",
        "id": 1614,
        "target_term": "shift",
        "is_hardcore": true
    },
    {
        "topic": "Feature Engineering",
        "prefix": "在讨论如何优化推荐系统时",
        "sentence_A": "我们在处理用户兴趣向量时，使用 cosine similarity 来度量不同用户之间的兴趣相似度。",
        "sentence_B": "我们在处理用户兴趣向量时，使用余弦相似度来度量不同用户之间的兴趣相似度。",
        "id": 1615,
        "target_term": "cosine similarity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的仿真环境时",
        "sentence_A": "我们在进行模型训练时，需要在 simulation 环境中反复测试，确保模型的稳定性和准确性。",
        "sentence_B": "我们在进行模型训练时，需要在仿真环境中反复测试，确保模型的稳定性和准确性。",
        "id": 1616,
        "target_term": "simulation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们这次训练的时候，batch size 设置为 single，看看效果如何。",
        "sentence_B": "我们这次训练的时候，批量大小设置为单个，看看效果如何。",
        "id": 1617,
        "target_term": "batch size",
        "is_hardcore": true
    },
    {
        "topic": "AI Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员提到技术奇点对未来的影响。",
        "sentence_A": "我们在训练这个模型时，要考虑 singularity 带来的影响，确保模型在未来的数据环境下依然有效。",
        "sentence_B": "我们在训练这个模型时，要考虑技术奇点带来的影响，确保模型在未来的数据环境下依然有效。",
        "id": 1618,
        "target_term": "singularity",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中所需的技术能力时",
        "sentence_A": "这次的模型训练任务需要很强的 skill，特别是在数据预处理和特征工程方面。",
        "sentence_B": "这次的模型训练任务需要很强的技能，特别是在数据预处理和特征工程方面。",
        "id": 1619,
        "target_term": "skill",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的需求时",
        "sentence_A": "我们要确保团队成员具备足够的 machine learning skill，这样才能高效地完成模型训练任务。",
        "sentence_B": "我们要确保团队成员具备足够的机器学习技能，这样才能高效地完成模型训练任务。",
        "id": 1620,
        "target_term": "machine learning skill",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到软件工具的选择对效率的影响。",
        "sentence_A": "在训练模型时，一个好的 software 可以大大提升我们的效率，减少很多不必要的麻烦。",
        "sentence_B": "在训练模型时，一个好的软件工具可以大大提升我们的效率，减少很多不必要的麻烦。",
        "id": 1621,
        "target_term": "software",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方案时",
        "sentence_A": "我们正在寻找一个更好的 solution 来提高模型的训练效率。",
        "sentence_B": "我们正在寻找一个更好的解决方案来提高模型的训练效率。",
        "id": 1622,
        "target_term": "solution",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，讨论特征空间的维度问题",
        "sentence_A": "我们在训练模型时，发现这个特征的 dimension 在 feature space 里太低了，需要增加一些维度来提高模型的表达能力。",
        "sentence_B": "我们在训练模型时，发现这个特征的维度在特征空间里太低了，需要增加一些维度来提高模型的表达能力。",
        "id": 1623,
        "target_term": "dimension",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的参数设置时",
        "sentence_A": "我们在训练模型时，需要特别注意不同特征的 space，以确保模型的泛化能力。",
        "sentence_B": "我们在训练模型时，需要特别注意不同特征的空间，以确保模型的泛化能力。",
        "id": 1624,
        "target_term": "space",
        "is_hardcore": true
    },
    {
        "topic": "Spatial Data Processing",
        "prefix": "在模型训练过程中，我们遇到一个问题需要处理空间数据。",
        "sentence_A": "在训练这个模型时，我们发现处理 spatial 数据的效率很低，需要优化算法。",
        "sentence_B": "在训练这个模型时，我们发现处理空间数据的效率很低，需要优化算法。",
        "id": 1625,
        "target_term": "spatial",
        "is_hardcore": true
    },
    {
        "topic": "Spectral Analysis in Model Training",
        "prefix": "在模型训练过程中，我们经常需要分析特征的频谱特性。",
        "sentence_A": "在训练这个模型的时候，我们发现使用 spectral 方法可以更好地捕捉数据的频谱特征。",
        "sentence_B": "在训练这个模型的时候，我们发现使用频谱方法可以更好地捕捉数据的频谱特征。",
        "id": 1626,
        "target_term": "spectral",
        "is_hardcore": true
    },
    {
        "topic": "Speech Recognition",
        "prefix": "在模型训练过程中，我们发现了一些问题。",
        "sentence_A": "在训练模型时，我们发现 speech 的识别准确率在某些场景下不够高。",
        "sentence_B": "在训练模型时，我们发现语音的识别准确率在某些场景下不够高。",
        "id": 1627,
        "target_term": "speech",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference Optimization",
        "prefix": "在讨论模型推理优化时",
        "sentence_A": "我们可以通过减少模型的参数量来提高 inference 的 speed。",
        "sentence_B": "我们可以通过减少模型的参数量来提高推理的速度。",
        "id": 1628,
        "target_term": "inference",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在最近的一次模型训练中，团队遇到了一些问题。",
        "sentence_A": "我们在最新的模型训练中遇到了一些问题，特别是在大规模数据集上，模型的 stability 显著下降。",
        "sentence_B": "我们在最新的模型训练中遇到了一些问题，特别是在大规模数据集上，模型的稳定性显著下降。",
        "id": 1629,
        "target_term": "stability",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时，团队成员提到：",
        "sentence_A": "我们最近的实验结果显示，这个模型在不同数据集上表现得相当 stable，这对我们来说是个好兆头。",
        "sentence_B": "我们最近的实验结果显示，这个模型在不同数据集上表现得相当稳定，这对我们来说是个好兆头。",
        "id": 1630,
        "target_term": "stable",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的架构选择时",
        "sentence_A": "我们在选择模型训练的 stack 时，需要考虑多个因素，比如计算资源、模型复杂度和训练时间。",
        "sentence_B": "我们在选择模型训练的堆栈时，需要考虑多个因素，比如计算资源、模型复杂度和训练时间。",
        "id": 1631,
        "target_term": "stack",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论如何优化模型结构时，团队成员提到：",
        "sentence_A": "我们可以尝试用 stacked 的多层网络来提升模型的性能。",
        "sentence_B": "我们可以尝试使用堆叠的多层网络来提升模型的性能。",
        "id": 1632,
        "target_term": "stacked",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队讨论了数据预处理的标准问题。",
        "sentence_A": "在模型训练过程中，我们讨论了数据预处理的 standard，确保数据质量和一致性。",
        "sentence_B": "在模型训练过程中，我们讨论了数据预处理的标准，确保数据质量和一致性。",
        "id": 1633,
        "target_term": "standard",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化的过程中，团队成员提到一个重要的概念。",
        "sentence_A": "在训练模型时，我们通常会设置一些 static 参数，这样可以确保模型在不同环境下的稳定性。",
        "sentence_B": "在训练模型时，我们通常会设置一些静态参数，这样可以确保模型在不同环境下的稳定性。",
        "id": 1634,
        "target_term": "static",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据的预处理时",
        "sentence_A": "我们在处理数据时，需要确保每个 station 的数据都被正确标记，这样才能保证模型的准确性。",
        "sentence_B": "我们在处理数据时，需要确保每个站点的数据都被正确标记，这样才能保证模型的准确性。",
        "id": 1635,
        "target_term": "station",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练过程中，团队成员提到数据的特性对模型的影响。",
        "sentence_A": "我们在训练模型时，需要注意数据是否是 stationary，这直接影响模型的稳定性和泛化能力。",
        "sentence_B": "我们在训练模型时，需要注意数据是否是平稳的，这直接影响模型的稳定性和泛化能力。",
        "id": 1636,
        "target_term": "stationary",
        "is_hardcore": true
    },
    {
        "topic": "Statistical Analysis in Model Training",
        "prefix": "在讨论模型训练的过程中，同事提到了一个关键点",
        "sentence_A": "我们在训练模型时，需要特别关注 statistical 特征的处理，这直接影响到模型的性能。",
        "sentence_B": "我们在训练模型时，需要特别关注统计特征的处理，这直接影响到模型的性能。",
        "id": 1637,
        "target_term": "statistical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练中的参数调整时",
        "sentence_A": "我们在训练模型时，需要对参数进行 fine-tuning，这个过程中的 steering 非常关键。",
        "sentence_B": "我们在训练模型时，需要对参数进行微调，这个过程中的参数调整非常关键。",
        "id": 1638,
        "target_term": "fine-tuning",
        "is_hardcore": true
    },
    {
        "topic": "Stereo Vision in AI",
        "prefix": "在讨论如何优化立体视觉模型的训练数据时",
        "sentence_A": "我们这次的数据清洗需要特别注意 stereo 图像的对齐问题。",
        "sentence_B": "我们这次的数据清洗需要特别注意立体图像的对齐问题。",
        "id": 1639,
        "target_term": "stereo",
        "is_hardcore": true
    },
    {
        "topic": "Stochastic Gradient Descent",
        "prefix": "在讨论模型训练方法时",
        "sentence_A": "我们这次用的优化器是基于 stochastic gradient descent 的，这样可以更好地处理大数据集。",
        "sentence_B": "我们这次使用的优化器是基于随机梯度下降的，这样可以更好地处理大数据集。",
        "id": 1640,
        "target_term": "stochastic gradient descent",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到优化策略的重要性。",
        "sentence_A": "我们在讨论模型训练时，提到了几种不同的 strategie，比如数据增强和正则化。",
        "sentence_B": "我们在讨论模型训练时，提到了几种不同的策略，比如数据增强和正则化。",
        "id": 1641,
        "target_term": "strategie",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方法时",
        "sentence_A": "我们这次可以尝试一下不同的 training strategy，看看哪种能提高模型的泛化能力。",
        "sentence_B": "我们可以尝试不同的训练策略，看看哪种能提高模型的泛化能力。",
        "id": 1642,
        "target_term": "training strategy",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的优化方法时，团队成员提出了一个关于模型强度的观点。",
        "sentence_A": "在训练这个模型的时候，我们要注意它的 strength，确保它在不同数据集上的表现都足够好。",
        "sentence_B": "在训练这个模型的时候，我们要注意它的强度，确保它在不同数据集上的表现都足够好。",
        "id": 1643,
        "target_term": "strength",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的结构优化时，团队成员提到：",
        "sentence_A": "我们需要重新审视模型的 structure，确保它在大规模数据集上表现良好。",
        "sentence_B": "我们需要重新审视模型的结构，确保它在大规模数据集上表现良好。",
        "id": 1644,
        "target_term": "structure",
        "is_hardcore": true
    },
    {
        "topic": "Manifold Learning",
        "prefix": "在模型训练过程中，我们讨论了如何在高维数据中找到低维子流形。",
        "sentence_A": "在训练模型时，我们发现通过优化 submanifold 可以显著提升模型的泛化能力。",
        "sentence_B": "在训练模型时，我们发现通过优化子流形可以显著提升模型的泛化能力。",
        "id": 1645,
        "target_term": "submanifold",
        "is_hardcore": true
    },
    {
        "topic": "subsequence",
        "prefix": "在讨论模型训练的数据处理阶段，团队成员提到一个关键的数据结构。",
        "sentence_A": "我们在处理时间序列数据时，经常需要提取 subsequence 来进行特征工程。",
        "sentence_B": "我们在处理时间序列数据时，经常需要提取子序列来进行特征工程。",
        "id": 1646,
        "target_term": "subsequence",
        "is_hardcore": true
    },
    {
        "topic": "Sequence Processing",
        "prefix": "在讨论模型训练时，团队成员提到如何处理输入数据的子序列问题。",
        "sentence_A": "我们这次在模型训练中，特别关注了如何高效地处理 input 的 subsequences，确保模型在推理时能快速响应。",
        "sentence_B": "我们在模型训练中特别关注了如何高效地处理输入数据的子序列，确保模型在推理时能够快速响应。",
        "id": 1647,
        "target_term": "input",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率问题时",
        "sentence_A": "我们需要在数据预处理阶段做出一些 substantial 的优化，这样才能确保模型训练的速度和效果。",
        "sentence_B": "我们需要在数据预处理阶段做出一些实质性的优化，这样才能确保模型训练的速度和效果。",
        "id": 1648,
        "target_term": "substantial",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的规模时，团队成员提到",
        "sentence_A": "我们需要确保训练数据集的大小是 sufficient 的，这样才能保证模型的泛化能力。",
        "sentence_B": "我们需要确保训练数据集的大小是足够的，这样才能保证模型的泛化能力。",
        "id": 1649,
        "target_term": "sufficient",
        "is_hardcore": true
    },
    {
        "topic": "Supervised Learning",
        "prefix": "在模型训练过程中，我们经常讨论不同类型的训练方法。",
        "sentence_A": "这次的模型训练，我们主要采用了 supervised 方法，数据集的质量对模型性能影响很大。",
        "sentence_B": "这次的模型训练，我们主要采用了监督学习方法，数据集的质量对模型性能影响很大。",
        "id": 1650,
        "target_term": "supervised",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员提到模型的适应性问题。",
        "sentence_A": "我们的模型需要更好的 support 多种输入格式，这样才能在不同的数据集上表现更好。",
        "sentence_B": "我们的模型需要更好地支持多种输入格式，这样才能在不同的数据集上表现更好。",
        "id": 1651,
        "target_term": "support",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要处理各种数据特征。",
        "sentence_A": "在训练深度学习模型时，我们经常需要处理各种特征，比如图像的 surface 特征。",
        "sentence_B": "在训练深度学习模型时，我们经常需要处理各种特征，比如图像的表面特征。",
        "id": 1652,
        "target_term": "surface",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练数据集的预处理时",
        "sentence_A": "我们需要注意，数据预处理的步骤会直接影响到模型的训练效果，特别是在处理包含各种 surface 的数据时。",
        "sentence_B": "我们需要注意，数据预处理的步骤会直接影响到模型的训练效果，特别是在处理包含各种表面的数据时。",
        "id": 1653,
        "target_term": "surface",
        "is_hardcore": true
    },
    {
        "topic": "Symbolic Computation in AI Models",
        "prefix": "在模型训练过程中，我们经常需要处理符号计算的问题。",
        "sentence_A": "在训练这个模型时，我们发现 symbolic 计算部分的效率特别低，需要优化。",
        "sentence_B": "在训练这个模型时，我们发现符号计算部分的效率特别低，需要优化。",
        "id": 1654,
        "target_term": "symbolic",
        "is_hardcore": true
    },
    {
        "topic": "Symmetry in Data Preprocessing",
        "prefix": "在数据预处理阶段，我们发现某些特征需要进行对称处理，以确保模型的鲁棒性。",
        "sentence_A": "我们在数据预处理阶段发现，某些特征需要进行 symmetric 处理，以确保模型的鲁棒性。",
        "sentence_B": "我们在数据预处理阶段发现，某些特征需要进行对称处理，以确保模型的鲁棒性。",
        "id": 1655,
        "target_term": "symmetric",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的多机多卡配置时",
        "sentence_A": "我们在多机多卡训练时，synchronization 的问题一定要处理好，不然会影响训练效率和模型收敛。",
        "sentence_B": "我们在多机多卡训练时，同步的问题一定要处理好，不然会影响训练效率和模型收敛。",
        "id": 1656,
        "target_term": "synchronization",
        "is_hardcore": true
    },
    {
        "topic": "Data Synthesis",
        "prefix": "在模型训练过程中，我们需要生成大量合成数据来增强模型的泛化能力。",
        "sentence_A": "在模型训练过程中，我们需要生成大量 synthesi 数据来增强模型的泛化能力。",
        "sentence_B": "在模型训练过程中，我们需要生成大量合成数据来增强模型的泛化能力。",
        "id": 1657,
        "target_term": "synthesi",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and System Integration",
        "prefix": "在模型训练过程中，我们讨论了系统的集成问题。",
        "sentence_A": "我们在训练模型时，发现 system 的集成遇到了一些问题。",
        "sentence_B": "我们在训练模型时，发现系统的集成遇到了一些问题。",
        "id": 1658,
        "target_term": "system",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练任务的分配时",
        "sentence_A": "这次的 model training task 我们需要尽快分配下去，确保每个 team 都有明确的责任。",
        "sentence_B": "这次的模型训练任务我们需要尽快分配下去，确保每个团队都有明确的责任。",
        "id": 1659,
        "target_term": "model training task",
        "is_hardcore": true
    },
    {
        "topic": "Temporal Data Processing",
        "prefix": "在讨论模型训练数据处理时",
        "sentence_A": "我们在处理 temporal 数据时，需要特别注意时间序列的连续性和一致性。",
        "sentence_B": "我们在处理时间数据时，需要特别注意时间序列的连续性和一致性。",
        "id": 1660,
        "target_term": "temporal",
        "is_hardcore": true
    },
    {
        "topic": "Tensor Operations",
        "prefix": "在讨论模型训练的过程中，同事提到了一个关键的数据结构。",
        "sentence_A": "在训练模型时，我们经常需要操作 tensor，比如进行矩阵乘法和张量转置。",
        "sentence_B": "在训练模型时，我们经常需要操作张量，比如进行矩阵乘法和张量转置。",
        "id": 1661,
        "target_term": "tensor",
        "is_hardcore": true
    },
    {
        "topic": "Model Deployment",
        "prefix": "在部署模型时，我们需要确保所有环境变量都配置正确。",
        "sentence_A": "在部署模型时，我们需要确保所有环境变量在 terminal 里都配置正确。",
        "sentence_B": "在部署模型时，我们需要确保所有环境变量在终端里都配置正确。",
        "id": 1662,
        "target_term": "terminal",
        "is_hardcore": true
    },
    {
        "topic": "Model Inference",
        "prefix": "在讨论模型推理优化时，",
        "sentence_A": "我们需要确保在不同的 terminal 上模型的性能都是一致的。",
        "sentence_B": "我们需要确保在不同的终端设备上模型的性能都是一致的。",
        "id": 1663,
        "target_term": "terminal",
        "is_hardcore": true
    },
    {
        "topic": "Model Evaluation",
        "prefix": "在模型训练完成后，团队正在讨论下一步的计划。",
        "sentence_A": "模型训练得差不多了，下一步我们要开始 doing some testing，确保模型在实际数据上的表现。",
        "sentence_B": "模型训练得差不多了，下一步我们要开始进行一些测试，确保模型在实际数据上的表现。",
        "id": 1664,
        "target_term": "doing some testing",
        "is_hardcore": true
    },
    {
        "topic": "Text Processing in Model Training",
        "prefix": "在讨论模型训练的数据预处理阶段时",
        "sentence_A": "我们这次的训练数据集包含了大量的 text，需要先进行清洗和分词。",
        "sentence_B": "我们这次的训练数据集包含了大量的文本，需要先进行清洗和分词。",
        "id": 1665,
        "target_term": "text",
        "is_hardcore": false
    },
    {
        "topic": "Textual Data Processing",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们在处理 textual 数据的时候，需要特别注意数据清洗和预处理的步骤。",
        "sentence_B": "我们在处理文本数据的时候，需要特别注意数据清洗和预处理的步骤。",
        "id": 1666,
        "target_term": "textual",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的理论与实践差距时",
        "sentence_A": "我们在讨论模型训练的时候，总是需要平衡 theoretical 和实际应用之间的差距。",
        "sentence_B": "我们在讨论模型训练的时候，总是需要平衡理论和实际应用之间的差距。",
        "id": 1667,
        "target_term": "theoretical",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的策略时",
        "sentence_A": "我们不仅要关注 practical implementation，还要深入理解 underlying theory。",
        "sentence_B": "我们不仅要关注实际实现，还要深入理解底层理论。",
        "id": 1668,
        "target_term": "practical implementation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练时，团队成员正在探讨模型的思考过程。",
        "sentence_A": "我们在训练这个模型的时候，要特别注意它的 thinking 过程，确保它能够有效地处理复杂任务。",
        "sentence_B": "我们在训练这个模型的时候，要特别注意它的思考过程，确保它能够有效地处理复杂任务。",
        "id": 1669,
        "target_term": "thinking",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整各种参数来优化模型性能。",
        "sentence_A": "在调整模型的超参数时，我们发现如果把 dropout 的 threshold 设得太高，会导致模型在验证集上的表现不佳。",
        "sentence_B": "在调整模型的超参数时，我们发现如果把 dropout 的阈值设得太高，会导致模型在验证集上的表现不佳。",
        "id": 1670,
        "target_term": "dropout",
        "is_hardcore": true
    },
    {
        "topic": "Model Training and Inference Optimization",
        "prefix": "在讨论模型训练和推理优化的过程中",
        "sentence_A": "我们需要优化模型的 throughput，以确保在高负载下依然能保持高性能。",
        "sentence_B": "我们需要优化模型的吞吐量，以确保在高负载下依然能保持高性能。",
        "id": 1671,
        "target_term": "throughput",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的效率和优化时",
        "sentence_A": "我们在训练模型的时候，需要特别关注每个 epoch 的 time，这样才能确保整体训练效率。",
        "sentence_B": "我们在训练模型的时候，需要特别关注每个 epoch 的时间，这样才能确保整体训练效率。",
        "id": 1672,
        "target_term": "epoch",
        "is_hardcore": true
    },
    {
        "topic": "Data Processing",
        "prefix": "在数据清洗过程中，我们发现了一个时间戳的问题。",
        "sentence_A": "在数据清洗的时候，我们发现有些记录的 timestamp 不对，需要进一步校正。",
        "sentence_B": "在数据清洗的时候，我们发现有些记录的时间戳不对，需要进一步校正。",
        "id": 1673,
        "target_term": "timestamp",
        "is_hardcore": true
    },
    {
        "topic": "Token Usage in Model Training",
        "prefix": "在讨论模型训练中的数据预处理时",
        "sentence_A": "我们在预处理数据时，每个句子都会被拆分成 token，这样模型才能更好地理解输入。",
        "sentence_B": "我们在预处理数据时，每个句子都会被拆分成词元，这样模型才能更好地理解输入。",
        "id": 1674,
        "target_term": "token",
        "is_hardcore": true
    },
    {
        "topic": "Tokenization",
        "prefix": "在模型训练过程中，我们经常需要对输入文本进行预处理。",
        "sentence_A": "在进行模型训练时，我们通常需要对输入文本进行 tokenization，这一步骤对于模型的性能至关重要。",
        "sentence_B": "在进行模型训练时，我们通常需要对输入文本进行分词，这一步骤对于模型的性能至关重要。",
        "id": 1675,
        "target_term": "tokenization",
        "is_hardcore": true
    },
    {
        "topic": "Tokenization in Model Training",
        "prefix": "在讨论模型训练数据预处理时",
        "sentence_A": "我们在处理文本数据时，经常会用到 token，这些 token 是输入模型的基本单位。",
        "sentence_B": "我们在处理文本数据时，经常会用到词元，这些词元是输入模型的基本单位。",
        "id": 1676,
        "target_term": "token",
        "is_hardcore": true
    },
    {
        "topic": "Topic",
        "prefix": "在模型训练过程中，我们讨论了如何优化数据流和处理特定主题的数据。",
        "sentence_A": "在训练模型时，我们发现处理不同的 topic 数据时，需要优化数据流以提高效率。",
        "sentence_B": "在训练模型时，我们发现处理不同的主题数据时，需要优化数据流以提高效率。",
        "id": 1677,
        "target_term": "topic",
        "is_hardcore": true
    },
    {
        "topic": "Network Topology in Model Deployment",
        "prefix": "在讨论模型部署的网络结构时，团队成员提到",
        "sentence_A": "我们在设计模型的部署方案时，需要特别注意 network topology，确保各个节点之间的通信效率。",
        "sentence_B": "我们在设计模型的部署方案时，需要特别注意网络拓扑，确保各个节点之间的通信效率。",
        "id": 1678,
        "target_term": "network topology",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型的训练周期时",
        "sentence_A": "这次的 training 我们要特别注意数据的平衡性和模型的泛化能力。",
        "sentence_B": "这次的训练我们要特别注意数据的平衡性和模型的泛化能力。",
        "id": 1679,
        "target_term": "training",
        "is_hardcore": true
    },
    {
        "topic": "Model Transfer Learning",
        "prefix": "在讨论模型迁移学习时",
        "sentence_A": "我们在做模型训练时，经常需要从一个领域 transfer 到另一个领域，这样可以大大节省训练时间和资源。",
        "sentence_B": "我们在进行模型训练时，经常需要将模型从一个领域迁移到另一个领域，这样可以大大节省训练时间和资源。",
        "id": 1680,
        "target_term": "transfer",
        "is_hardcore": true
    },
    {
        "topic": "Data Transformation",
        "prefix": "在模型训练数据预处理阶段，我们讨论如何优化数据转换过程。",
        "sentence_A": "在数据预处理阶段，我们需要确保每个步骤的 transformation 都是高效的，这样才能保证模型训练的顺利进行。",
        "sentence_B": "在数据预处理阶段，我们需要确保每个步骤的数据转换都是高效的，这样才能保证模型训练的顺利进行。",
        "id": 1681,
        "target_term": "transformation",
        "is_hardcore": true
    },
    {
        "topic": "Transformer Architecture",
        "prefix": "在讨论模型优化时",
        "sentence_A": "我们在优化这个模型的时候，发现用 Transformer 可以显著提升性能，特别是在处理长文本时。",
        "sentence_B": "我们在优化这个模型的时候，发现使用变换器可以显著提升性能，特别是在处理长文本时。",
        "id": 1682,
        "target_term": "Transformer",
        "is_hardcore": true
    },
    {
        "topic": "Machine Translation",
        "prefix": "在模型训练过程中，我们讨论了如何优化翻译模型的性能。",
        "sentence_A": "在训练过程中，我们发现模型在处理复杂的 translation 任务时效果不佳。",
        "sentence_B": "在训练过程中，我们发现模型在处理复杂的翻译任务时效果不佳。",
        "id": 1683,
        "target_term": "translation",
        "is_hardcore": true
    },
    {
        "topic": "Decision Tree Optimization",
        "prefix": "在讨论模型优化时",
        "sentence_A": "我们在优化 decision tree 的过程中，发现通过剪枝可以显著提高模型的泛化能力。",
        "sentence_B": "我们在优化决策树的过程中，发现通过剪枝可以显著提高模型的泛化能力。",
        "id": 1684,
        "target_term": "decision tree",
        "is_hardcore": true
    },
    {
        "topic": "Data Labeling",
        "prefix": "在讨论模型训练数据集时",
        "sentence_A": "我们在训练模型时，发现这批数据里有很多 unlabeled 的样本，需要先进行标注。",
        "sentence_B": "我们在训练模型时，发现这批数据里有很多未标注的样本，需要先进行标注。",
        "id": 1685,
        "target_term": "unlabeled",
        "is_hardcore": true
    },
    {
        "topic": "Unsupervised Learning",
        "prefix": "在讨论模型训练时",
        "sentence_A": "我们这次用的 unsupervised 方法，可以大大减少标注数据的依赖，提升模型的泛化能力。",
        "sentence_B": "我们这次使用的无监督方法，可以大大减少对标注数据的依赖，提升模型的泛化能力。",
        "id": 1686,
        "target_term": "unsupervised",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论如何优化模型的训练过程。",
        "sentence_A": "我们在每次训练后都要进行一次 model update，确保模型能逐步改进。",
        "sentence_B": "我们在每次训练后都要进行一次模型更新，确保模型能逐步改进。",
        "id": 1687,
        "target_term": "model update",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练资源分配时",
        "sentence_A": "我们需要优化每个任务的 resource usage，确保每个模型都能在限定时间内完成训练。",
        "sentence_B": "我们需要优化每个任务的资源使用，确保每个模型都能在限定时间内完成训练。",
        "id": 1688,
        "target_term": "resource usage",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议中，团队成员提到一个关键的优化工具。",
        "sentence_A": "我们最近开发了一个新的 utility，可以显著提高模型训练的效率。",
        "sentence_B": "我们最近开发了一个新的工具，可以显著提高模型训练的效率。",
        "id": 1689,
        "target_term": "utility",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的会议中，团队成员提到验证集的重要性。",
        "sentence_A": "在模型训练过程中，我们一定要重视 validation 集的数据质量，这直接影响到模型的泛化能力。",
        "sentence_B": "在模型训练过程中，我们一定要重视验证集的数据质量，这直接影响到模型的泛化能力。",
        "id": 1690,
        "target_term": "validation",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整超参数以优化模型性能。",
        "sentence_A": "我们这次调整 learning rate 的 value，看看对模型收敛速度有没有影响。",
        "sentence_B": "我们这次调整学习率的值，看看对模型收敛速度有没有影响。",
        "id": 1691,
        "target_term": "learning rate",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要调整各种参数。",
        "sentence_A": "在训练模型时，我们经常需要调整各种 variable，以优化模型性能。",
        "sentence_B": "在训练模型时，我们经常需要调整各种变量，以优化模型性能。",
        "id": 1692,
        "target_term": "variable",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在讨论模型训练的稳定性时",
        "sentence_A": "我们在训练模型时发现，如果 batch size 太小，会导致 variance 很大，模型的性能波动很大。",
        "sentence_B": "我们在训练模型时发现，如果批量大小太小，会导致方差很大，模型的性能波动很大。",
        "id": 1693,
        "target_term": "batch size",
        "is_hardcore": true
    },
    {
        "topic": "Variational Inference",
        "prefix": "在讨论模型训练的优化策略时",
        "sentence_A": "我们在模型训练中使用了 variational 方法，这样可以更好地处理不确定性。",
        "sentence_B": "我们在模型训练中使用了变分方法，这样可以更好地处理不确定性。",
        "id": 1694,
        "target_term": "variational",
        "is_hardcore": true
    },
    {
        "topic": "Vector Representation in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到特征向量的重要性。",
        "sentence_A": "在训练模型时，我们发现使用更复杂的 vector 可以显著提高模型的性能。",
        "sentence_B": "在训练模型时，我们发现使用更复杂的向量可以显著提高模型的性能。",
        "id": 1695,
        "target_term": "vector",
        "is_hardcore": true
    },
    {
        "topic": "Vector Operations in Model Training",
        "prefix": "在讨论模型训练时，团队成员提到向量处理的重要性。",
        "sentence_A": "我们在训练模型时，需要特别注意 vector 的处理，确保它们的维度和格式一致。",
        "sentence_B": "我们在训练模型时，需要特别注意向量的处理，确保它们的维度和格式一致。",
        "id": 1696,
        "target_term": "vector",
        "is_hardcore": true
    },
    {
        "topic": "Video Processing",
        "prefix": "在讨论模型训练的数据预处理时",
        "sentence_A": "我们在处理 video 数据的时候，发现有一些视频的帧率不一致，需要进行统一处理。",
        "sentence_B": "我们在处理视频数据的时候，发现有一些视频的帧率不一致，需要进行统一处理。",
        "id": 1697,
        "target_term": "video",
        "is_hardcore": false
    },
    {
        "topic": "Model Training",
        "prefix": "在一次模型训练的讨论中，团队成员正在讨论数据预处理的细节。",
        "sentence_A": "我们在预处理阶段需要考虑如何处理数据的 view，这样才能确保模型在训练时能够更好地理解数据的结构。",
        "sentence_B": "我们在预处理阶段需要考虑如何处理数据的视图，这样才能确保模型在训练时能够更好地理解数据的结构。",
        "id": 1698,
        "target_term": "view",
        "is_hardcore": false
    },
    {
        "topic": "Computer Vision",
        "prefix": "在讨论模型训练的数据集选择时",
        "sentence_A": "我们在训练这个模型时，需要特别注意数据集的多样性，尤其是对于 vision 任务来说，数据的丰富性直接影响到模型的泛化能力。",
        "sentence_B": "我们在训练这个模型时，需要特别注意数据集的多样性，尤其是对于计算机视觉任务来说，数据的丰富性直接影响到模型的泛化能力。",
        "id": 1699,
        "target_term": "vision",
        "is_hardcore": true
    },
    {
        "topic": "Visual Feature Extraction",
        "prefix": "在模型训练过程中，我们需要优化视觉特征的提取过程。",
        "sentence_A": "我们需要优化 visual feature 的提取过程，以提高模型的准确率。",
        "sentence_B": "我们需要优化视觉特征的提取过程，以提高模型的准确率。",
        "id": 1700,
        "target_term": "visual feature",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，我们经常需要监控各种指标的变化。",
        "sentence_A": "在训练过程中，我们经常使用 visualization 工具来监控模型的性能，比如 loss 和 accuracy 的变化。",
        "sentence_B": "在训练过程中，我们经常使用可视化工具来监控模型的性能，比如损失和准确率的变化。",
        "id": 1701,
        "target_term": "visualization",
        "is_hardcore": true
    },
    {
        "topic": "Vocabulary Management in NLP Models",
        "prefix": "在模型训练过程中，讨论如何处理词汇表的问题",
        "sentence_A": "我们在训练模型时，发现 vocab 的大小对性能有显著影响。",
        "sentence_B": "我们在训练模型时，发现词汇表的大小对性能有显著影响。",
        "id": 1702,
        "target_term": "vocab",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员讨论如何调整模型的参数以提高性能。",
        "sentence_A": "我们这次的训练结果不太好，可能需要调整一下模型的 weight，看看能不能提升精度。",
        "sentence_B": "我们这次的训练结果不太好，可能需要调整一下模型的权重，看看能不能提升精度。",
        "id": 1703,
        "target_term": "weight",
        "is_hardcore": true
    },
    {
        "topic": "Model Training",
        "prefix": "在模型训练过程中，团队成员讨论如何优化模型的性能。",
        "sentence_A": "我们在调整模型的 weight 时，发现有些 layers 的 weight 更新得特别慢，这可能会影响最终的性能。",
        "sentence_B": "我们在调整模型的权重时，发现有些层的权重更新得特别慢，这可能会影响最终的性能。",
        "id": 1704,
        "target_term": "weight",
        "is_hardcore": true
    },
    {
        "topic": "Model Architecture",
        "prefix": "在讨论模型架构优化的会议上，团队成员提出了一个关于卷积层的建议。",
        "sentence_A": "我觉得我们可以试着把卷积层的宽度调得更 wide 一些，看看效果如何。",
        "sentence_B": "我觉得我们可以试着把卷积层的宽度调得更宽一些，看看效果如何。",
        "id": 1705,
        "target_term": "wide",
        "is_hardcore": true
    },
    {
        "topic": "Model Training Workflow",
        "prefix": "在讨论模型训练的优化流程时，",
        "sentence_A": "我们需要优化整个 workflow，包括数据预处理、模型训练和评估环节。",
        "sentence_B": "我们需要优化整个工作流，包括数据预处理、模型训练和评估环节。",
        "id": 1706,
        "target_term": "workflow",
        "is_hardcore": true
    }
]